Humans vs computer:
-human -get bored, creative, detect patterns, follows
-computer -don't bored, non-creative, computation, follow blindly


Think like programmer:
-programming is about problem-solving, not just writing code
-understand problem deeply
-What are inputs
-What are outputs
-What constraints exist
-break problem into small, manageable pieces
-jumping into code without plan = wasted time & frustration
-write out logic in plain english (pseudocode)
-break task into smaller subproblems
-identify patterns & reusable solutions
-what happens if password is incorrect
-should there be limit on login attempts
-how will user data be stored securely
-divide & conquer –solve subproblems 1st
-big problems ---> small problems ---> solve them one by one
-find patterns that make problem simpler
-use recursion, loops, or functions to handle repeated logic
-debugging –find & fix issues systematically
-avoid frustration by debugging methodically
-reproduce bug
-add print statements or use debugger
-test parts of your code in isolation
-change one thing at time & observe effect
-compare expected vs actual output
-think in algorithms
-algorithms = step-by-step problem-solving techniques
-common algorithm approaches:
-brute force: Try all possibilities (simple but slow)
-greedy approach: Take the best immediate option
-divide & conquer -break down into smaller problems (merge sort)
-dynamic programming -store results to avoid redundant work (fibonacci memoization)
-learn to recognise patterns
-many problems share similar structures
-common patterns -two-pointer technique (for sorted arrays)
                  -sliding window (for continuous subarrays)
                  -hash maps (for fast lookups)
                  -recursion + memoization (for optimisation)
-use HashMap instead of nested loops
-keep practicing & never give up
-best programmers fail lot—but they keep trying
-solve at least one coding problem daily
-try problems above your skill level to push yourself
-learn from others solutions to see different approaches
-participate in coding challenges like LeetCode, Codeforces, Hackerrank


Python modules:
-GUI development -PyQT5, tinter, kiva, wxpython, pyside2
-game development -pygame, piglet, panda3d, pykyra, pyopenGL
-image processing -PIL/pillow openCV, scimitar-image, simpleTK, mahouts
-data visualisation -metaplotlib, ploty, seaborn, bokeh, ggplot
-web scraping -request, selenium, scrape, lxml, beautiful soup
-web development -django, web2p, flash, bottle, cherrypy


-CPU ----(process 2 executing)----> main memory (process 1,2,3,4,5,6) ---(process 1 doing I/O operation 
 & 3,4,5,6 waiting for CPU)----> secondary memory


How to think as programmer:
-pseudo code
-Amstrad CPC 464
-write simple & elegant code
-think creatively & logically
-avoid copy & pasting of code
-never try to over-engineer code


-dual-core pentium (32-bit), 2.0GHz clock, 4GB RAM, 5400RPM HDD, basic integrated graphic processor


Homelab:
-core devices -server -main computing power to host services (VMs, Docker, databases)
                      -options -prebuilt (Dell powerEdge, HP ProLiant) 
                      -at-least 16GB RAM, multicore CPU (Xeon or Ryzen), SSDs for storage
              -switch -connect multiple devices within your homelab
                      -managed (for VLANs) or unmanaged
                      -TP-Link TL-SG108 or Ubiquiti UniFi switch
              -router -connect homelab to internet & manage network traffic
                      -consumer-grade (Netgear, ASUS) or enterprise-grade (Ubiquiti, pfSense)
              -NAS (network-attached storage) -centralised file storage & backups
                                              -synology, QNAP, build your own (FreeNAS, TrueNAS)
              -firewall appliance -protect homelab from external threats
                                  -pfSense box, Ubiquiti UniFi security gateway
              -backup power (UPS) -prevent power loss during outages
                                  -APC UPS (500-1500VA, depending on your load)
              -workstation/client PC -access, manage & test homelab setups
                                     -daily-use desktop or laptop
-networking components -access point -extend wireless coverage, Ubiquiti UniFi AP, TP-Link Omada
                       -patch panel -Neatly organise & route ethernet cables
                       -cables -ethernet cables -CAT6 or CAT6A for faster speeds
                               -power cables -standard AC cables for all devices
                               -console cable -configuring network devices (RJ45-to-USB)
                       -cable management -velcro straps, zip ties, cable sleeves
-server components -CPU -handles computation tasks, Intel Xeon or AMD Ryzen
                   -RAM -memory for VMs & services, 16GB (upgradeable to 64GB+)
                   -storage -SSD (NVMe/SATA) faster storage for OS & frequently used data
                            -HDD -bulk storage for backups & media
                   -cooling -prevent overheating, Noctua fans, liquid cooling for silence
                   -RAID Controller -redundancy for storage
-software & Tools -virtualisation -host multiple VMs or containers, proxmox, VMware ESXi, virtualbox
                  -containerisation -run lightweight apps, Docker + Portainer
                  -monitoring Tools -keep track of system health, Grafana, Zabbix, Prometheus
                  -backups -ensure data safety, Veeam, rsync, Synology backup
-optional -KVM switch -share keyboard, video, mouse across multiple systems, IOGEAR KVM
          -Raspberry Pi -lightweight experiments or Pi-hole (ad-blocker)
          -smart plug -remote power cycling of devices
          -rack mount -neatly organise all devices, 12U-20U rack
-connectivity -ethernet ports -at-least 1 per device, prefer multi-port NICs for servers
              -fibre optics -high-speed backbone links
              -USB devices -bootable drives, Wi-Fi dongles, adapters


PDU:
-protocol data unit is single unit of information transmitted b/w entities (devices) on network 
-consists of 2 parts -protocol control information (PCI) -header contains instructions & information 
 needed for routing, error detection, other network functions, specific content of PCI varies depending 
 on layer
-user data -actual data being transmitted (text, images, application data), each layer of open systems 
 interconnection (OSI) model, conceptual framework for network communication, uses PDUs in its specific 
-physical layer -carries basic electrical, optical signals
-data link layer -adds addressing information for devices on same network segment
-network layer -adds routing information for devices across different network segments
-transport layer -datagram & provides reliable data transfer b/w applications on different devices
-session layer -manage, terminate communication sessions b/w applications
-presentation layer -focuses on data format & representation for different systems
-application layer -original user data, potentially encapsulated within PDUs from lower layers
Key differences between PDUs and layers:

PDUs are data units transmitted on the network, while layers are conceptual models defining network communication functions.
Each layer processes the PDUs it receives, adding or removing its specific header information.
PDUs change format and content as they move down or up the layers, accumulating headers or trailers needed for each layer's function.
Ethernet Frame Filtering**: Ethernet switches use MAC address tables to filter and forward frames only to the appropriate destination devices, enhancing network security and efficiency.

2. **Ethernet Address Resolution Protocol (ARP)**: ARP is used in Ethernet networks to map IP addresses to MAC addresses, enabling communication between devices on the same LAN.

3. **Ethernet Frame Size**: Ethernet frames have a maximum transmission unit (MTU) size, which varies depending on the Ethernet variant. For example, standard Ethernet has an MTU of 1500 bytes, while jumbo frames can support larger payloads.

4. **Ethernet Physical Media**: Ethernet can operate over various physical media types, including twisted-pair copper cables (e.g., Cat 5e, Cat 6), coaxial cables, and fiber optic cables (single-mode or multi-mode).

5. **Ethernet Auto-negotiation**: Ethernet devices often support auto-negotiation, a process where devices automatically negotiate the highest common speed and duplex mode (e.g., half-duplex or full-duplex) for communication.

6. **Ethernet Frame Error Handling**: Ethernet frames include error detection mechanisms, such as the Frame Check Sequence (FCS), to detect transmission errors. Frames with errors are typically discarded or retransmitted.

7. **Ethernet Broadcast and Multicast**: Ethernet supports broadcast frames, which are sent to all devices on the LAN, and multicast frames, which are sent to a specific group of devices identified by a multicast MAC address.

8. **Ethernet Link Aggregation**: Ethernet link aggregation, also known as EtherChannel or port trunking, allows multiple physical Ethernet links to be combined into a single logical link for increased bandwidth and redundancy.

9. **Ethernet VLAN Trunking**: VLAN trunking protocols like IEEE 802.1Q enable the transmission of VLAN information across Ethernet networks, allowing VLAN-aware switches to maintain VLAN segregation across multiple interconnected switches.

10. **Ethernet Security Features**: Ethernet switches often include features like port security, MAC address filtering, and IEEE 802.1X authentication to enhance network security and prevent unauthorised access to the network.


Blockchain:
-network, market cap, circulating supply, all time high, events, social media, launch price, product, 
 growth since launch, ICO round, market dominance, max supply, all time low, use cases, price 
 prediction
-no restriction on payment, use complex algorithm, speed of exchange, no-3rd party involvement, 
 free/very less transaction fees, no inflation
-use complex technique, highly volatile, not accepted everywhere, black market, scaling issues, no  
 reserve of payment & recovery
-works on shared ledger of transactions
-blockchain is basically like network of different blocks
-Web 2.0 (login, signing, liking, posting & so on)
-Web 1.0 (only Html, css, & barely some javascript)
-Web 3.0 (nobody owns your data) (transaction can be accessed by anyone) (network of block)
-no technology till now to hack all block chains
-written or smart contacts is extra thing to write in block chain
-javascript, typescript, python
-solidity programming language to write smart contracts
-gas fees for doing any transaction
-polygon/ solana
-remix IDE/ hardhat/ mocha
-NFT (non fungible token projects) (opens/wallet app)
-finding open source projects
-ledger information is stored in blocks
-blocks are verified using "proof of work"
-only verified blocks are added to blockchain
-miner who verifies block gets reward
-reward keep enough miner for safe system
-block ---- block ---- block 
-verifying information with a lot of computing effort
-consensus -mechanism requiring enough people to agree which transaction are valid
-ledger -record of all transaction in group
-blockchain ledger of each person (who gives & takes bitcoin & how much)
-blockchain ledger -user addresses transactions are more publicly traceable
-transaction requested ---> block (representing transaction created) ---> block is sent to every 
 node in network ---> nodes validate transaction & receive reward fro proof of work ---> block is  
 added to existing blockchain & transaction is complete
-peer-to-peer decentralised network -users verify transactions by completing complex math problem
				   -order transaction from past 10 min
				   -receive bitcoin in return
				   -keep network secure
-blockchain trilemma -security, scalability, decentralisation
-hot wallet -connected to internet 
            -allow from instantaneous fund transfer
            -greater ease of use but more vulnerable to hacking
-cold wallet -offline wallet live in small hardware device/ paper
             -more secure, payment process may be more cumbersome
-bitcoin -security -strong proof-of-work consensus makes highly secure
         -decentralised -large number of nodes worldwide
         -scalability trade-off -struggles with transaction speed (7 transaction per second)
-ethereum -security -initially used (PoW), now use proof-of-stake (PoS) for energy efficiency
          -decentralisation -large validator network (staking based)
          -scalability trade-off -fees are high due to congestion
-solana -scalability -handles 65000 TPS with low fees
        -security -uses proof-of-history (poH) reducing consensus time
        -decentralisation -high hardware requirements means fewer validator, leading to concerns 
                           about centralisation
-polygon -security -relies on ethereum's security
         -scalability -supports high speed transactions with low fees
         -decentralisation trade-off -centralised due to early validator concentration


Creating own cryptography:
-decide on type of cryptocurrency
-create token (built on existing blockchain like Ethereum, Binance Smart Chain, or Solana)
-create coin (your own blockchain, like Bitcoin or Ethereum)
-tokens are easier to create & don’t require new blockchain
-coins require setting up & maintaining blockchain
-set up development environment
-Node.js (for smart contracts & blockchain interaction)
-Solidity (for Ethereum-based tokens)
-Python/Go/Rust (for developing blockchains)
-Metamask (for testing your token)
-Ganache (for local blockchain testing)
-npm install -g truffle ganache-cli
-creating token 
-If making token, Ethereum (ERC-20) is best choice
-create solidity smart contract ---> deploy it to Ethereum/ Binance smart chain ---> test on Testnet
 ---> launch it on Mainnet ---> list on exchanges
-Writing an ERC-20 Token in Solidity
-create new solidity file MyToken.sol ---> sets name & symbol. --->  Mints 1M tokens
-deploying token ---> install dependencies ---> configure Hardhat ---> deploy using Hardhat script
 ---> run deployment script
-creating your own blockchain 
-consensus mechanism (proof of work/ proof of stake)
-mining algorithm (SHA-256, Ethash)
-block time, reward, difficulty
-setting up blockchain with python
-making blockchain work ---> if using Ethereum, set up Geth (go Ethereum) node
-use Tendermint (for PoS)
-use Substrate (for Rust-based chains)
-use Cosmos SDK for easy blockchain development
-listing your token on exchange
-to list on PancakeSwap (BSC) or Uniswap (Ethereum)
-get liquidity tokens by adding BNB/ETH
-use token listing services
-apply on centralised exchanges (KuCoin, Binance)
-adding utility 
-smart contracts ---> for DeFi, gaming, payments
-DApps ---> apps using token
-NFTs ---> create NFTs with your token
-security considerations
-use OpenZeppelin contracts (pre-audited)
-audit your contract using Slither or MythX
-prevent reentrancy attacks


Making money from crypto:
-choose profitable crypto model
-utility token -used in platform or ecosystem -->	Binance Coin (BNB), Chainlink (LINK)
-DeFi token -earn fees from lending, staking, liquidity pools -->	Aave (AAVE), Uniswap (UNI)
-Meme coin -build hype, raise funds, create viral movement --> Dogecoin (DOGE), Shiba Inu (SHIB)
-NFT ecosystem -charge fees for minting & selling NFTs --> Axie Infinity (AXS), Decentraland (MANA)
-transaction fees -earn fees when users trade your token --> Ethereum (ETH), BNB
-initial coin offering (ICO/IDO)	-raise funds by selling early-stage tokens --> Ethereum, Solana
-mining & staking rewards -users earn by mining/staking your coin --> Bitcoin (BTC), Polkadot (DOT)
-build strong community (Hype = Money)
-build hype & demand
-use social media –twitter, reddit, telegram, discord
-create white-paper –explain your project's value
-list on CoinMarketCap & CoinGecko –get exposure
-get listed on DEXs (Uniswap, PancakeSwap) –more users = higher demand
-paid influencers –crypto influencers on Twitter & YouTube
-create staking system –holders earn rewards, reducing sell pressure
-airdrops –give free tokens to get more users
-raise money with ICO/ IDO (make millions in funding)
-create website & Whitepaper
-launch pre sale (private investors first)
-create smart contract for ICO
-launch public sale on your website
-list on Uniswap/ PancakeSwap
-market hard (influencers, ads, airdrops)
-get listed on centralised exchanges (Binance, KuCoin, OKX)
-transaction Fees
-if blockchain or token is used frequently, charge small fees per transaction
-ethereum makes billions from gas fees
-BNB chain earns millions from transaction fees
-if people use your token for millions of transactions, collect passive income from fees
-make money with liquidity pools & staking
-provide liquidity on DEXs
-add liquidity to Uniswap/PancakeSwap
-earn fees when people trade your token
-allow Users to Stake Your Token
-users stake tokens → You collect a % of rewards
-creates buy pressure (fewer people sell)
-sell Your Coin to Big Investors
-after launch, sell tokens in bulk to whales (big investors)
-you pre-mine tokens & sell them later
-build NFT ecosystem & make royalties
-NFTs = big money
-create NFTs on your blockchain
-earn royalties (2-10%) on every resale
-NFT contract with royalties in solidity
-every NFT resale = passive income
-list on centralised exchanges (CEXs) for big money
-listing on Binance, KuCoin, Coinbase = more buyers
-price goes up when coin listed on big exchange
-build a strong community (telegram, twitter, reddit)
-have high trading volume on DEXs
-apply for listing on Binance, KuCoin, OKX
-market like crazy to increase demand
-build DeFi platform & earn millions
-create lending platform (Aave, Compound)
-charge interest on borrowed crypto
-offer staking, farming & rewards
-advanced tricks -burn mechanism –reduce token supply to increase price
                 -governance token –let users vote on changes, increasing demand
                 -cross-chain compatibility –expand to multiple blockchains
                 -paid promotions –partner with you-tubers & twitter influencers
                 -airdrops to new users –create FOMO & attract investors


Making best crypto:
-most coins fail because ----> no real use, better than any other crypto your coin must solve real 
 problem
-high fees ----> near-zero transaction fees (solana, nano)
-slow transactions ----> lightning-fast TPS (transactions per second) (solana, avalanche)
-scalability issues ----> no congestion, infinite scalability (ethereum layer 2) (optimism, arbitrum)
-privacy issues	----> fully anonymous transactions ----> monero, Zcash
-lack of smart contracts ----> fully programmable blockchain (Ethereum, Cardano)
-DeFi & staking ----> high APY, yield farming rewards ----> (Aave, Uniswap)
-faster -use DAG (directed acyclic graph) technology –1M+ TPS
        -layer 2 scaling (rollups, side-chains) –instant transactions
        -sharding –parallel processing for infinite scalability
        -proof-of-stake or delegated proof-of-stake (PoS/ DPoS) –Faster than PoW
        -use rust or C++ –more optimised than Solidity
-implement AI-powered smart contract system
-auto-adjusting fees –low fees when network is busy
-fraud detection –AI spots scam transactions before they happen
-self-optimising smart contracts –AI predicts best gas fees & executes trades automatically
-market sentiment analysis – AI tracks social media & predicts price trends
-stability & price control (many coins are too volatile)
-dynamic supply mechanism –burn tokens during crashes, mint tokens in bull runs
-algorithmic stabilisation –AI controls price fluctuations
-auto-staking & dividends –holders earn interest just by holding
-NFT & GameFi utility –NFTs drive demand, reducing volatility
-create billion dollar DeFi & staking ecosystem
-more ways people use your coin, more valuable it becomes
-high APY staking (Auto-Compounding) –users earn passive income
-flash loans & lending –create decentralised bank
-yield farming & liquidity mining –users earn tokens by providing liquidity
-cross chain compatibility -work on Ethereum, Solana, Binance Smart Chain
-add NFT & Metaverse utility to skyrocket value
-NFTs + Metaverse = massive demand for your Coin
-NFT marketplace –let users buy & sell NFTs using your coin
-GameFi & Play-to-Earn (P2E) –use your token in blockchain games
-virtual Real Estate –sell land & assets in your metaverse
-real-World NFTs –link NFTs to physical assets (cars, property, luxury items)
-build strongest community & market like beast
-crypto success = HYPE + FOMO (fear of missing out)
-Twitter, Telegram, Discord, Reddit Marketing –build cult-like following
-Airdrops & Giveaways –give free tokens to early users
-influencer Partnerships –get YouTubers & TikTokers to shill your coin
-referral Programs –users earn rewards for inviting friends
-whale Investors –get big investors to pump your project
-get listed on top exchanges (Binance, Coinbase, KuCoin, OKX, Uniswap, PancakeSwap)
-listing on major exchanges = more buyers & higher price
-start on DEXs (Uniswap, PancakeSwap, SushiSwap)
-increase trading volume –fake it if necessary (market making)
-strong community growth –Telegram, Discord, Twitter, Reddit
-apply for Binance & Coinbase listing –once volume is high


-Crypto minining:
-types of crypto mining -proof-of-work (PoW) mining -solve complex mathematical problems (hashes) to 
                                                     validate transactions 1st miner to solve problem 
                                                     adds block to blockchain & receives reward
                                                    -requires high computational power & electricity
                        -Bitcoin, Ethereum Classic, Litecoin, Dogecoin, Monero
-ASIC mining  -most profitable for Bitcoin
              -uses application specific integrated circuits (ASICs) –specialised mining machines
              -extremely powerful but expensive & consumes high electricity
              -Bitcoin (BTC), Litecoin (LTC), Dash (DASH)
              -buy ASIC miner (Bitmain Antminer, Whatsminer)
              -get mining rig frame & power supply
              -install mining software (CGMiner, BFGMiner)
              -join mining pool (F2Pool, Slush Pool)
              -start mining & withdraw earnings
              -most profitable for Bitcoin, efficient for large-scale mining, high electricity costs
-GPU mining -best for Altcoins & Ethereum Classic
            -uses graphics processing units (GPUs) for mining
            -more flexible than ASICs & mine different coins
            -requires powerful gaming GPU (NVIDIA RTX 3090, AMD RX 6800 XT)
            -ethereum Classic (ETC), Ravencoin (RVN), Ergo (ERG)
            -buy high-performance GPU
            -install mining software (NBMiner, T-Rex, TeamRedMiner)
            -join mining pool (Ethermine, 2Miners)
            -optimise GPU settings (Undervolt to save power)
            -mine multiple coins, lower electricity cost than ASIC, GPUs are expensive, Less efficient 
             for Bitcoin
-CPU mining -least profitable, easy to start
            -uses regular computer’s CPU to mine crypto
            -not powerful, only profitable for privacy-focused coins
            -Monero (XMR), Bytecoin (BCN), Aeon (AEON)
            -install mining software (XMRig, SRBMiner)
            -join Monero mining pool
            -mine using normal PC, very low profits, high CPU wear & tear
-cloud mining -no hardware needed
              -rent mining power from cloud mining providers instead of buying hardware
              -pay fee & earn passive crypto income
              -Bitcoin (BTC), Ethereum Classic (ETC), Litecoin (LTC)
              -choose cloud mining service (sGenesis Mining, Hashflare, NiceHash)
              -buy mining contract (rent Hashpower)
              -receive Daily/Monthly Crypto Payouts
              -no hardware, no electricity cost, passive income potential, high risk of scams, lower 
               profits than real mining
-mobile mining -not recommended for profits
               -mine cryptocurrency on smartphone using app
               -uses CPU power & battery but earns tiny rewards
               -Pi network (PI), Electroneum (ETN)
               -download mobile mining app (Pi Network, Electroneum)
               -run mining sessions daily
               -withdraw rewards (when possible)
               -no special hardware needed, tiny earnings, drains battery & heats up phone
-staking -proof-of-stake alternative to mining)
         -instead of mining, users lock up crypto to validate transactions & earn rewards
         -requires owning & staking coins in crypto wallet
         -Ethereum (ETH), Cardano (ADA), Solana (SOL)
         -Buy PoS cryptocurrency
         -stake via exchange (Binance, Kraken, Coinbase) or wallet
         -earn passive crypto rewards
         -no electricity costs, passive income, requires holding coins, no mining involved
-maximising crypto mining profits 
-choose right coin to mine
-use WhatToMine (whattomine.com) to find profitable coins
-join mining pool
-solo mining is too hard –use mining pool for steady payouts
-best pools -Slush Pool, F2Pool, Ethermine, 2Miners
-use efficient mining hardware
-ASIC miners for bitcoin
-GPUs for Altcoins
-avoid CPU mining unless for Monero
-reduce Electricity Costs
-optimise power usage (undervolt GPUs)
-use renewable energy (solar panels)
-mine in regions with cheap electricity
-regularly withdraw profits
-convert mined crypto to stablecoins (USDT)
-secure earnings in hardware wallet (Ledger, Trezor)


[Google = prefers to keep ownership with code that allocate it, If other code needs access to 
 object, prefer to use std::unique_ptr to make ownership transfer explicit]
[jQuery, Netbeans, cocoa, Saas, CEF, cocos2d, SCSS, Redux, WebGL, Three.js, apache sparks, scrum, 
 objective-c, agile methodologies, azure devOps, AWS, quarkXpress, AJAX, REST APIs, jQuery, spring, 
 struts, hibernate, maven, XML, design patterns, agile methodologies, sensible, oracle cloud, GCP]
[more powerful features --> bring complexity, more bug prone, hard to read & maintain]
[ownership & smart pointers]
[use type deduction only to make code clearer/ safer & don't use it merely to avoid inconvenience of 
 writing explicit type]
[limit implementation inheritance, prefer interface inheritance, use composition instead]
[ownership (n) -concept in secure programming that dictates what object is responsible for management 
 of transient piece of memory]
[interface inheritance (n) -use of inheritance from exclusively abstract classes, no values or code are 
 inherited from parent]
[data hiding is technique of hiding internal object details, data hiding restricts data access to class 
 members ---> maintains data integrity]


Promoting your app:
-developer who spend succeed
-top earners spend time on marketing
-number of downloads --> games > weather > social networking > maps > music > news
-unique & memorable
-include most important keywords
-don't infringe any trademark


-bipolar junction transistor
-metallisation, oxide layer, silicon water
-photomask, photoresist, oxide layer, silicon wafer


Memory hierarchy:
-top -processor registers (small size, small capacity, very fast, very expensive) 
-2nd -processor cache (small size, small capacity, very fast, very expensive) 
-3rd -RAM (medium size, medium capacity, fast, affordable) 
-4th -flash/ USB (small size, large capacity, slower, cheap) 
-5th -hard drive (large size, very large capacity, slow, very cheap) 
-6th -tape backup (large size, very large capacity, very slow, affordable) 


ASCII vs UNICODE:
-ASCII -American standard code for information interchange
       -encodes charter for communication
       -2 standards -7 bit ASCII 128 characters, 8 bit ASCII 256 characters
       -support specific character & occupies less space
-UNICODE -universal character set/ universal coding system
	 -IT standard encodes text for computer & other communication device
	 -UTF-8 --> 256, UTF-16 65536, UTF-32 4294967296, UTF (unicode transformation format)
	 -support large number of character & occupies more space


Database:
-relational database -designed to capture & record data (OLTP)
-live, real-time data, stored in tables (rows & columns)
-highly detailed, flexible schema


Data warehouse:
-relational database -designed for analytical processing (OLAP)
-data is refreshed from source systems stores current & historical
-data is summarised, rigid schema 


Data lake:
-relational database -designed to capture raw data (structured, semi-structured, unstructured)
-made for large amount of data
-used for ML & AI in current state or analytics with processing
-can organise & put into databases or data warehouses


Github:
-create new git 
-git init
-git add --all
-git commit -m "message"
-git remote add https://github.com/<git>.git
-local changes
-git status
-git add --all
-git add -p file.txt
-history
-git log
-git log -p file.txt
-git blame file.txt
-branch
-git branch -av
-git branch new-branch
-git checkout branch
-undo
-git reset --hard HEAD
-git checkout HEAD file.txt
-fit revert commitID


Software vs firmware:
-software -set of instruction that specific what computer does
	  -application, SW, system, SW
	  -large size, KBs & GBs
	  -high level & low level programming language
	  -easy to update & modify
	  -visible & intractable for user
	  -runs in CPUs & GPUs
	  -constant change
	  -long development cycles 
-firmware -controls hardware devices
	  -BIOS, EFI
	  -small size, few KBs
	  -only low-level language
	  -hard/impossible to update & monitor
	  -hidden & locked from user
	  -runs on purpose-built/ tiny processor
	  -changes extremely rarely 
	  -short development cycles


-packets are reassemble in order
-utilities softwares -designed to assist users in maintain & core of their computers
-fault tolerance & redundancy -grow & scale without interrupting service 
			     -more routers = more reliable
		   	     -TCP + router systems = scalable
			     -TCP -manages sending & receiving of all your data as packets
-internet protocol -often best route for data to travel is not most direct
-routers act like traffic managers to keep packets moving smoothly
-packets don't have drivers, don't choose routes
-digital information can be sent with IP packets (music, e-book, videos)
-data travels on internet in much less direct fashion
-electricity (cheap & signal loss), light (really fast & no signal loss), radio (totally mobile, 	
 short range)
-direct dedicated connections --> impossible to keep things working
-wireless -uses radio signal to send bits from 1 place to another
-spammers try to game search algorithm
-keep eye on untrustworthy web addresses 
-website makes money when people visit there
-ranking algorithm -title, sequence, keyword (search engine)
-ranks page based on what it thinks people want
-fake emergency security update (may have wrong spellings)
-virus -organism spread through airborne or physical contact
-smart contracts can decentralise -information storage, how data is used, computing effort needed 
 to enforce rule
-NFT -non-fungible token (asset tracked on blockchain, digital collectibles, artwork, items in game)
-MPEG-4 video -20-200x smaller than original uncompressed file
-delay line memory -data in---speaker---microphone/amplifier---data out
-autonomous program ensures transaction followed without need of legal contracts
-writer, co-writer, performer


Logcat -CLI tool dumps log go system messages


[Vs code, Xcode, android studio, Jet brains, Pycharm, IJ, Arduino IDE]
[blender, scratch, pencil 2D, krita, Autodesk, notepad++, virtual box]
[computer = common operating machine purposely used for technological educational research]


-sudo nano /etc/pan.d/sudo
-brew install toilet
-curl https://.............
-which $SHELL
-bash
-ps -ax | grep thisascript
-kill -0 62779
-df -h
-mv test ~/documents/test
-security ping-generic-password -wa "James Coffee Co"
-security ping-generic-password -wa "James Coffee Co" | pbcopy
-ll


DOS vs DOSS:
-dos -transmits less amount of traffic
     -often carried out from single machine using script/ tool
     -tracking true origin is significantly less difficult 
     -simple to identify & terminate connections
     -DOS attack deployed less quicker
     -hacker ---- botnet ---- IP request point --------> server
-doss -transmits more amount of traffic
      -C&C server to coordinate numerous hosts infect with malware (bots), resulting in botnet
      -tracking true origin is significantly more difficult 
      -emanates from several location, hiding its origin
      -hacker ---- botnet ---- IP request point (multiple computers) --------> server
      -
      -DDOS attack deployed much quicker


Raspberry Pi:
-programmers can build anything with raspberry pie
-hard drive, SD card, active cooler
-choosing OS distro --> login through Ssh (ssh ankur@raspberry.local) 
-npx create-next-app@latest my-app
-cd my-app
-npm run dev
-raspberrypi.local:3000
-credit-card-sized computer run full linux-based OS, execute python, C++ code & used in electronics 
 projects, home automation, robotics, AI applications
-applications -run full linux OS ---> use raspberry Pi OS, ubuntu, kali linux
              -make retro gaming console ---> emulate games with RetroPie
              -home automation System ---> Control smart home devices (lights, cameras, sensors)
              -media centre ---> stream movies & music using Kodi or Plex
              -AI & machine learning ---> run TensorFlow & OpenCV for AI projects
              -DIY security camera system ---> use motion detection & record footage
              -weather station ---> collect temperature, humidity, air pressure data
              -web server ---> host websites using Apache or Nginx
              -personal VPN server ---> create secure network tunnel
              -robotics & IoT ---> control motors, servos, sensors for robots
              -ad-blocker (Pi-hole) ---> block ads & trackers on your entire network
              -bitcoin node ---> run full bitcoin node for decentralised finance
              -DIY smart mirror ---> display weather, time, news using one-way mirror
              -portable hacking tool ---> use kali linux for cybersecurity testing
              -automatic download server ---> automate torrents & downloads
              -AI assistant ---> build own Google assistant or alexa
              -music production ---> use FL studio or sonic Pi for audio projects
              -time lapse photography ---> capture images over time
              -automated plant watering system ---> control pump to water plants
              -car computer dashboard ---> display GPS, speed, vehicle stats
-hardware -raspberry Pi board → (Pi 4, Pi 5, Pi Zero)
          -power supply ---> 5V USB-C (for Pi 4)
          -microSD card ---> 16GB+ (for OS)
          -HDMI cable ---> for monitor connection
          -keyboard & mouse ---> for direct input
          -cooling fan/heatsinks ---> prevent overheating
-OS -Raspberry Pi OS (official)
    -Ubuntu for Raspberry Pi
    -Kali linux (cybersecurity)
    -RetroPie (gaming)
    -LibreELEC (media center)
-sudo apt update && sudo apt upgrade 
-raspi-config (open configuration menu)
-python3 myscript.py ---> run python script
-networking -SSH (control Pi remotely (ssh pi@youripaddress))
            -VNC (remote desktop connection)
            -Wi-Fi hotspot (turn Pi into router)
-LEDs & buttons ---> blink LEDs using python
-sensors ---> use temperature, motion, gas sensors
-motors ---> control servos & stepper motors


Some networks:
-internet ------> ISP modem (192.168.0.1) ------> wireless router (192.168.10.254) -------> laptops 
 (DHCP), smartphones (DHCP), printer (DHCP), CCTV camera (DHCP)
-internet ------> firewall ------> router ------> server
                                          ------> firewall ------> wireless hub ---> W01
                                                                                ---> W02
                                          ------> switch S1 -----> M01 -----> M02 -----> M03
                                          ------> switch S2 -----> M04 -----> M05
-internet ---ASDL---> firewall router ------> switch ------> mail server, file servers, PC, printers


Game development:
-using stones, touch, grasses, sticks
-barcode game -using barcode scanner as input device
-building deck game
-kingdom management game
-tower defence game
-setting design goal
-gamification -points, badges, levels, leaderboards, challenges, accelerated feedback cycle, clear 
 goals, compelling narrative, challenging but achievable tasks
-using AI in game as opponent (don't make unbeatable AI model)
-humans like having impact in environment (feeling of power & control) (reward = impact)
-increasing randomness  & fantasy --> more rewarding
-balance between challenge & players skill ---> ideal game
-handful of simple script can also make great game (movement, restart level, born enemies, enable/ 
 disable other scripts)
-1 idea --> new ideas
-battlefield, fortune wheel, VIP access (removing ads, purchase gifts, level bonus) (X days free 
 trial), settings
-mathematics is important in game development
-Pac-man (game about fear), space invader extreme, Zelda, snake, NES, mega man
-computerised D&D


DBMS vs RDBMS:
-DBMS -data are stored as file
      -relationship between 2 tables/ files are maintained programmatically
      -no support client server architecture & no support distributed architecture
      -no security of data
      -xml, file systems
-RDMBS -store tabular form
       -relationship b/w 2 tables/ files can specify at time of table creation
       -support client server architecture & distributed architecture
       -multiple level of security at logging level, command level, object level
       -mysql, Postgres, sql server, oracle


[Automation frameworks, E-bike display update]
[never open more than 6 tabs in browser]
[blackeye]


Deno2:
-


HTTP & HTTPS:
-communication between web server & client
-http requests/ responses
-loading pages form submit, Ajax calls
-every request is completely independent similar to transaction
-programming, local storage, cookies, sessions used to create enhanced user experience
-WWWL -unsecured web page
-HTTPS-WWW -secured web page
-SSl/TLS
-install certificate on web host
-GET -retrieves data from server
-POST -submit data to server
-PUT -update data already on server
-DELETE -delete data from server
-HEAD -same as get but doesn't return body
-OPTIONS -returns supported http response
-PATCH -update partial resources
-General -request URL, request method, status code, remote address, referrer policy
-Response -server, set cookie, content-type, content-length, date
-Request -cookies, accept-xxx, content-type. content-length, authorisation, user-agent, referrer
-1xx (request received/processing), 2xx (successfully received, understood, accepted), 3xx 
 (redirect), 4xx (client error), 5xx (server error)
-http -website visitor ----> plaintext data ----> plaintext data ----> plaintext data ----> web server
-https -website visitor ----> plaintext data (encryption key) ----> plaintext data ----> plaintext data 
        (decryption key)----> server


[jQuery, Axios, superagent, fetchAPI, prototype, Node HTTP]


Reason for less common TLD:
-more availability, unique, SEO
-https://news.ycombinaotr.com
-https://www.wikipedia.org
-https://www/php.net


URL:
-uniform resource locator
-https:// (protocol)
-www (sub-domain)
-example.com (domain name)
-:so (port)
-/file.html (path)
-? (query)
-key1-value1&key2-value2 (parameters)
-#00s035q (fragment)


XmlHttpRequest:
-XHR object -API in form of object
-provided by browser JS environment
-methods transfer data b/w client/server
-used with other protocol than HTTP
-work with data other than XML (JSON, plain text)


-npm install (install dependencies)
-npm start (run react dev server) (http://localhost:3000)
-npm run server (run JSON server (http://localhost:5000)
-npm run build (build for production)
-npm test (starts test runner)
-npm run eject 


HTTP/2:
-major revision of http, under hood changes, respond with data, reduce latency by enabling full 
 request & response multiplexing
-fast, efficient, secure


PostCSS:
-tool for transforming css with javascript plugins
-automate css task, used with many popular front-end tooling software (Next.js, Vice, Web pack)
-no external compiler needed, build in part of project structure
-take input CSS & convert into AST (abstract syntax tree0 & parses css strings as JS object
-API allows JS plugins to access & update properties, providing different output file
-anyone can create postCSS plugins if good with javascript & css
-css --> parser --> plugin1 --> plugin2 --> signifier --> new css


Javascript:
-high level, interpreted programming language of browser, scripting language, polymorphism
-encapsulation, inheritance
-Firefox -- spider-monkey, chrome -- V8, edge -- chakra
-conforms to ECMASscript specification
-multi-paradigm
-typescript is JS with static typing
-runs on client/browser as well as on server 
-build very interactive user interfaces with react
-used in building building fast server side & full stack application
-used in mobile development (react native, native script, ionic)
-used in desktop application development (electron JS)
-DOM selection, DOM manipulation, events, basic form validation, OOP (prototypes & classes)


Ajax:
-asynchronous javascript & XML, set of web technologies, send & receive data asynchronously, no 	
 interfere with current web page
-JSON has replaced XML for most parts


Static vs dynamic website:
-static -html, Js, css
        -easy to build, cheap to host, fixed content
        -server-------client
        -brochure site, B2B marketing sites, non-profit sites, blogs
-dynamic -html, Js, css, mysql, php
         -little hard to build, costly than static website to host, easily edit content
         -server-------database server-------client
         -e-commerce stores, membership site, learning management system


Website file (html, css, Js)----> web host (Mysql + RDBMs) (server) (OS, http, http server + SSPL + dbms)----> internet ----> website visitor            


MySQL ----> SQL based RDBMS ----> web database          


How fast computer can be:
-bremermann's limit -1.3564 * 10^(50) bits/s/kg
-135 trillion trillion trillion trillion
-1.4 * 10^(103) bits/s  


System design:
-basics -define problem -what are you building? (social network, messaging app, marketplace)
                        -functional requirements (newsfeed, likes, real-time messaging)
                        -non-functional requirements (scalability, reliability, low latency)
        -key metrics -requests/ second (RPS), latency requirements, storage requirements (data size, 
                      growth rate)
-high-level design -break system into components -twitter -frontend: web/mobile UI
                                                 -backend -user service, tweet service, feed service
                                                 -database -for user data, tweets, timelines
                                                 -cache -for frequently accessed data (recent tweets)
-draw block diagram -use simple boxes to represent components & arrows to represent interactions
-scaling techniques -vertical scaling -increase resources (CPU, RAM) of single server
                    -horizontal Scaling -add more servers & distribute load
-database design -relational database (SQL) -use for structured data (user profiles, relationships)
                                            -MySQL, PostgreSQL
                 -NoSQL database -use for scalability & high write volumes
                                 -types -key-value store -Redis, dynamoDB (caching, sessions)
                                        -document store -mongoDB (user settings)
                                        -columnar store -Cassandra (logs, time-series data)
                                        -graph database -Neo4j (social networks)
-caching -reduce latency & database load
         -types of caches -write-through cache -data written to cache & database
                          -write-back cache -data written to cache 1st & flushed to database later
         -where to cache -CDN (content delivery network), for static content (images, videos)
                         -application cache frequently accessed data (Redis, Memcached)
-load balancing -distribute traffic among multiple servers
                -algorithms -round robin, least connections, IP Hashing
                -tools -Nginx, HAProxy, AWS elastic load balancer
-API design -RESTful API -use HTTP methods (GET, POST, PUT, DELETE)
            -GET /users/{id} ---> Fetch user info
            -POST /tweets ---> Create a new tweet
            -GraphQL -flexible querying, ideal for reducing over-fetching or under-fetching of data
-asynchronous communication -use for time-consuming tasks & background processing
                            -message queues -RabbitMQ, Kafka, AWS SQS
                            -task queue -Celery (Python), Sidekiq (Ruby)
-monitoring & logging -CPU, memory usage, RPS, latency
                      -tools -Prometheus, Grafana, Datadog
                      -logging -centralised log aggregation using ELK (Elasticsearch, Logstash, Kibana) 
                               or Fluentd
-security -authentication -OAuth, JWT, API keys
          -encryption -HTTPS, encrypt sensitive data at rest (AES) & in transit (TLS)
          -rate limiting -protect against DDoS attacks & abuse
          -firewalls -use WAF (web application firewall) for protection
-content delivery network (CDN) -use CDNs like Cloud-flare, Akamai, AWS CloudFront to cache static 
                                 assets closer to users
-partitioning (sharding) -split databases to distribute data across multiple servers
                         -user IDs 1–1000 on DB1, 1001–2000 on DB2
-design patterns -rate limiter -limit number of requests per second from client
                 -circuit breaker -stop cascading failures in micro-services
                 -retry logic -automatically retry failed requests
                 -event sourcing -store sequence of events instead of current state
-tools & technologies -frontend -React, Angular, Vue.js
                      -backend -Node.js, Django, Spring Boot
                      -databases -MySQL, PostgreSQL, MongoDB, Cassandra
                      -caching -sRedis, Memcached
                      -cloud: AWS, GCP, Azure
                      -orchestration -kubernetes, docker
-interview-style steps for any system 
              -clarify requirements -functional ("How many users will post tweets?")
                                    -non-functional ("What’s expected latency?")
              -high-level design -draw an architecture diagram
                                 -identify key components & their interactions
              -scale & reliability -estimate traffic (RPS, data storage, bandwidth)
                                   -discuss scaling strategies (horizontal/vertical scaling, sharding)
              -deep dive into key components -focus on most critical parts (feed generation for 
                                              Twitter, real-time chat for WhatsApp)
              -think about stradeoffs -consistency vs availability
                                     -latency vs throughput


Directory vs folder:
-directory -contains hold folders & files
           -occupy space, almost 4KB/4096 bytes in size
           -operations include creation, deletion, opening, closing, reading renaming, linking, 
            unlinking
           -organise data in different level
           -can store files, subdirectories, other directories, provides high accessibility for user
-folder -serves as holding place for collection of documents arranged under same header
        -don't occupy any memory space on computer
        -no specific size
        -users have ability to make share, rename, movie, delete folders
        -organise data in single level
        -better suited for organising small amount of data
        -store subfolders & files, provides high accessibility for users


MAC address vs IP address:
-MAC address -48 bit hexadecimal address, works at OSI layer 2 (link layer), physical address, 
              fixed, assigned  
              by manufacturer, 00:F5:09:56:E8
             -helps to solve IP address issues
             -media access control, identifies physical address of computer on internet
             -assigned in NIC card, ARP protocol can retrieve MAC address of device
-IP address -32 bit address, works at OSI layer 3 (network layer), logical address, can change 
             depending on network environment, 150.60.122.98
            -reverse address resolution protocol helps to retrieve IP address
            -IPv4 is 32 bit address & IPv6 is 128 bits address
            -assigned by network administrator or ISP
            -RARP protocol can retrieve IP address of device


Hacking:
-web interface for router (device connected with stranger) --> something wrong
-Instagram & linked-in are great way to get information about someone
-90% of penetration tests are recon, reconnaissance is finding out everything about target,  
 checking websites, look for technology & location/blueprints --> probe/ scan target to compromise 
 --> run code --> download data --> send it


Vector vs Raster:
-vector -scalable without quality loss, convertible to raster, mathematical shapes (EPS, AI, SVG, PDF, 
         PSD, CGM, CDR, ), multiple reference points & curves, resolution independent, logos, icons
-raster -pixels, loses quality when scaled, non convertible to vector, resolution dependent (BMP, JPG,  
         GIF, PNG, PCX, TIFF, RAW, PSD)
-image colour format -CMYK (cyan, magenta, yellow, key (black), RGB (red, green, blue)


Colors:
-RGB (0->255, 0->255, 0->255)
-256 intensities per colour channel
-red, green, blue
-hexadecimal (40EODO)
-binary (R:01001111, G:01001111, B:01001111)
-black (0,0,0), white (255,255,255), green (0,255,0), red (255,0,0), blue (0,0,255)


File format:
-document file formats
-.DOC / .DOCX	Microsoft Word document	Word processing, reports, resumes
-.PDF	Portable Document Format	Readable, printable, non-editable files
-.TXT	Plain text file	Notes, logs, configurations
-.RTF	Rich Text Format	Cross-platform formatted text
-.ODT	OpenDocument Text	Open-source document format (LibreOffice)
-.MD	Markdown file	Readme files, documentation, web formatting
-.CSV	Comma-separated values	Data exchange, spreadsheets, databases
-.XLS / .XLSX	Microsoft Excel spreadsheet	Data analysis, financial reports
-.ODS	OpenDocument Spreadsheet	Open-source alternative to Excel
-.PPT / .PPTX	Microsoft PowerPoint presentation	Slides, business presentations
-.PDF/A	Archival version of PDF	Long-term digital document storage
-image File Formats
.JPG / .JPEG	Compressed image	Photos, web images (lossy compression)
.PNG	Lossless image	Transparent backgrounds, high-quality images
.GIF	Animated or static image	Simple animations, memes
.BMP	Bitmap image	High-quality uncompressed images
.TIFF	Tagged Image File Format	High-resolution images, professional printing
.SVG	Scalable Vector Graphics	Logos, illustrations, icons (scalable)
.WEBP	Google’s web image format	Faster loading web images
.HEIC	High Efficiency Image Coding	Apple’s default image format (iPhones)
.ICO	Icon file	Favicons, app icons
3️⃣ Video File Formats
Format	Description	Use Cases
.MP4	MPEG-4 video	Web, streaming, mobile (most common)
.AVI	Audio Video Interleave	High-quality videos, larger file size
.MKV	Matroska video file	High-quality videos, subtitles support
.MOV	Apple QuickTime format	Professional video editing
.WMV	Windows Media Video	Windows media playback
.FLV	Flash Video	Older web video format (deprecated)
.WEBM	Web-optimized video	HTML5, YouTube videos
.3GP	Mobile video format	Older mobile phones
.MPEG / .MPG	MPEG video file	DVD, digital TV broadcasts
4️⃣ Audio File Formats
Format	Description	Use Cases
.MP3	Compressed audio	Music, podcasts, most common audio format
.WAV	Uncompressed high-quality audio	Studio recording, sound editing
.FLAC	Lossless audio format	High-fidelity audio
.AAC	Advanced Audio Codec	Apple Music, better compression than MP3
.OGG	Open-source audio format	Alternative to MP3 (Spotify uses this)
.M4A	Apple audio format	iTunes music, ringtones
.WMA	Windows Media Audio	Windows proprietary audio format
.AIFF	Audio Interchange File Format	Mac-based high-quality audio
5️⃣ Archive & Compression Formats
Format	Description	Use Cases
.ZIP	Compressed archive	Reducing file size, multiple files in one
.RAR	Proprietary compressed archive	More efficient than ZIP, password protection
.7Z	7-Zip compressed file	High compression ratio
.TAR	Linux archive format	Bundling files together (used with gzip)
.GZ	Gzip compressed file	Compressing files on Linux
.ISO	Disk image file	CD/DVD backups, bootable OS images
.DMG	Mac disk image file	macOS software installation
.CAB	Windows Cabinet file	Windows software installations
6️⃣ Code & Programming File Formats
Format	Description	Use Cases
.HTML / .HTM	HyperText Markup Language	Web pages, frontend development
.CSS	Cascading Style Sheets	Web styling and layouts
.JS	JavaScript	Web interactivity and scripting
.JAVA	Java source code	Java programming
.PY	Python script	Python programming
.C / .CPP	C / C++ source code	Low-level and system programming
.H	C/C++ header file	Declaring functions and classes
.PHP	PHP script	Backend web development
.RB	Ruby script	Ruby programming
.GO	Go language file	Backend and concurrent programming
.R	R script	Data science, statistics
.SQL	Structured Query Language	Database queries
.JSON	JavaScript Object Notation	Data exchange between web servers
.XML	Extensible Markup Language	Configuration files, data exchange
7️⃣ Database File Formats
Format	Description	Use Cases
.DB	Generic database file	Application data storage
.SQLITE	SQLite database	Lightweight database storage
.MDB / .ACCDB	Microsoft Access database	Windows-based database management
.CSV	Comma-separated values	Data exchange between programs
.JSON	Data-interchange format	Web APIs, storing structured data
8️⃣ 3D Modeling & CAD Formats
Format	Description	Use Cases
.DWG	AutoCAD drawing	Engineering, architectural designs
.DXF	Drawing Exchange Format	CAD file sharing
.STL	3D Printing format	Used in 3D printing
.OBJ	3D model file	3D animation and gaming
.FBX	Autodesk 3D model format	Game development, animations
9️⃣ Executable & System File Formats
Format	Description	Use Cases
.EXE	Windows executable file	Running software on Windows
.APP	macOS application file	macOS software execution
.BAT	Windows batch script	Automating Windows tasks
.SH	Shell script	Linux/macOS scripting
.DLL	Windows Dynamic Link Library	Shared system libraries
.SYS	Windows system file	Core OS functions
.ISO	Disk image file	OS installation media
.VHD / .VHDX	Virtual Hard Disk	Virtual machine storage
🔹 Bonus: Web Development Formats
Format	Description	Use Cases
.HTML	Webpage structure	Frontend web development
.CSS	Web styling	Styling web pages
.JS	JavaScript code	Adding interactivity
.PHP	Server-side scripting	Dynamic web content
.ASP / .ASPX	Microsoft web page file	Microsoft web applications
.EJS	Embedded JavaScript Templates	Server-side rendering



IP address:
-ban from accessing certain websites
-restrict your geological
-show personalised ads
-track your online activity
-execute DDoS attack
-find & use personal information
-impersonate to commit illegal activities


-output --> [CPU & memory] --> input
-CPU calculates how to display pixel by pixel
-keyboard converts letter --> binary
-all computer do same thing (input --> store --> process --> output)
-anything to do with technology requires lots of information to be processed extremely quickly
-electricity speed = light speed
-modern circuits can perform billions of calculations per second


Hardware vs software:
-hardware -physical component of computer 
          -wears out of time, tangible
          -keyboard, mouse, monitor, RAM, ROM, CPU
-software -set of instructions written using various programming language help control hardware
          -doesn't ware out of time (affect by bugs & glitches), tangible 
          -windows, powerpoint, excel


SSL vs SSH:
-SSL -secure socket layer, port 443
     -for encryption communication b/w browser & server, protect data sharing by expensive/ cheap 
      certificates
     -widely used by e-commerce, banking, social media, government, healthcare, industries
     -via public key/ private key pair (PKI) public key infrastructure
     -works based on certificates
-SSH -secure shell, port 22
     -for encryption communication b/w 2 computer
     -widely adopted by networking industry
     -public key/ private key pair, user ID password pair (PKI) public key infrastructure
     -works based on network tunnels


Input & output devices:
-input -mouse, keyboard, joystick, trackpad, light pen, scanner, bar code scanner, QR code scanner, 
        mic, stylus
       -connected to accept data from users
       -translate user friendly inputs to machine understandable inputs
-output -printer, monitor, speaker, headphone, GPS, braille reader, projector, plotter, sound card, 
         video card
        -connected to provide information to users
        -translates machine friendly outputs to user understandable outputs
-both -CD/DVD, pen drives, touch screen, digital camera, modem, fax, modem, webcam


Super computing vs high performance computing:
-SC -processing of extremely complex/ data intensive problem by using SC
    -solve by concentrating combined resources of multiple computers working in ||
    -fast, highest operational rate of computer
    -weather forecasting, aerospace engineering crash & safety, modelling, quantum physics, 
     physical simulations, oil & gas exploration
-high performance -recent version super computer
                  -both administration & parallel computational technique to develop || processing 
                   algorithm & systems
                  -superior performance as compared to typical desktop computer
                  -include structural analysis, computational fluid dynamics, oil exploration, 
                   atmospheric science, defines apps


Google search:
-search_term -word
-site:website.com search_term
-filetype:extension search_term
-term1 OR term2
-related:website.com
-search term after:YYYY before:YYYY
-search term *
-define:word
-intitle:search term
-inurl:search term
-search term $X..$Y
-cache:website.com
-search term location:place
-site:.edu search term
-search term number1..number2
-~search term
-link:website.com
-search term before:YYYY-MM-DD after:YYYY-MM-DD
-search term _
-calculation expression (56 * 43)
-weather city
-time city
-stock:stock symbol
-flight airline flight number
-translate word to language
-compare item1 vs item2
-movie:movie name
-search term filetype:doc
-author:author name


Structured vs unstructured data:
-structured data -information highly organised, factual & to-point
                 -product IDs, pricing data, customer account data
                 -patient forms, medical insurance, medical billing data
                 -financial transactions, customer account data
                 -stored in rows & columns, database, text, dates & boolean data
                 -accumulates at much slower pace
                 -easier to manage & less storage space, easily analysed using tools (excel & SQL)
                 -several formats, not flexible
                 -RDBMS, CRM, OLAP, OLTP
                 -business analysts, software engineers, marketing analyst
                 -quantitative, data warehouse, relational database, sever predetermined formats
-unstructured data -no predefined structure 
                   -NoSQL DBMS non relational, AL driven tools, data storage, architecture, data 
                    visualisation tools
                   -customer behaviour, spending patterns, reviews, social media mentions, X-ray & MRI 
                    scans, doctor notes, treatment, call logs, weblogs
                   -more storage device needed, mangoDB, NoSQL
                   -consists of text, image, mails, audio, video files
                   -huge variety of formats
                   -data scientist, engineers, analysts with deep expertise
                   -qualitative, data lakes, non-relational database, huge array of formats


[traffic indicates growth --> more traffic --> more resources --> optimising their host --> using 
 scalable hosting --> maintaining databases --> constantly updates & clean databases --> cache 
 their content --> using content delivering networks]
[godaddy.com, domains.google, namecheap.com, get.tech, bluehost, hostinger, dreamhost, hostgator]


Client side & server side:
-client side -frontend, collect user input, client side scripts mostly, deals with visual & user 	
 	      input aspect, script may derestricted to run in sandbox
	     -html, css, react, angular, javascript, bootstrap
-server side -backend, processes user input, server side scripts mostly, deals with transactions & 	
 	      complex computations, processes are transparent to users
	     -php, Node.js, python, mysql, mongoDB
-Client system <----response/request----> server <----database five response to server/ server 
 check in database----> database (check for validation & availability)


General things:
-penetration testing -company hiring hacker or security professional to test their security by 	
		     breaking in website, building itself/ even international network devices to 	
		     validate their security
-firmware -software built into hardware, cannot be changed or upgrade
-web1 & 2 data stored centrally on developer/ companies server
-web3 -data distributed over multiple servers creating collective ownership & verification of data
-computer memory -bunch of switches (transistors), turned on/off in patterns represent information
                 -capacitor -type of hardware, hold some electricity from switches & create memory
-our data is not worth much by itself, hackers open lines of credit, get passports & create 	
 identities to sell criminal
-certain vulnerabilities can happen by just having reading page open, receiving SMS message can 
 compromise your machine
-using more digits is less efficient & binary is simpler to implement & more resistant to errors
-internet is built upon layers of ideas (at lowest layer 0s & 1s)
-microchips are on logic/motherboard that has many ports (audio, networking, USB), ports connect to 
 different chips (traces & tiny wires), interpret signals from these ports, some perform operations  
 & some store information
-


Keyboards:
-membrane -cheapest, plastic, polyester, silicon, rubber
          -rubbery press, less noisy, less durable
-mechanical -accuracy, feel, precision, speed are in our control
            -little expensive, louder, more customisable, highly durable
-optical -use light induction to trigger switch
         -light is blocked ---> key is registered
         -fastest, expensive, louder, less customisable


Connecting wires:
-thunderbolt -high speed technology interface that outputs 1 serial signal from combination of PCI 	
	      express & display port
             -can daisy chain upto 6 devices
             -version 1&2 uses mini display port & version 3 uses USB type-C
-displayPort -royalty free
             -max resolution of 8K at 60Hz
             -has locking mechanism that keeps cable locked in place
             -has multi-monitor capability
             -allows use of multiple monitor in daisy chain configuration
             -high performance interface
             -can be connected to older ports by using adapters
             -developed by VESA (video electronic standard association)
             -used in video
             -used to carry to Usb & audio data
-HDMI -higher resolution & refresh rates
      -4K video at 120Hz
      -8K video at 60Hz
      -10K video for commercial A/V systems & specialty usages
      -added network communication
      -sends & receives data at 100MB/s ethernet
      -4K video at 30Hz
      -high definition multimedia interface
      -has broad range of use in electronic
      -designed for transmitting uncompressed video & audio through single cable
-DVI -dual link DVI has max resolution of 2560x1600
     -single link DVI has max resolution of 1920x1200
     -digital visual interaces
     -succeeded VGA port
     -designed to provide uncompressed, high quality video to LCD monitor
     -DVI-A (used to send analog signals only)
     -DVI-D (used to send digital signals only
     -DIV-I (used to send both analog & digital signals)
-VGA -video graphics array
     -older technology 
     -has 15 pins (divided into 3 rows)
     -only carries analog data
     -end adapter will typically have blue colour
     -used in CRT monitors


Connectors:
-RJ-11 -registered jack, 4 wire connector used to connect telephone equipment
       -connects to computer modems on computer
       -hinged locking tab locks itself in place 
       -resembles RJ-45 but smaller 
-RJ-45 -8 wire connector 
       -connect computer to LAN, uses twisting pair cabling, uses to connect network interface card
        to hubs & switches
-RJ-48c -used with shielded twisted pair cables
        -used with T1 lines
        -wired differently than RJ-45
-UTP coupler -connecting UTP cables with RJ-45 connectors to each other
             -used with running longer cable is not option
             -----------UTP coupler---------- (used for extending cables)
-BNC cable -common type of RF connector used on coaxial cable
           -bayonet Neill councilman
           -used for both analog & digital video & audio
-BNC coupler -connect together 2 coaxial cables with BNC connector
             -BNC female to female coupler 
-fibre coupler -connect 2 of same fibre optic connector 
               -2 connectors have be same time
               -not to be confused with finer adapter
-F-type -provided by cable provider to connectable modems
        -screw on connector used on coaxial cable 
        -hand tightens by attached nuts
-USB -Universal Serial Bus 
     -many manufactures make wireless network card to plug into USB port
     -2 different connectors type (A & B)
     -extremely common in desktop & laptop 
-IEEE 1394 -firewire, commonly associated with peripheral devices digital camera & printers than 
            network connection
-MT-RJ -mechanical transfer register jack
       -fibre optic cable connector, uses latched push-pull connector 
       -small form factor for high packed density
-ST -straight tipped, half-twist bayonet type of lock
    -used with single mode fibre optic cable
-LC -local connection
    -used jack similar to RJ-45, commonly used in floors & building
-SC -standard connector
    -uses push-pull connector similar to audio & video plugs
    -commonly used in floors & buildings
-RS-232 -sending data 1 bit at time
        -has D shaped connector, most common forms are DB-9, DB-25
        -carries serial data transmission 


Connectors:
-power cables -AC power cables -connects appliances & devices to wall outlets (type A,B,C power cords)
              -USB power cables -deliver power over USB ports for charging devices (USB-C, Micro-USB)
              -DC power cables -direct current (DC) power, for electronics with external power adapters
              -figure-8 power cable (C7) -devices like DVD players & some laptops
              -3-prong power cable (C13/C14) -desktops & monitors
              -2-prong power cable (C5/C6) -laptops
-data cables -ethernet cable (Cat5e, Cat6, Cat6a, Cat7, Cat8) -used for wired network connections
             -USB cables -various types for connecting peripherals & transferring data
             -USB-A to USB-B -printer cables, older devices
             -USB-C -modern standard for data, video, power
             -Micro-USB & mini-USB -smaller, older USB types used in portable devices
             -lightning cable: Apple’s proprietary cable for iPhones, iPads, iPods
             -SATA cable -used inside computers to connect hard drives & SSDs to motherboard
             -eSATA cable -external version of SATA for external hard drives
             -firewire (IEEE 1394) -used in older computers & camcorders for data transfer
             -thunderbolt -high-speed for data transfer, video, power, compatible with USB-C  
             -fibre optic cable -used for very high-speed data transmission in internet connections
             -RS-232 serial cable -older cable for connecting to serial ports on routers, modems
-video cables -HDMI -most common video & audio cable for TVs, monitors, and projectors
              -display-port -video cable similar to HDMI used in computers & gaming monitors
              -mini display-port -smaller version of DisplayPort used in some laptops
              -DVI -older video connection for monitors, supports both analog & digital video
              -VGA -analog video cable for older monitors & projectors
              -composite video (RCA) -old standard with yellow (video) & red/white (audio) connectors
              -component video (RGB) -video-only cable with red, green, blue connectors for higher-
                                      quality analog video
              -S-video -analog video cable, mainly used in older TVs & video equipment
-audio cables -3.5mm -standard for headphones, microphones & speakers
              -6.35mm (¼-inch) -audio equipment like musical instruments
              -RCA -red & white connectors for left & right audio channels
              -optical audio -digital audio cable, common for high-quality audio b/w TVs, sound systems
              -XLR -professional cable for microphones & balanced audio equipment
              -MIDI -connect musical instruments & other MIDI-compatible devices
              -TRS -sleeve ring tip, TRRS -sleeve, ring, ring, tip
-combination cables (audio/ video) -HDMI -supports both audio & video
                                   -display-port -supports both audio/ video, for computer monitors
                                   -USB-C -carry data, power, video, audio in single cable
-peripheral cables -printer cable (USB-A to USB-B) -common for connecting printers
                   -PS/2 cable -older cable type to connects keyboards & mice
                   -serial cable -older devices for data transmission (RS-232 standard)
                   -parallel cable -legacy cable for connecting printers & other devices
-storage & internal cable -SATA & eSATA -connecting storage devices inside computers
                          -IDE -older cable connect hard drives & optical drives in older computers
                          -NVMe/M.2 -internal connectors for high-speed SSDs
                          -SCSI -older servers for connecting multiple hard drives
-specialty cables -KVM -connects keyboard, video, mouse to KVM switch, lets users control multiple 
                        computers with 1 setup
                  -coaxial -cable TV & internet
                  -BNC -professional video & surveillance equipment
                  -antenna -connecting an antenna to TV, radio
                  -splitter -splits signal into 2 outputs (audio, HDMI)


APC vs UPC connector:
-when 2 UPC wire connects connection is imperfect & light not able to pass properly & reflects back
 leads to signal loss
-APC solves this issue, difference is in angel of tip 


Optimisation & fault tolerance:
-bandwidth shaper -control network traffic, setting up upload & download limit on less important 
                   data (recreation)
-traffic shaper -similar to bandwidth shaper
                -prioritise apps & guarantees bandwidth for more important services
-load balancer -piece of hardware/ software to evenly distribute data activity across network, no 
                single server/ computer becomes overwhelmed


Authentication protocol:
-PAP -password authentication protocol
     -login & password are in sent in clear text
     -not very safe & compatible with everything
-CHAP -challenge hack-shaked protocol
      -better than PAP
      -client validation done by 3 way handshake
      -encrypted username & password
      -client gives 1 way hash function in response
-MS-CHAP -Microsoft version of chap 
         -MS-CHAP basic chap & MS-CHAP 2 both client & servers are authenticated
         -more secure
-radius -enables single server, domain controller to handle all authentications
        -allows companies to store user access data in central location
        -radius server makes request on user behalf after authentication
-EAP -extensible authentication protocol
     -extension to PPP (point to point protocol)
     -supports many methods of authentication
     -associated with smart cards
-Kerberos -authentication by ticket
          -authenticate with kerberos server -----> client is issued ticket & gives client network 
           resources


API:
-application program interface
-apis are everywhere
-contract provided by 1 piece of software to another
-structured request & response


Vertical vs horizontal scaling:
-vertical -+CPU, +RAM, +SSD ---> increase power of single server
-horizontal -deploying new server


Distributed computing -search engines have 100s/1000s of more server around world
                      -each server spread out across multiples servers removing bottlenecks


Rest:
-representation state transfer
-architecture style for designing network applications
-relies on stateless, client-server protocol, almost always http
-treats server objects as resources that can be created or destroyed
-used by virtually any programming language


Operating system vs firmware:
-OS -interface between hardware & application running on computer systems
    -execute user programs & control computer resources like disk, memory, keyboard, printer
    -stored onto disk
    -written in C++ & python 
    -handle high level operations like providing GUI interface to end user, multitasking
    -installed or changed by user
-firmware -piece of code embedded in any device 
          -permanent instructions to communicate 
          -stored in ROM/ flash memory (non-volatile memory)
          -written in C or assembly langue
          -cannot be changed
          -BIOS


[FreeBSD, Solaris, Sun cobalt, Red-hat, Linux]
[digitalocean, Linode, Netlify, versel]
[sPlan]
[haveibeenpwned]
[kakoune]


Python:
-simple to write & read
-versatile coding language
-code runs smoothly on variety of operating platforms
-certain speed difficulties, uses more memory, python layer for dealing with databases can be 
 improved, limited support for mobile app
-flash, django, web2py, dash, cubic web, AIOHTTP, cherrypy, giotto, bottle


React Native:
-JS library/framework for creating UIs
-react is agnostic, react-DOM & used to render in browser
-compile react components into native components/widgets
-allows to use react to create native IOS & android applications (single codebase)
-requirements -Mac -IOS/android, windows -android
              -android studio/ SDK/ emulator (AVD)
-components -flat-view, sectionalist, action sheet IOS, alertIOS, backhander, date picker android


UI/UX:
-UX -physical & digital product, psychology, strategy, mental models
    -fully experience from user 1st contract to last
    -information architect, user research, interactive design, wireframe & prototype 
    -structural design solutions fro pain points that users encounter anywhere along their journey 
     with product
    -delight users with their effectiveness
-UI -application -digital products only, prototyping
    -visual design, colours, graphic design, layout, typography
    -visual touchpoint allows users to interact with product
    -combinations of typography, colour palette, buttons, animations, imagery
    -product that delight users aesthetically


Statically vs dynamic typed:
-statically -perform tap checking at compile time, errors shown in compile time
            -provides more control
            -static variable -global/static area
            -FIFO, size must known at compile time
            -assigned to stack
            -explicitly allocates memory
            -explicitly define your data types
            -string, int, float
-dynamic -type checking is done at run-time, perform type checking at runtime
         -dynamic variable -stack area, for local variable in subprogram
         -size is not known
         -no particular order
         -implicitly allocates memory
         -assigned to heap
         -assumes data type automatically
         -less code but also more prone to errors at runtime


DPU vs GPU vs CPU vs TPU:
-DPU -offload functions & data manipulation, very low power, very high storage efficiency, low cost
     -multi core MIMD + tightly coupled accelerators high throughput for multiplexed workloads true 
      fabric enables disaggregation & pooling specialised memory, storage, security, 
      virtualisation, data centric, computations run > 10X more efficiently
-CPU -user application (generation compatibility), high power, low storage efficiency, high cost,  
      multi-core, MIMD, high IPC for single threads, ideal for low to medium I/O, fine grain memory 
      sharing classical cache coherency
-GPU -paralleled compute processing, very high power, low storage efficiency, very high cost, 
      multi-core, SIMD, ideas for graphics, ML training
     -high throughput for vector processing coarse-gain memory sharing relaxed  coherency, based on 
      data
-TPU -


Dedicated vs integrated GPU:
-dedicated -gaming on 1440p or 4K resolution
           -good for high frame rates (FPS)
           -more expensive, uses separate PCB & uses dedicated VRAM
           -high performance, consumes more power, dissipates more heat
           -use its own RAM, cooling system, power supply
-integrated -only for 60FPS & 1080p in games 
            -less expensive
            -does not use its own memory & shares its resources with CPU
            -low performance, consumes less power, dissipates minimum heat


[Rows (records) runs horizontally & column (field) runs vertically]


Static & dynamic data structure:
Static -memory allocated -static variables are allocated memory at program start rather than at 
        runtime like dynamic variables
       -fixed memory size, easier to access element in static data structure
       -provides easier access to element through index
       -not flexible
       -in array
-dynamic -dynamic variables ...........
         -no easier access
         -data elements not placed sequentially of linearly (non-linear data structure)
         -created Y& destroyed at runtime (more flexible in managing memory)
         -linked list data structure, size of list can changes as elements are added or removed 
         -initialised in any value at any time, gives developer control over value


React.Js:
-JavaScript library for building user interfaces (UIs)
-uses component-based architecture
-uses Virtual DOM for faster rendering
-can build single-page applications (SPAs) and mobile apps (with React Native)
-every segment in browser is component (button, box, section)
-reusing component reducing code lines (using same images, card, text component)
-installation -npx create-react-app my-app
              -cd my-app
              -npm start
-project structure -public/ ---> static assets (images, icons, etc.)
                   -src/ ---> main react components & logic
                   -App.js ---> main application component
                   -index.js ---> entry point for rendering react app



Security:
-recover you account & change password
-check banks balance & PayPal on regular basis
-back up important files on flash drive
-data breach & data leak
-remote access trojan (RAT)
-man in middle attack
-hashing (plain text ---> hash function ---> hash text ---> database)
-types of hashing algorithm (MD6, tiger, CRC32, SHA-1, SHA-256, MD5, ripeMD128, Ddler32)
-salting (123456 ---> 1abc2abc3abc4abc5abc6) (salt = abc)
-brute force attack (attacker ---> guess list of username & password ---> repeat login attempt  
 until successful ---> successfully credential validation)
-dictionary attack (lots of password & their hash)
-letters + number + special character = strong password


Data types:
-primitive -numeric -integer -byte, short, long, int
                    -floating point -double, float
           -non-numeric -character, boolean
-non-primitive -string
               -arrays
               -user defined classes


Data type vs data structures:
-data type -


Symptoms of device being infected by computer virus:
-low performance
-freeze-ups & crashes
-missing files
-new files appear
-problems with hardware
-computer operating by itself


MERN vs MEAN:
-Mean -manages files & abstraction in coding
      -managing & upgrading code
      -offers better productivity
      -offers various ready to use features
      -data flow bidirectional
      -size of project is small
      -not in mobile app
      -focus on performance is medium
      -focus on defect prevention is high
-Mern -help to code faster
      -facilitates smooth UI rendering
      -offers low productivity
      -needs additional libraries for supporting similar requests
      -data flow unidirectional
      -size of project is large
      -mobile app
      -focus on performance is high
      -focus on defect prevention is medium


HTTP vs HTTPS:
-http -hypertext transfer protocol
      -works at application layer
      -default port number is 80 for communication
      -no encryption is present in http websites
-https -hypertext transfer protocol secure
       -works at transport layer
       -default port number is 443
       -both encryption & decryption exist on https websites


MERN stack:
-html, css, javascript --> react --> node --> express --> mongoDB --> connecting & deploying 


Node.js:
-javascript runtime (not language or framework)
-build on V8 javascript engine (same as google chrome)
-written in C++
-essentially allows us to run javascript code on server
-javascript fundamentals (objects, arrays, conditionals)
-asynchronous, event-driven, non-blocking, great for real-time apps (chat apps, streaming services)
-MVC patterns, promises, arrow functions, JSON, HTTP (status codes, headers)
-fast, efficient & highly scalable
-event driven, non-blocking I/O model
-same language on front & backend
-works on single thread using non-blocking I/O calls
-supports 10s of 1000s concurrent connections
-optimises throughout & scalability in apps with many I/O operations
-single threaded. Supports concurrency via events & callbacks
-event emitter class is used to bind events & listeners
-install ---> check version -node -v, -npm -v
-node
-console.log("Ankur");
-node app.js


[Framework is collection of software modules, tools, artefact provides theoretical & technical  
 essential assistance in development of application software]


Endpoints -URI/URL where api/service can be accessed by client application 
Authentication -some APIs require authentication to use their service (paid or free)
Boot -booting is loading OS into computer main memory/ RAM


Web scraping:
-bunch of websites (unstructured data) ---> web scraping software ---> structured data in file/ 
 database (JSON, CSV, XLSX, SQL, TXT, XML)
-select website --> find data --> write script --> run bot ---> store data


Read & write binary:
-any number ----> keep dividing by 2 ----> even (0) & odd (1) -----> binary


Flowchart:
-start/stop (oval)
-input/output (parallelogram)
-processing (rectangle)
-condition (diamond)
-flow direction  (-------->)


Programming paradigms:
-imperative programming -procedural programming, object oriented, parallel processing approach
-declarative programming -logic programming, functional, database processing approach


Types of languages:
-procedural -specifies series of well-structured steps & procedure to compose program
            -complex to read, very long code, supports conditional & loop statements, switches
            -time consuming process, C, FORTAN, COBOL, PASCAL
            -researchers use because of simplicity & flexibility
            -doesn't focus on data encapsulation, user have direct access to data
            -accessors & mutators not required as no data layering
            -contains systematic order of statements, functions & commands to complete task
-functional -writing programs only in pure functions, never modifies variables, only creates new 1s 
             ones outputs
            -straightforward & easy to read, reusability of code, time saving process
            -no iteration support, C++, big data, SQL, Scala
            -used when to perform lot of different operations no same on set of data (ML)
-object oriented -revolves around objects, code + data = object 
                 -easy to develop, debug, use, maintain software
                 -data encapsulation is prime feature of this language paradigm
                 -don't have access to data, programs provide more data security
                 -mutators & accessors is needed
                 -inheritance is key component of programs used as sub-classes use properties of super-
                  class


-knowledge factor -password, security question, PIN
-possession factor -smartphone, smart card, hardware token
-inherence factor -fingerprint, retina pattern, face recognition


Benefits of 2-factor authentication:
-shrinks attack surface by reducing human error
-1st step toward zero-trust security model
-allows enterprise to embrace BYOD policies
-helps comply with industry regulation
-leverage hardware advancements in everyday life


Open journal systems (OJS) -free, open-source software, applications for managing & publishing 
                            scholarly journals
                           -flexible system can be downloaded & installed on local web server


Some computer specs:
-product name, SKU number, processor type, processor speed, cache size (L1,L2,L3), memory size (channel 
 A, channel B), integrated MAC, system BIOS, chassis serial number, asset tracking number ME firmware, 
 ME management mode
-NVIDIA GeForce GTX 1660 Ti 6GB (discrete)
-core count, thread count, base clock, total cache, TDP, socket
-fan speed (CPU fan(RPM), GPU fan(RPM), Fan acoustics(dBA))
-system configuration (win key, AC key, touch pad, panel power saver, legacy DRM compatibility)
-GPU stats (frequency(MHz), usage(%), memory frequency(MHz), temperature('C), voltage(mV), max TGP(W))
 CPU stats, FPS, render latency, fan speed, GPU power, GPU voltage
-GPU mode (ultimate, standard, eco mode, optimised)
-I5-12th Gen (R), 12500H, NVIDIA Geforce, RTX 3050 ,GDDR6 4GB (128 bits)
-I7 9700k 3.60Ghz, NVIDIA geforce RTX 2700 8GB, 16GB DDR4
-10GEN I7, 1660ti 6GB, 16GB DDR4
-HP omen 15, RTX 3060, AMD Ryzen 7
-I5 4GEN, GT710 
-RTX 3090s
-Ryzen 5600 
-IPS 240Hz, I9, 14900HX, RTX 4080 32GB, DDR5 1TB SSD
-Ryzen 5 9600x coller, 240 Elite GPU, RTX 4070 32GB
-AMD Ryzen 7 8845HS, 3.8Hz, RTX 4070 8GB, GDDR6, DDR5-5600 16GB, 1TB SSD
-Ryzen 7 7800x3D 32GB, DDR5, 600mhz B650 Aorus elite AX Ice GB 4070 super blue 1TB NVME 850W,  
 Thermaltable PSU Lian Li GA || AIO
-RTX 4070, I9 14900HX, 32GB 
-I5 12400, MSI H410 PRO VH, G.skill ripsaws 16GB, corsair 550w, crucial nvme 480GB, WD 1TB HDD,   
 chiptronex x610B
-I5 10400, MSI H410 PRO VH, G.skill ripsaws 16GB, Ant Esports VS550L, 240GB SSD, chiptronex x610B
-I3 10105, MSI H410 PRO VH, G.skill ripsaws 8GB, Ant Esports VS550L, 240GB SSD, chiptronex x610B
-4k (240hz), 2k (360hz) -2560x1440 78% more than 1080p & 3840x2160 300% more than 1080p (1920x1080)


How do API works:
-web app in browser <----request/ response----> internet -----> API -----> web server -----> database
-database/backend (post, get, put, delete, custom) ----- API <-------> app


High level language (humans) source code(.java)----compiler----bytes code (.class) (cross platform,  
portable)----JVM----object code (machine code) Low level language (computer)


HLL ----> processor ---(pure HLL)---> compiler ---(relocated code)---> assembler ---(assembly)---> loader/linker ----> machine code


Hardware ---> machine learning ---> assembly language ---> C, C++ rust


Compiler vs interpreter:
-compiler -converts program -----> machine code as whole
          -create object code file
          -converts high level program that can execution many times
          -execution is fast
          -displays syntax errors after compiling whole program
          -C++, C
-interpreter -converts program -----> machine code line by line
             -no create object code file
             -convert high level programs each time execution
             -execution is slow
             -display syntax errors on each statement of program
             -ruby, perl, python, PHP
-assembler -converts program assembly language -----> machine language
           -used by assembly language


Errors in programming:
-syntax error
-runtime error
-linker error
-logical error
-semantic error 
-segmentation fault -occur when program tries to access memory locations thats not allowed
                    -use compatible version of python the all libraries are up-to-date
                    -make sure environment is clean
                    -ensure system has enough memory & resource to run application


Database server (storage, login, retrieval of data) <-----> web server (store, share html pages) 
<-----> client/web browser (viewing & interaction with html pages)


Cookies vs sessions:
-cookies -mechanism for storing data in remote browser & tracking/ identifying return users
         -set specific data to stored in browser & retrieve it when user visits site again
         -cookies are on clients, no-one should store sensitive data in them
         -accepting cookies ---> agree to storing cookies on device to enhance site navigation, analyse  
          site usage, assist in marketing efforts
-sessions -way to store information (variables) to be used across multiple pages, sessions are 
           stored on server


Loudspeaker basics:
-18 inches across speakers -makes huge thunderous sound 
-12,8,4,3
-pure audio speaker 
-audio visual system -variation of frequency where using microphone ---> modulate output signal to 
                      desired values (use LPF, HPF, amplifier) ---> distribute signal to value (ex-4 
                      ohms, 6 ohms, 8 ohms) ---> adjust gain of signal then ----> give to speaker
-visual -video signal earlier chrome signal (black & white colours) ---> improved to RGB signal
        -combination of RGB ----> produce various colours ex-VGA (analog signal) ---> HD signal, full 
         HD, ultra HD, 3D, 4k, developing 5k
-amplifier -generate audio signal to produce more power at particular impedance level 
           -collection of electronic circuit takes low-level sound signal from microphone, electronic 
            musical instrument, record, CD, audio tape, MP3, & boost enough to power speakers
-car audio operates (1-4 ohms)
-14.4VDC = 1200 wattage at 1 ohm
-14.4VDC = 600 wattage at 2 ohm
-14.4VDC = 300 wattage at 4 ohm
-subwoofer -designed to reproduce low frequencies from 20Hz upto few 100s
           -power supplied to voice coil ----> cone to vibrate & produce sound waves
           -large & specially designed enclosure helps them produce low frequency
-amplitude -height of sound wave, tells loudness
-frequency -number of sound wave cycles per second, measured hertz (Hz)
           -higher frequency --> higher pitch
-pitch -perceived frequency of sound
       -high pitch sounds are sharp, low pitch sounds are deep
-timbre -unique quality/ colour of sound, distinguishing different instruments even at same pitch
-decibel (dB) -unit to measure sound intensity/ loudness
              -0dB is threshold of hearing, sounds over 120 dB can cause pain/ damage
-echo -sound reflects off surface & returns to listener with delay, creating repeated effect
-reverb -series of reflections that blend together to create lingering sound, simulating space size or 
         material
-harmonics -frequencies at integer multiples of fundamental tone, adding richness & depth to sound
-wavelength -physical length of 1 sound wave cycle, inversely related to frequency
-envelope -shape of sound over time
-equalisation (EQ) -process of adjusting specific frequencies in sound to balance or enhance certain 
                    elements (boosting bass, treble)
-compression -reduces dynamic range by lowering loud sounds & raising quiet sounds, creating more 
              balanced volume level
-dynamic range -difference b/w loudest & softest parts of sound
-phase -position of sound wave in its cycle, phase shifts cause sounds to reinforce, cancel each other
-distortion -alteration of sound, used to add grit, edge, especially in guitars
-noise -unwanted or random sounds in recording, sometimes used for stylistic effect
-resonance -amplification of specific frequencies, typically near object’s natural vibration rate
-sample rate -number of audio samples captured per second in digital recording, affecting sound quality
-bit depth -number of bits used per audio sample, impacting dynamic range & quality of digital audio
-stereo -sound that uses 2 channels (left & right), creating sense of space & dimension
-mono -sound that uses single channel, without directional cues
-pan -positioning sound in stereo field (left, right, centre), creating spatial placement
-overtones -frequencies above fundamental tone that add richness to sound
-attack time -time taken for sound to reach its peak after being played
-decay time -time it takes for sound to reduce after initial peak
-tempo -speed at which piece of music is played, measured in beats per minute (BPM)


AutoCAD:
-every engineer should know autoCAD (mechanical, civil, electrical)
-making design, map, plan only software is used no manual work is required
-2D drafting & 3D design software by Autodesk
-CAD (computer aided design) used to create 2D & 3D design
-layers control visibility and properties of objects (colour, line type)
-workflow for 2D design -set up drawing -UNITS to set measurement units
                                        -LAYER to organise objects
                        -create geometry -basic commands like LINE, CIRCLE, RECTANGLE
                        -edit geometry -commands like TRIM, EXTEND, or OFFSET
                        -add text & dimensions -TEXT for annotations
                                               -DIMENSION to show measurements
                        -print (plot) -PLOT command to print drawings
                                      -LAYOUT for scaling & presentation
-workflow for 3D design -switch to 3D workspace -change workspace to 3D Modelling from workspace menu
                        -create 2D shapes -basic commands to create profiles (LINE, CIRCLE)
                        -convert to 3D -EXTRUDE, REVOLVE, SWEEP to turn 2D shapes into 3D objects
                        -modify 3D objects -BOOLEAN OPERATIONS (UNION, SUBTRACT, INTERSECT)
                                           -FILLET or CHAMFER to smooth edges
                        -apply materials & lighting -RENDER for realistic visualisation
-advance softwares like sketch-up, 3D max
-file formats -.dwg (working file), .dwt (template file, predefined file of any software) --> acad.dwt 
 (inches), acadiso.dwt (mm), .dxf (3D file format)
-application menu bar
-quick access toolbar
-workspace (drafting & annotation, 3D basic, 3D modelling), share, title bar, search bar, info bar
-every tab has ribbon, panel, drawing tab
-model views, custom visual style
-view cube (N,S,W,E), orbit (changing direction of view in 3D)
-command prompts (where we write commands)
-layout bar (model, layer1, layer2)
-application status bar 
-x-axis & y-axis (WCS (world coordinate system)), UCI (user coordinate icon)
-units -standard of measurement (mm, feet, inches)
       -imperial & metric units
-commands -UN ----> dialogue box (engineering, architecture...)
          -L (line) ----> enter (0,0), (10,0), (10,10), (0,10) to create square
                    -shift --> straight line
          -DS (drafting setting) ----> grid, isometric, 
-coordinate system -absolute coordinate system -(+x & +y ---> add, -x & -y ---> subtract)
                                               -points are measured relative to origin (0,0)
                   -relative rectangular coordinate system -(+x & +y --> +symbol, -x & -y --> -symbol)
                                                           -formula = @x,y
                                                           -points measured relative to last point 
                                                            created
                   -relative polar coordinate system (0,90,180,270, no addition & subtraction, only 
                    directions & angle) formula = -@x or y < angle
-giving dimensions
-drag & select object ----> right click ----> move
-

-


AutoCAD commands:
-L -line
-PL -polyline
-REC -rectangle
-C -circle
-ARC -arc
-ELLIPSE	 -ellipse
-SPLINE	-creates smooth curve
-editing commands
-MOVE -moves objects
-COPY -copies objects
-ROTATE -rotates objects
-SCALE -scales objects
-MIRROR	-creates mirrored copy
-OFFSET -creates parallel copies
-TRIM -trims objects to boundary
-EXTEND	-extends objects to boundary
-FILLET	-rounds corners
-CHAMFER	 -bevels corners
-layer & properties
-LA -layer properties manager
-LAYER -creates and manages layers
-MA -match properties
-CHPROP -modify object properties
-selection & object manipulation
-ERASE -deletes objects
-EXPLODE	 -breaks block into separate objects
-GROUP -groups objects together
-UNGROUP	 -ungroups objects
-SELECTALL -selects all objects
-dimensioning & text
-DIM -creates dimensions
-DIMALIGNED -creates aligned dimensions
-DIMLINEAR -creates linear dimensions
-TEXT -adds text
-MTEXT -creates multi-line text
-blocks & references
-B -creates a block
-INSERT	-inserts a block
-ATTDEF	-defines block attributes
-REFEDIT	 -edits block in place
-WBLOCK	-writes block to external file
-view & display
-ZOOM -zooms in/out
-PAN -moves view
-REGEN -regenerates display
-VPORTS -sets up multiple viewports
-drawing utilities
-UNITS -sets drawing units
-LIMITS -sets drawing limits
-GRID -toggles grid display
-ORTHO -restricts cursor to 90° angles
-OSNAP -enables object 
-3D modeling
-EXTRUDE	 -converts 2D objects into 3D
-REVOLVE	 -creates 3D solid by rotating shape
-LOFT -creates 3D solid between multiple shapes
-UNION -combines 3D solids
-SUBTRACT -subtracts one solid from another
-INTERSECT -creates 3D solid at intersection of 2 solids
-rendering & visualisation
-RENDER	-renders drawing
-MATERIALS -opens materials manager
-LIGHT -adds lights to the drawing
-file management
-OPEN -opens drawing
-SAVE -saves current drawing
-EXPORT -exports to different formats
-IMPORT -imports files
-PLOT -prints drawing


DJ:
-all DJ equipment & tools do same thing (play & mix to appease crowd)
-2 DJ decks & mixer
-plugin Dj controller & open DJ software
-white & red output on back of controller send master volume of mix to speakers
-start mixing tracks that are similar in BPM
-deck1 & deck2
-load button
-beat grid -visual guide & series of markers point to location of beat within track
-most DJ friendly tracks have intro & outdo section
-play/pause function
-cue function -cues function
-tempo function -long fader controls BPM of song (faster/ slower)
-jog wheels -temporarily speed up & down song (push/ pull from their side)
-mixer section -blending & mixing songs
-volume fader area 
-cross fader section -controls volume of each deck simultaneously
-EQ section -high, mid, low knobs controls frequency of song
-low knob -controls bass of song
-mid knob -controls Acapella/ loud instrumental-like section of song
-high knob -controls Hi-hat section of song
-headphone cue section -button lets pre-hear song in each deck 


Music software (game development):
-Zoom H6 mic, boya mic
-Audacity -selecting correct microphone (mono) & output speaker 
          -recording too loud cause clipping 
          -select tool, move tool, envelop tool (adjusting volume)
          -effect --> noise reduction (get rid of noise)
          -edit --> clip boundaries --> split
          -pan left & right 
          -creating more tracks 
          -export as WAV, MP3
-layering -combining multiple sound 
-pitch shifting -effects ---> change speed
-equalisers -effects ---> filter curve (x-axis -frequency, y-axis -loudness)
-keep experimenting
-make something that is nice to listen & not irritating, boring
-using things that are available at home
-VST instruments software
-DAW (digital audio workstation) -reaper
-inserting new MIDI item 
-loop button, FX icon (opensVST instrument setting)
-music theory -piano roll is representation of piano keys
              -2 notes right next to each other = 1 semi tone
              -1 octave = 8 keys in b/w
              -C major scale = from 1 C to another only using white
-melodies are implemented by chord (white (major) = happy, black (minor) = sad)
-BPM (speed of music)
-inserting virtual instrument on new track
-B section (nice change of events in melody)
-transition
-section A, B, C, D
-file --> render


Autocad:
-CAD -computer aided design -simply, design & drafting with aid of computer
     -contains many commands & tools to create & adjust basic geometric structures fluidity
     -create 2D or 3D computer models, consists of numeric data in binary form that saved onto disk
     -large user base of auto cad world wide
-design -creating real product from idea, drafting -production of drawings used to document design
-interface -drawing area -represents piece of paper, colour of area changed using tools/ option/ 
                          display/ colour
           -crosshairs cursor -movement of cursor controlled by movement of pointing device (mouse)
                              -use cursor to locate points, makes selections & draw objects, size 
                               changed using tools/ options/ display/ crosshair size
           -command line -3 lines at bottom, screen, enter commands & auto cad will prompt to input 
                          information
           -coordinate display -lower left corner in absolute mode (coords = 1) -displays location of   
                                crosshairs/ cursor in reference to origin
                                1st number represents horizontal movement (x-axis)  
                                2nd number represents vertical movement (y-axis)
                                3rd number represents (z-axis) making 3d 
                               -relative polar mode (coords = 2) -display distance & range of cursor 
                                form last point entered (distance < angle)
           -status bar -display current settings (off & on) by clicking on word (snap, gird, ortho) by 
                        pressing keys F1, F2
                       -[snap] (F9) -increment snap control movement of cursor
                                    -off --> cursor move smoothly, on --> cursor jump in incremental 
                                    -incremental spacing changed at any time using tools/ drafting 
                                     settings/ snap & grid, default spacing is .250
                       -[grid] (F7) -grid dot merely visual drawing aid, default spacing = 1 unit
                                    -change grid spacing anytime using tools/ drafting settings/ snap
                       -[ortho] (F8) -on --> cursor movement restricted to horizontal/ vertical
                                     -off --> cursor moves freely
                       -[polar] (F10) -polar tracking creates alignment path at specific angles
                       -[osnap] (F3) -running object snap, specific object snaps set to stay active 
                                      until turn off
                       -[otrack] (F11) -object snap tracking creates alignment paths at precise 
                                        positions using object snap location
                       -[lwt] -line wight, displays width assigned to each object
                       -model -switches drawing b/w paper space & model space
           -UCS icon (super coordinate system) -lower left corner of screen, indicates location of 
                                                origin
                                              -appearance changed using view/ display/ icon/ properties
           -origin -location where x, y, z axes intersect 0,0,0
-function keys -
-drawing commands -access to large number of commands, general rule to use 20% of commands 80% of times
                  -make elaborate drawing quite quickly
                  -line -line/L, home > line, drawing straight line segment form 1 point to next
                  -circle -circle/C, home > circle > centre, radius, draw circle based on centre point 
                           & radius
                  -erase -erase/ E, home > erase, erase object
                  -arc -arc/A, home > arc > centre, start, end, draw arc based on centre point & 
                        endpoints
                  -plot -print/ plot/ ctrl + P, quick access toolbar> print, enables print/ plot 
                         configuration dialog box
                  -undo -U/ ctrl + z, quick access toolbar > undo, undoes last command
                  -QNEW ---> acad.dwt template file ---> open ---> Z ---> E ---> zoom into extents of 
                   drawing area 
                  -don't have dynamic input (DYN) turned on
                  -rectangle -rectangle/ REC, home > draw > rectangle, draw rectangle after entering 1 
                              corner & then second
                  -trim -trim/ TR, home > modify > trim, trims objects to selected cutting edge
                  -extend -extend/ EX, home > modify > trim, extend objects to selected boundary edge
                  -offset -offset/ O, home > modify > offset, offsets object (parallel) by set distance
                  -object snaps -osnap/ OS > tools > object > snap settings, brings up snap dialog box
-object snaps -draw line from centre of circle to middle of vertical line extended earlier
              -OS --> dialogue box appears ---> choose object snaps
              -
-blocks -collection of objects (lines, arcs, circles, text) form more complex entity represents object 
         in real world (door, windows, computer)
-advantages of ping blocks -single entity, modify (move, copy, rotate) block by selecting only 1 object
                           -build library of blocks of parts require many times, stored in separate 
                            folder & network all drafters have access to them
                           -keep file size down, insert block, only stores name of block , its location 
                            (insertion point), scale, rotation, noticeable in large drawing
                           -when changing something ----> redefine block
                           -contain non-graphical information -text objects (attributes), information 
                            stay with block buy also extracted to database or spreadsheet
                           -internal to current drawing & external saved as separate file
                           -block -Bmake/B, home > block > create, creates block from separate entities 
                                   (internal to current drawing)
                           -write block -Wblock/W, none, creates block & write to file (external) 
                           -insert -Insert/I, home > block > insert, insert block (internal, external) 
                           -explode -Explode/X, home > modify > explode, explode block, other compound 
                                     object into its component parts 
                           -zoom -1 section of room close to desk (draw rectangle to represent desk)
                                 -create new layer COMPUTERS & make colour #73 (LA invokes layer 
                                  properties manager)
-zero layer -special properties when creating block, when objects in block are drawn on zero layer
             -
-


Figma:
-cloud-based design tool used for UI/UX design, prototyping, collaboration
-allows real-time collaboration
-toolbar (top) -contains selection, shape, text, pen tools
-layers panel (left) -shows all elements on art-board
-properties panel (right) -adjust size, colour, alignment
-canvas (centre)
-Frames -art-boards —used for screens, pages, components (F)
        -resize by dragging edges or entering pixel values
-layouts -use grids for precise designs (rows, columns, square grids)
         -auto layout -dynamically adjusts content spacing —great for buttons, cards, responsive design
-colours -add fills/strokes using right panel
         -save colours as styles for consistency
         -RGBA for transparency control
-typography -font size set in pixels (px), line height, letter spacing
-components -re-usable design elements —like buttons, icons, cards
            -create component -select element -> right-click -> create component (use Cmd + Alt + K)
            -instances -copies of components that update automatically when main component changes
-variants -multiple versions of component —useful for buttons (default, hover, disabled)
          -Add variants -select component -> right panel -> add variant
-prototyping —making designs interactive
             -link frames -select object -> click Prototype tab -> drag blue circle to another frame
             -interactions -set triggers (click, hover, after delay)
             -transitions -choose animations like instant, dissolve, slide, smart animate
             -overlays -show pop-ups or modals
             -scrolling areas -create scrollable containers for mobile apps
             -Smart animate -smooth transitions b/w states —ideal for micro-interactions
-grids -add grids using layout grid in right panel (rows, columns, squares)
-constraints -pin elements using constraints to make responsive designs
             -options -left, right, top, bottom, scale, centre
-design system -reusable components, styles, rules for consistent design
                -create colour styles -define primary, secondary, background colours
                -create text styles -headings, subheadings, body, captions
                -build components -buttons, icons, cards
                -Use variants -button states & input fields
                -organise into frames & sections
-export designs -select frame/component ---> export (right panel) & formats (PNG, JPG, SVG, PDF)


Designer:
-


Canva:
-social media post, book cover, thumbnails, presentation, logos, infographics, website
-templates, elements, upload, animate
-video, transition, splitting, cut
-Design Types
Social Media: Instagram posts, Facebook covers, YouTube thumbnails.
Presentations: Slideshows, pitch decks.
Marketing: Posters, flyers, brochures, business cards.
Documents: Resumes, reports, letterheads.
Videos: Animated posts, reels, video intros.
2. Main Panels
Homepage: Templates, projects, brand kits.
Editor: Canvas for design work.
Projects: Saved designs.
Brand Kit: Upload logos, fonts, colours (Pro feature).
Apps: Integrations like Google Drive, Dropbox, Pexels.
3. Design Toolbar (Left)
Templates: Pre-made designs.
Elements: Shapes, lines, frames, icons, stickers.
Uploads: Add custom images, videos, audio.
Text: Add headings, subheadings, body text.
Photos: Stock images from Pexels, Unsplash.
Audio: Background music, sound effects.
Videos: Stock videos, animated clips.
Charts: Graphs (bar, line, pie charts).
Background: Solid colors, gradients, patterns.
Apps: Integrations like Giphy, QR code generator.
4. Top Toolbar (Editing Options)
File: Resize, save, version history.
Position: Align (top, center, bottom), layer (bring forward/backward).
Transparency: Adjust opacity.
Effects:
Text Effects: Shadow, lift, neon, glitch.
Image Effects: Blur, duotone, vignette.
Animate: Add transitions (fade, pop, wipe).
Lock: Freeze an element’s position.
Group: Combine elements to move/resize together.
Comment: Collaborate by leaving feedback.
5. Export and Sharing
Download:
PNG: Transparent backgrounds (Pro).
JPEG: Smaller file sizes.
PDF: For printing.
MP4: Animated designs.
GIF: Short animations.
Share:
Link Sharing: View, edit, comment permissions.
Social Media: Direct post to Facebook, Instagram, LinkedIn.
Present: Full-screen slideshows.
Schedule: Plan social media posts.
6. Advanced (Pro Features)
Background Remover: Instantly remove image backgrounds.
Magic Resize: Resize for multiple platforms at once.
Brand Kit: Store logos, fonts, brand colors.
Content Planner: Schedule social media content.
Version History: Access past design edits.
7. Shortcuts
Cmd/Ctrl + D: Duplicate.
Cmd/Ctrl + G: Group elements.
Cmd/Ctrl + Shift + K: Add new text box.
Arrow keys: Nudge elements.
Shift + Arrow keys: Larger nudge.


Figma:
-product designing -relationship that the designed product has with the user
                   -user experience design, product strategy, and go-to-market planning
                   -


Graphic designing:
-art of combining text, images, ideas to communicate visually (logos, websites, posters, social media)
-balance -symmetrical or asymmetrical distribution of elements
-contrast -using opposing elements (colour, size, type) to highlight differences
-alignment -organising elements to create visual connection
-repetition -reinforcing consistency by repeating design elements
-proximity -grouping related elements together
-white space -empty areas to improve readability & focus
-adobe photoshop, adobe illustrator, adobe InDesign, figma, canva, procreate, blender, after effects
-colour theory —master science of colours
-colour wheel -primary, secondary, tertiary colours
-colour harmony -complementary, analogous, triadic colour schemes
-RGB (red, green, blue) -for digital designs
-CMYK (cyan, magenta, yellow, black) -for print designs
-typography —make text look powerful
            -typeface -design style (Helvetica); font -specific weight/size (Helvetica bold)
            -limit to 2-3 fonts per design
            -ensure readability (contrast text against background)
            -adjust kerning (space b/w letters) & leading (space b/w lines)
-layout & composition -grid systems -organise elements evenly (web design & print)
                      -golden ratio -design principle (1:1.618) for aesthetically pleasing balance
                      -rule of thirds -divide design into 9 equal parts —place focal points along lines
-common design layouts -
Single Column: Simple, for mobile-first designs.
Multi-Column: For magazines and brochures.
Modular Grid: Great for structured designs like websites.
-use Figma or InDesign for grid-based designs
🏁 6. Advanced Graphic Design Techniques
Blending Modes (Photoshop):

Multiply: Darkens layers.
Screen: Brightens layers.
Overlay: Enhances contrast.
Masking:

Clipping Mask: Reveals only a part of a layer (useful for text effects).
Layer Mask: Hides portions of a layer non-destructively.
-branding & logo design -wordmark (logotype) -Google, FedEx
                        -lettermark -IBM, CNN
                        -pictorial mark -apple, twitter
                        -abstract mark -nike swoosh
                        -mascot -KFC’s colonel sanders
Logo Design Process:

Research: Understand the brand’s values and target audience.
Sketch: Brainstorm multiple logo ideas.
Refine: Choose strong concepts and digitize them (Illustrator).
Color + Typography: Align with brand guidelines.
Test: Ensure scalability (logo looks good on a business card and billboard).
🔥 Pro Tip: Keep logos simple, memorable, versatile.

📱 8. UI/UX Design
UI (User Interface): Designing visual elements of digital products (buttons, sliders).
UX (User Experience): Ensuring products are user-friendly and intuitive.

Key UI/UX Tools:

Figma: Collaborative design platform.
Adobe XD: Prototyping and wireframing.
Sketch: Popular for app design.
Wireframing and Prototyping:

Start with low-fidelity wireframes (simple sketches).
Move to high-fidelity prototypes (detailed designs with interactions).
🎬 9. Motion Graphics
Take your designs to the next level with motion:

After Effects: Animate text, logos, and UI elements.
Principle/Figma: Add simple animations for app designs.
Key concepts:

Keyframes: Define motion at specific points.
Easing: Smooth acceleration/deceleration of animations.
Transitions: Slide, fade, bounce effects.
-Behance, Dribbble, custom site (Squarespace, Webflow)
-Upwork & Fiverr -start small, build reputation
-Toptal -for high-end clients (once experienced)


Amplifier:
-electronic device/ circuit used to increase voltage, current, power of input signal
-wireless communications & broadcasting, audio equipment of all kinds
-boosts the power of an audio signal
-produces louder, clearer sound
-signal input (microphone, phone, mixer) ------> amplifier ------> signal output (speaker)
-MIC-1, MIC-2, MIC-3
-knobs -volume, gain, bass, mid, treble, MIC-1, MIC-2/AUX, MIC-3/USB, DVD/AMP, USB/FM
-LED spectrum analyser (-5dB -3dB, 0, +3dB, -5dB)
-SD/MCC card slot, USB
-balance/ pad control, crossover knob, master volume, FX/effect buttons
-input ports (RCA, XLR, TRS)
-line output -sends not amplified signal to another device (recorder, another amp)
             -signal routing, linking multiple amps
-auxiliary (AUX) input -receives signals from non-standard audio sources (MP3 players, phones)
                       -3.5mm jack
-USB port -connect digital sources like computers, support charging, data transfer
-preamp out -connect external power amp
-power amp in -bypass amp’s preamp section & use as power amplifier only
-mode selector switch -allows to switch b/w different modes (stereo, mono, surround)
                      -home theatre & multi-channel setups
-low/high-pass filter switches -remove certain frequencies
                      -fine-tuning sound for specific speakers like subwoofers
-limiter/compressor switch -prevents signal peaks from causing damaging speakers
                           -limiter -sets maximum level
                           -compressor -smooths out volume spikes & reducing loudest parts of signal
-mute button -instantly cuts signal to speakers
             -stopping audio without changing volume settings
-standby switch -puts amplifier into low-power mode without completely turning it off
                -quick reactivation
-phase inversion switch -reverses signal phase by 180 degrees
                        -multi-speaker setups to prevent phase cancellation & improve sound clarity
-ground lift switch -eliminates ground loop hum by isolating ground connection & reduce unwanted noise


Audio terms:
-volume -controls overall loudness of output, turning up increases sound intensity
-bass -adjusts low-frequency sounds (20-250 Hz) (drum beats/ deep voices)
-loudness depends on amplitude, pitch depends on frequency, quality depends on waveform
-treble -controls high-frequency sounds (4,000-20,000 Hz) cymbals, high vocals
        -increase treble ---> highs crisper, decrease ---> softens high-end sounds
-mids -adjusts mid-range frequencies (250-4,000 Hz) (vocals, guitars, pianos)
      -boosting ---> makes instruments & vocals more pronounced
      -lowering ---> makes softer
-gain -controls input level before volume adjustments, set initial loudness
      -higher gain ---> add power, too high ----> distortion 
-EQ/ equaliser -precise control over different frequency bands (low, mid, high)
               -fine-tune sound balance by boosting/cutting specific frequencies
-balance/ pan -adjusts left-right stereo positioning
       -moving towards left sends more sound to left speaker & vice versa
-fader -controls volume for individual channels in DJ mixer
       -smoothly fades b/w tracks, adjusts level of each input
-master volume -controls total output volume for all channels combined
               -affects loudness of everything coming out of speakers
-FX/ effects -adds audio effects (echo, reverb, distortion) to sound
             -create unique sound textures, transitions in DJing
-low-pass filter (LPF) -filters high frequencies & allows low frequencies only
                       -makes sound deep used for bass drops/ transitions
-high-pass filter (HPF) -filters low frequencies, allows high frequencies only
                        -creates thin sound
-crossfader -blends sound b/w 2 channels/ decks
            -sliding left/ right shifts sound from 1 track to another smoothly


-broadcast model -few senders, direction of communication is 1 way, many receivers
-internet model -many senders, direction of communication is both way, many receivers
-unicast (source -----> single viewers)
-multicast (source -----> multiple viewers)
-broadcast (source -----> all viewers)
-broadcaster -production house, internet, broadcast to transmitters, uplink to satellite, content 
              providers, user contribution, outsider broadcast, video


[google search = entering engine + javascript engine + user-interface]


-internet explorer = trident + chakra 
-fire-fox = gecko + monkey
-chrome = webkit + V8
-safari = webkit + javascript core
-opera = blink
-brave = blink
-edge = blink


Symbols & signs:
-semicolon (;) -used to write many commands on single line
-ampersand (&) -shell doesn't wait for command to complete when line ends with ampersand
-($?) -keep track of previous command exit code
-(&&) -logical AND
-(||) -logical OR
-combining && & || -create if-then-else statement for command line arguments
-(#) -anything typed after # won't be read
-(\) -makes possible to use control characters without shell interpreting them


Subwoofers, woofers & tweeters:
-speakers of all kinds convert electrical signals ------> sound waves allowing listen to music 
-sound has extremely wide frequency range overall
-tweeters -2000-20000Hz (top audible range for humans), uses dynamic drivers, smallest speaker
          -uses voice coil suspended in magnetic field attached to corn/ diaphragm (thin membrane),  
           actuate & move air to produce sound to hear
          -High frequencies
-woofers -broad spectrum, low frequency speakers, 20-2000Hz, deep heavy sound, uses dynamic drivers 
          but enclosed in external housing increase sound clarity & reduce distortion by preventing 
          sound waves created at different location from crossing 
         -low to mid-range
-subwoofer -20-200Hz, perfect organ shaker, move large amount of air with slow accurate vibration
           -uses its own power source to maintain reasonable listening volume 
           -extreme bass


Developers tool:
-elements tab (DOM & CSS inspector)
-inspect & edit HTML –modify webpage structure in real time
-modify CSS styles –edit styles, colours, fonts, positioning
-toggle element states –simulate hover, focus, active
-computed styles –view final applied styles (after inheritance & overrides)
-event listeners –which JavaScript event handlers are attached
-layout & box model –visualise margins, padding, width, height
-console tab (JavaScript debugging & logging)
-execute JavaScript commands –run JS in real-time (console.log("test"))
-view errors & warnings –see red errors & yellow warnings in scripts
-debug JavaScript –check variable values, stack traces, and errors
-interact with elements –modify elements using $0, document.querySelector()
-performance logs –monitor execution times & performance bottlenecks
-sources tab (debugger & file explorer)
-view & edit JavaScript files –see & modify loaded .js files
-set breakpoints –pause execution at specific lines of JS
-step through code –run JS step-by-step to find errors
-event listener breakpoints –pause on click, keypress, submit
-XHR & fetch breakpoints –debug AJAX/API calls
-local overrides –modify files & test changes without changing the server
-network tab (API requests & Resource Loading)
-Monitor API Requests –see all fetch & AJAX requests (XHR, Fetch)
-inspect Responses –view returned JSON, HTML, or text
-check status codes –200 ok, 404 not found, 500 server error
-simulate slow internet –throttle connection to test page speed
-block requests –prevent certain files (like ads or scripts) from loading
-performance tab (speed & rendering analysis)
-record page performance –profile speed of rendering & execution
-frame rate monitoring –detect animation or scrolling lag
-CPU usage analysis –find slow scripts consuming too much power
-paint & rendering times –check how long elements take to render
-memory tab (RAM & garbage collection)
-detect memory leaks –see objects that are not getting freed from RAM
-take heap snapshots –analyse JavaScript memory usage
-garbage collection testing –check how well page frees up memory
-application tab (storage & cookies)
-view local storage & session storage –check data saved by JavaScript
-manage cookies –add, delete, edit cookies
-indexedDB & WebSQL –inspect databases used by site
-service workers –check if site using background scripts
-cache storage –see cached assets for offline usage
-push notifications & background sync –debug push messaging
-security tab (SSL & certificates)
-check SSL/TLS certificates –ensure HTTPS is secure
-detect mixed content issues –identify HTTP content on HTTPS sites
-check permissions -see which APIs (location, camera) page use
-lighthouse tab (SEO & performance reports)
-run performance audits –get speed score & recommendations
-check SEO Score –analyse metadata, alt texts, and best practices
-accessibility testing –find issues for visually impaired users
-PWA (progressive web app) testing –see if website works offline
-recorder tab (user flow debugging)
-record user interactions –track clicks, typing, navigation
-replay actions –debug step-by-step without manually testing
-export automation scripts –generate puppeteer scripts from recordings
-rendering tab (advanced debugging)
-paint flashing –highlights areas being re-rendered
-FPS meter –shows animation & frame rates
-simulate dark mode & colour blindness –test different colour schemes
-experiments override
-force Device Mode –simulate different screen sizes
-test different user agents -pretend to be mobile or bot
-emulate touch events –test mobile gestures on desktop


Blender shortcut:
-open source 3d software used to make animation, visual effects, game assets
-shift + A (adding new items)
-option + left click (orbit view)
-shift + option + left click (pan view)
-cmd + trackpad (zoom in/out)
-trackpad + . (frame selected object)
-ctrl + spacebar (toggle fullscreen)
-tab (switch b/w object & edit mode)
-ctrl + tab (select Sculpt)
-1 (vertex select) 
-2 (edge select)
-3 (face select)
-G (grab/ move)
-R (rotate)
-S (scale)
-shift + D (duplicate object)
-X or delete (delete object)
-enter (confirm action)
-ESC (cancel action)
-cmd + Z (undo)
-cmd + shift + Z (redo)
-cmd + 1 (front view)
-cmd + 3 (side view)
-cmd + 7 (top view)
-cmd + 5 (perspective/orthographic toggle)
-cmd + 0 (camera view)
-ctrl + spacebar (maximise area)
-E (extrude)
-ctrl + B (bevel)
-I (inset faces)
-K (knife tool)
-ctrl + R (loop cut)
-cmd + M (merge)
-cmd + E > subdivide
-cmd + E > bridge edge loops
-A (select/ deselect all)
-Alt + Left Click (Select Edge Loop)
-Ctrl + Alt + Left Click (Select Edge Ring)
-B (box select)
-C (circle select)
-cmd + Left Click + Drag (lasso select)
-cmd + I (invert selection)
-I (insert keyframe)
-alt + I (delete keyframe)
-spacebar (play/ pause animation)
-shift + right arrow (jump to next keyframe)
-shift + left arrow (jump to previous keyframe)
-shift + left click on timeline (timeline scrubbing)
-ctrl + tab > sculpt
Brush Size Increase/Decrease: F
Brush Strength Increase/Decrease: Shift + F
Smooth Brush Shortcut: Shift + Left Click
-F12 (render)
-ctrl + F12 (render animation)
-F11 (open render view)
-shift + S in render window (save render)
-cmd + S (save)
-cmd + shift + S (save as)
-cmd + N (new file)
-cmd + O (open file)


5.1ch
It uses five full bandwidth channels and one low-frequency effects channel. Dolby Digital, Dolby Pro Logic II, DTS, and SDDS are all commonly 5.1 systems. 5.1 is also the standard surround sound audio component of digital broadcast and music.


DBMS patterns:
-case study -cab booking app -tiny startup
                             -10 customers onboard
                             -single small machine DB stores all customers, trips, locations, booking 
                              data & customer trip history
                             -1 trip booking in 5 mins
                             -app becoming famous, but problems begins 
                                           -requests scales upto 30 bookings per minute
                                           -tiny DB system started performing poorly
                                           -API latency has increased lot
                                           -transactions facing deadlock, starvation & frequent failure
                                           -sluggish app experience
                                           -customer dis-satisfaction
                             -solution -apply some kind of performance optimisation measures
                                       -might have to scale our system going forward
-pattern-1 -query optimisation & connection pool implementation
           -cache frequently used non-dynamic data (booking history, payment history, user profiles)
           -introduce database redundancy (may be use NoSQL)
           -connection pool libraries to cache DB connections
           -multiple application threads use same DB connection
           -good optimisations as of now
           -scaled business to 1 more city & now getting ~100 booking per minute
-pattern-2 -vertical scaling or scale-up
           -upgrading our initial tiny machine
           -RAM by 2x & SSD by 3x etc
           -scale up is pocket friendly till point only
           -more you scale up, cost increases exponentially
           -good optimisation as of now
           -business is growing, you decided to scale to 3 more cities & getting 300 booking/ minute
-pattern-3 -command query responsibility segregation (CQRS)
           -scaled up big machine not able to handle all read/write requests
           -separate read/write operations physical machine wise
           -2 more machines as replica to primary machine
           -all read queries to replicas
           -all write queries to primary
           -business is growing, you decided to scale to 2 more cities
           -primary not able to handle all write requests
           -lag between primary & replica is impacting user experience
-pattern-4 -multi primary replication
           -all machines can work as primary & replica
           -multi primary configuration is logical circular run
           -write data to any node
           -read data from any node that replies to broadcast firs
           -scale to 5 more cities & your system is in pain again (~50 req/s)


DBMS:
-advantages -data organisation & storage of data in structured manner, making easy to retrieve & query 
             data as needed
            -provide mechanism for enforcing data integrity constraints (value of data & access 
             controls restrict who access data)
            -provides mechanism for controlling concurrent access to database ensure multiple users 
             access data without conflicting with each other
            -provides tools for managing security of data, controlling access to data & encrypting 
             sensitive data
            -provides mechanism for backing up & recovering data useful in collaboration work 
             environment
            -allows multiple users to access & share same data --> useful in collaboration work 
             environment
-disadvantages -complex to setup & maintain, requiring specialised knowledge & skills
               -add overhead to performance of app, high levels of concurrency required
               -limit of scalability of app, require use of locking & other synchronisation mechanism 
                ensure data consistency
               -high cost of maintaining & upgrading DBMS for large & complex system
               -limited use cases


DBMS:
-failure classification -transaction failure (logical, system error)
                        -system crash (power cuts, h/w malfunction, bug in s/w/ OS itself)
                        -data transfer failure (disk head crash, unreachability, forming bad sector)
-data -collection of raw, unorganised facts & details (text, observations, figures, symbols)
      -doesn't carry any specific purpose & no significance by itself
      -measured in terms of bits & bytes (context of computer storage & processing)
      -recorded & doesn't have any meaning unless processed
      -quantitative -numerical form (weight, volume, cost)
      -qualitative -descriptive, not numerical, name, gender, hair colour
      -data doesn't depend on information
-information -processed, organised & structured data
             -enables decision making & meaningful
             -extracted from data, analysing & interpreting pieces of data
             -presented by words, language, thoughts, ideas
             -information depends on data
-database -electronic piece/system where data is stored in way accessed, managed, updated
          -database management system
          -interrelated data & set go programs to access those data
          -collection of data refers to database contains information relevant to enterprise
          -way to store & retrieve database information both convent & efficient
          -perform different operations (addition, access, updating, deletion of data)
          Database ----> DBMS ---> API---> App
                              ---> API---> App
                              ---> API---> App
-file processing system -data redundancy 7 inconsistency
                        -difficulty in accessign data & data isolation
                        -integrity problems, atomicity problems
                        -concurrent-access anomalies & security problems
-DBMS architecture -view of data
                   -provide abstract view of data (system hides certain details & data is stored & 
                    maintained)
                   -simplify user interaction with system, abstraction is applied through several 
                    levels of abstraction
                   -enable multiple users to access same data with personalised view while storing 
                    underlying data only once
                   -physical level/ internal level -lowest level of abstraction 
                                                   -low level data structures are used
                                                   -describe physical storage structure of DB
                                                   -storage allocation (N-ary tree), data 
                                                    compression, encryption
                                                   -use algorithm allow efficient access of data
                   -logical level/ conceptual level -design database at conceptual level (what data 
                                                     is stored in DB & what relationships exist 
                                                     among data
                                                    -user at logical level doesn't need to be aware 
                                                     of physical level structures
                                                    -DBA who must decide what information to keep 
                                                     in DB use logical level of abstraction
                                                    -should be easy to use
                   -view level/ external level -highest level of abstraction to simplify user 
                                                interaction with system by providing different view 
                                                to different end-user
                                               -each view schema tells database part the particular 
                                                user group is interested & hides remaining database 
                                                from user group
                                               -database contains several schemas (subschemas) used 
                                                to tell different view of database
                                               -view also provide security mechanism to prevent 
                                                users from accessing certain part of DB
                   -instances & schemas -collection of info stored in DB at particular moment 
                                         (instance of DB)
                                        -overall design of DB (DB schema)
                                        -schema is structure description of data & not change 
                                         frequently but data can
                                        -DB schema correspond to variable declarations in program
                                        -types of schema -physical -change should not affect 
                                                                    logical schema/app
                                                         -logical -programmer construct app by 
                                                                   using logical schema
                   -data models -provides way to describe design of DB at logical level
                                -collection of conceptual tools for describing data, data 
                                 relationships, data semantics, consistency constraints
                                -ER model, relational model, object-oriented model, object-
                                 relational data model
                   -database languages -data definition language (DDL) -specific DB schema, specify  
                                        consistency, checked every-time DB is updated
                                       -data manipulation language (DML) -express DB quires, update
                                        retrieval, insertion, deletion, updating, query language 
                                        (specify statements requesting retrieval of info)
                                       -both features are present in SQL
                   -database accessed from application programs -apps interact with DB
                                                                -API provided to send DML/DDL to DB
                                                                 to retrieve results (ODBC open 
                                                                 database connectivity, JDBC java 
                                                                 database connectivity)
                   -database administrator (DBA) -person who has central control of both data & 
                                                  programs that access data 
                                                 -function of DBA -schema definition, storage  
                                                  structure & access methods, schema & physical 
                                                  organisation modifications, authorisation  
                                                  control, routine maintenance (period backup, 
                                                  security patches, any upgrades)
                   -DBMS application architecture -client machines, remote DB users work, server 
                                                   machines on which DB system run 
                                                -T1 -client server & DB all present on same machine 
                                                -T2 -app is partitioned into 2 components 
                                                    -client machine, invokes DB system  
                                                     functionality at server end through query 
                                                     language statement
                                                    -API stands like ODBC & JDBC used to interact 
                                                     b/w client & server
                                                -T3 -app is partitioned into 3 components
                                                    -client machine is just frontend & don't have 
                                                     any direct DB calls
                                                    -client machine communicate with app server 
                                                     communicate with DB system to access data
                                                    -business logic
                                                    -best for WWW apps
                                                    -scalability -due to app servers
                                                    -data integrity -app servers acts as middle  
                                                     layer b/w client & DB, minimise chances of data 
                                                     corruption
                                                    -security -client can't directly access DB ---> 
                                                     more secure
-data model -collection of conceptual tools for describing data, data relation, data semantics, 
             consistency constant
-ER model -high level data model based on real world consists of collection of basic objects (entities, 
           & relation among these objects)
          -graphical representation of ER model is ER diagram --> blueprint of DB
-entity -thing/object in real world, physical exits
        -strong entity -can be uniquely identified
        -weak entity -can't be uniquely identified
                     -loan (strong), payment (weak), weak depends on strong
-entity set -set go entities of same type share same property, attributes
            -student, customer (entity set)
-attributes -entity represent set of attributes
            -each entity has value of each of its attributes
            -set of permitted values (domains), value (set)
            -student_id, name, batch, year
            -simple -can't be divided further
            -composite -can be divided into subparts 
            -single valued -only 1 value attribute
            -multi-valued -attribute having more than 1 value
                          -limit constraint may applied, upper limit, lower limit
            -derived -values derived from other related attribute
            -null value -attribute takes null when entity have no value for it
-relationships -associate among 2 or more entities
     -strong relationship -2 independent entities
     -weak relationship -b/w weak entity & its owner/strong entity
     -degree of relationship -unary (1 entity), binary (2) (common), ternary (3)
-relationship constraints -mapping cardinality/ cardinality ratio -number of entities to which another 
                                                               entity can be associate via relationship
                          -1 to 1 -entity in A associate with at most 1 entity B (A & B are entity set)
                                  -entity of B is associated with at most 1 entity of A 
                                   (citizen has Aadhaar)
                          -1 to many -entity in A associate with N entity B 
                                     -entity in B is associated with at most 1 entity of A 
                                      (citizen has vehicles)
                          -many to 1 -entity in A associate with at most 1 entity B
                                     -entity of B is associated with at most N entity of A 
                                      (course taken by professor)
                          -many to many -entity in A associate with N entity B 
                                        -entity of B is associated with N entity of A 
                                         (customer buys product)
                          -participation constraints -minimum cardinality constraint
                                                     -types, partial & total participation
                                                     -partial participation, not all entities are 
                                                      involved in relationship instance
                                                     -total participation, each entity must be involved 
                                                      in at least 1 relationship instance
                                                     -(customer borrow loan, loan has total
                                                       participation as it can’t exist without customer 
                                                       entity, customer has partial participation)
                                                     -weak entity has total participation constraint, 
                                                      but strong may not have total
-normalisation -step forwards DB optimisation, greater overall database organisation
               -ensures data consistency maintains
               -avoid redundancy in DB, not to store redundant data
               -greater overall database organisation, data consistency is maintained in DB
               -minimise redundancy from relations, eliminate unwanted insertion, update, deletion
               -divide composite attribute --> individual attributes, layer table into smaller links 
                them using relationships
               -normal form used to reduce redundancy from database table
               -normal forms types -1NF -every relation cell must have atomic value
                                   -relation must not have multi-values attributes
                                   -2NF -relation must be in 1NF
                                        -all non-prime attributes must be fully dependent on PK
                                        -non prime attribute can't depend on part of PK
                                   -3NF -relation must be in 2NF
                                        -non-transitivity dependency exists
                                        -non prime attribute should not find non-prime attribute
                                   -BCFN (boyce-cdd normal form) -relation must be in 3NF
                                                                 -FD: A->B (A must be super key)
               -anomalies -means abnormalities, 3 types of anomalies introduced by data redundancy
                          -insertion anomaly -when certain data (attribute) can't be inserted into DB 
                                              without presence of other data
                          -deletion anomaly -delete anomaly refers to situation where deletion of data 
                                             results in unintended loss of some other important data
                          -updation anomaly (modification anomaly) -when update of single data value   
                                             requires multiple rows of data to be updated
                                            -due to updation to many places, data inconsistency arises, 
                                             if 1 forgets to update data at all intended places
                          -DB size increases & DB performance become very slow
                          -rectify these anomalies & effect of these of DB, use Database optimisation 
                           technique (normalisation)
-specialisation -ER model, require to subgroup entity set into other entity sets distinct with other  
                 entity sets
                -splitting entity into further sub entity sets based on functionalities, specialities,  
                 features
                -top-down approach, certain attributes may only be applicable to few entities of parent 
                 entity set
                -DB designer show distinctive features of sub entities
                -overall refining DB blueprint
-generalisation -reverse of specialisation
                -DB designer encounter certain properties 2 entities are overlapping
                -generalises entity set will be super class
                -relationship is present b/w subclass & superclass
                -bottom-up approach, makes DB more refined & simpler
                -common attributes not repeated
-attribute inheritance -both specialisation & generalisation has attributes inheritance
                       -attributes of higher level entity sets are inherited by lower level entity set
-participation inheritance -parent entity set participates in relationship ---> child entity sets also 
                            participate in relationship
-aggregation -aggregation is technique, abstraction is applied to treat relationship as higher level 
              entities (abstract entity) 
             -avoid redundancy by aggregating relationship as entity set itself
-relational model -organises data in form of relations (tables)
                  -consists of collection of tables, each is assigned unique name
                  -row in table represents relationship among set of values, table is collection of 
                   such relationships
                  -tuple -single row of table representing single data point /unique record
                  -columns -represents attributes of relation, each attribute, permitted value, domain 
                            of attribute
                  -relation schema -design & structure of relation, contains name of relation & all
                                    columns/attributes
                  -common RM based DBMS systems, RDBMS (Oracle, IBM, MySQL, MS Access)
                  -degree of table -number of attributes/columns in given table/relation
                  -cardinality -total no. of tuples in given relation
                  -relational key -set of attributes which uniquely identify each tuple
                  -properties -name of relation is distinct among all other relation
                              -values have to be atomic, can’t broken down further
                              -name of each attribute/column must be unique
                              -each tuple must be unique in table
                              -sequence of row & column has no significance
                              -tables must follow integrity constraints, helps to maintain data 
                               consistency across tables
                  -relational model keys -super key (SK) -any P&C of attributes present in table which 
                                                          uniquely identify each tuple
                                         -candidate key (CK) -minimum subset of super keys, which 
                                                              uniquely identify each tuple, contains no
                                                              redundant attribute
                                                             -CK value shouldn’t be NULL
                                         -primary key (PK) -selected out of CK set, has least no. of 
                                                            attributes
                                         -alternate key (AK) -all CK except PK
                                         -foreign key (FK) -creates relation b/w 2 tables
                                                           -relation (r1) may include among its             
                                                            attributes PK of other relation (r2) (FK)
                                                            from r1 referencing r2
                                                           -relation r1 (referencing (child)) relation 
                                                            of FK dependency & r2 (referenced (parent))
                                                            relation of FK
                                                           -helps to cross reference b/w 2 different 
                                                            relations
                                         -composite key -PK formed using at least 2 attributes
                                         -compound key -PK formed using 2 FK
                                         -surrogate key -Synthetic PK
                                                        -generated automatically by DB, usually integer 
                                                         value, may be used as PK
                  -integrity constraints -CRUD operations must be done with some integrity policy so DB 
                                          is always consistent
                                         -introduced so we don't accidentally corrupt DB
                                         -domain constraints -restricts value in attribute of relation, 
                                                              specifies Domain, restrict data types of 
                                                              every attribute
                                         -entity constraints -every relation should have PK, PK != NULL

                                         -referential constraints -specified b/w 2 relations & helps 
                                                      maintain consistency among tuples of 2 relations
                                                     -requires that value appearing in specified 
                                                      attributes of any tuple in referencing relation 
                                                      also appear in specified attributes of at least 1 
                                                      tuple in referenced relation
                                                     -if FK in referencing table refers to PK of 
                                                      referenced table then every value of FK in  
                                                      referencing table must be NULL or available in 
                                                      referenced table
                                                     -FK must have matching PK for its each value in 
                                                      parent table or must be NULL
                                         -key constraints -6 types of key constraints present in DBMS
                                                          -NOT NULL -constraint restricts user from not 
                                                                     having NULL value, ensures that 
                                                                    every element in database has value
                                                          -UNIQUE -ensure that all values consisting in 
                                                                   column are different from each other
                                                          -DEFAULT -set default value to column, 
                                                                    default value is added to columns 
                                                                    if no value is specified for them
                                                          -CHECK -Its 1 of integrity constraints in 
                                                                  DBMS, keeps check that integrity of 
                                                                  data is maintained before & after 
                                                                  completion of CRUD
                                                          -PRIMARY KEY -attribute or set of attributes 
                                                                        that uniquely identify each 
                                                                        entity in entity set, must 
                                                                       contain unique & not null values
                                                          -FOREIGN KEY -whenever there's some 
                                                                        relationship b/w 2 entities,  
                                                                        must be some common attribute  
                                                                        b/w them, common attribute must  
                                                                        be primary key of entity set
                                                                        becomes foreign key of another 
                                                                        entity set, prevent every 
                                                                        action which result in loss of 
                                                                        connection b/w tables
-transaction -unit of work done against DB in logical sequence, sequence is important in transaction
             -logical unit of work contains 1 or more SQL statements, result of all these statements in 
              transaction either gets completed successfully (all changes made to database are 
              permanent) or at any point any failure happens it gets rollbacked (all changes being done 
              are undone)
-ACID properties -ensure integrity of data, require that DB system maintain following properties of  
                  transaction
                 -atomicity -either all operations of transaction are reflected properly in DB or none 
                 -consistency -integrity constraints must be maintained before & after transaction
                              -DB must be consistent after transaction happens
                 -isolation -even though multiple transactions may execute concurrently, system 
                             guarantees that, for every pair of transactions Ti & Tj, it appears to Ti 
                             that either Tj finished execution before Ti started, or Tj started   
                             execution after Ti finished, each transaction is unaware of other 
                             transactions executing concurrently in system
                            -multiple transactions happen in system in isolation, without interfering 
                             each other
                 -durability -after transaction completes successfully, changes it has made to database 
                              persist, even if there are system failures
-transaction states -active state -very 1st state of life cycle of transaction, all read & write    
                                   operations are being performed, If they execute without any error T 
                                   comes to partially committed state Although if any error occurs then 
                                   it leads to failed state
                    -partially committed state -after transaction is executed changes are saved in 
                                                buffer in main memory if changes made are permanent on        
                                                DB then state will transfer to committed state & if 
                                                theres any failure, T goes failed state
                    -committed state -when updates are made permanent on DB, then T is said to be in 
                                      committed state, rollback can’t be done from committed states
                                     -new consistent state is achieved at this stage
                    -failed state -when T being executed & some failure occurs, its impossible to 
                                   continue execution of T
                    -aborted state -when T reaches failed state, all changes made in buffer are 
                                    reversed, after that T rollback completely, T reaches abort state 
                                    after rollback, DB’s state prior to T achieved
                    -terminated state -transaction is said to have terminated if has either committed 
                                       or aborted
-database clustering (making replica-sets) -process of combining more than 1 servers or instances 
                                            connecting single database, sometimes 1 server may not be    
                                            adequate to manage amount of data or number of requests,  
                                            thats when data cluster is needed, database clustering, SQL    
                                            server clustering & SQL clustering are closely associated  
                                            with SQL is language used to manage database information
                                           -replicate same dataset on different servers
                      -advantages -data redundancy -clustering of databases helps with data redundancy,  
                                   as we store same data at multiple servers redundancy that clustering 
                                   offers is required & is quite certain due to synchronisation
                                  -any of servers faced failure ---> data is available at other servers 
                                   to access
                                  -load balancing/ scalability doesn’t come by default with database
                                  -depends on setup, allocating workload among different servers that 
                                   are part of cluster ---> indicates more users can be supported &   
                                   when huge spike in traffic ---> higher assurance that it will be 
                                   able to support new traffic, 1 machine not going to get all of hits  
                                   ----> provide scaling seamlessly as required
                                  -links directly to high availability, without load balancing ---> 
                                   particular machine get overworked & traffic would slow down --->  
                                   leading to decrement of traffic to zero
                                  -high availability -when you access database ---> implies that its 
                                   available, high availability refers amount of time database is  
                                   considered available, amount of availability need depends on number 
                                   of transactions running on database & how often running any kind of 
                                   analytics on your data, with database clustering ---> reach 
                                   extremely high levels of availability due to load balancing & have 
                                   extra machines, when server got shut down database ---> available
-cluster architecture -all requests split with many computers so individual user request executed & 
                       produced by number of computer systems, clustering is serviceable definitely by 
                       ability of load balancing & high-availability, If 1 node collapses, request is   
                       handled by another node, few or no possibilities of absolute system failures
-partitioning -technique used to divide stored database objects into separate servers
              -theres increase in performance, controllability of data, manage huge chunks of data 
               optimally, when horizontally scale our machines/servers ---> gives us challenging time  
               dealing with relational databases as its quite tough to maintain relations
              -when apply partitioning to database thats already scaled (equipped with multiple   
               servers) ---> partition our database among those servers & handle big data easily
              -vertical partitioning -slicing relation vertically/ column-wise
                                     -need to access different servers to get complete tuples
              -horizontal partitioning -slicing relation horizontally/ row-wise
                                     -independent chunks of data tuples are stored in different servers
              -when partitioning is applied -dataset become much huge that managing & dealing with it 
                                             become tedious task
                                            -number of requests are enough larger that single DB server 
                                             access is taking huge time & hence system’s response time 
                                             become high
              -advantages of partitioning -parallelism, availability, performance, manageability
                                          -reduce cost as vertical scaling is costly
-distributed database -single logical database thats spread across multiple locations (servers) & 
                       logically interconnected by network
                      -product of applying DB optimisation techniques like clustering, partitioning & 
                       sharding
-sharding -technique to implement horizontal partitioning
          -fundamental -instead of having all data sit on 1 DB instance, 
           split it up & introduce routing layer to forward request to right instances that actually 
           contain data
          -scalability, availability
          -complexity, making partition mapping, routing layer to be implemented in system, non-
           uniformity that creates necessity of Re-sharding
          -not well suited for analytical type of queries, as data is spread across different DB 
           instances (scatter-gather problem)
-indexing -optimise performance of database by minimising number of disk accesses required when query 
           is processed
          -index is type of data structure, used to locate & access data in database table quickly
          -speeds up operation with read operations like SELECT queries, WHERE clause
          -search key -contains copy of primary key or candidate key of table or something else
          -data reference -pointer holding address of disk block where value of corresponding key is 
           stored
          -indexing is optional, increases access speed, Its not primary mean to access tuple, its 
           secondary mean
          -index file is always sorted
-indexing methods -primary index (clustering index)
                  -file may have several indices on different search keys, if data file containing 
                   records is sequentially ordered,
                  -index whose search key also defines sequential order of file
                  -all files are ordered sequentially on some search key, it could be primary key or 
                   non-primary key
                  -dense & sparse indices -dense index -contains index record for every search key 
                                                        value in data file
                                                       -index record contains search-key value & 
                                                        pointer to 1st data record with search-key 
                                                        value, rest of records with same search-key 
                                                        value be stored sequentially after 1st record
                                                       -needs more space to store index record itself
                                                        index records have search key & pointer to 
                                                        actual record on disk
                                          -sparse index -index record appears for only some of search-
                                                         key values
                                                        -helps to resolve issues of dense indexing in 
                                                         DBMS, range of index columns stores same data 
                                                        block address & when data needs to be retrieved 
                                                         block address will be     
                  -primary indexing -based on data file is sorted w.r.t primary key attribute or non-
                                     key attributes
                  -based on key attribute -data file is sorted w.r.t primary key attribute
                                          -PK used as search-key in Index
                                          -sparse index formed (no. of entries in index file = no. of 
                                           blocks in datafile)
                  -based on non-key attribute -data file is sorted w.r.t non-key attribute
                                              -no. of entries in index = unique non-key attribute value 
                                               in data file
                                              -this is dense index, all unique values have entry in 
                                               index file
                                              -company recruited many employees in various departments 
                                               here, clustering indexing in DBMS should be created for 
                                               all employees who belong to same dept
                  -multi-level index -index with 1 or more levels
                                     -if single level index becomes enough large that binary search it 
                                      self take much time, break down indexing into multiple levels
                  -secondary index -non-clustering index, datafile is unsorted, primary indexing is 
                                    not possible, done on key or non-key attribute, called secondary  
                                    indexing because normally 1 indexing is already applied
                                   -no. of entries in index file = no. of records in data file
-advantages of indexing -faster access & retrieval of data, IO is less
-limitations of indexing -additional space to store index table
                         -indexing decrease performance in INSERT, DELETE, UPDATE query
-recovery mechanism component of DBMS supports atomicity & durability
-shadow-copy scheme -based on making copies of DB (shadow copies)
                    -assumption only 1 transaction (T) is active at time
                    -pointer called db-pointer is maintained on disk which at any instant points to 
                     current copy of DB
                    -T, that wants to update DB 1st creates complete copy of DB
                    -all further updates done on new DB copy leaving original copy (shadow copy) 
                     untouched
                    -if at any point T has to be aborted system deletes new copy & old copy is not 
                     affected
                    -if T success, its committed -OS makes sure all pages of new copy of DB written on 
                                                  disk
                                               -DB system updates db-pointer to point to new copy of DB
                                               -new copy is now current copy of DB
                                               -old copy is deleted
                                               -T have been COMMITTED at point where updated db-pointer 
                                                is written to disk
-atomicity -if T fails at any time before db-pointer is updated, old content of DB not affected
           -T abort done by just deleting new copy of DB
           -either all updates are reflected or none
-durability -system fails are any time before updated db-pointer written to disk
            -when system restarts, it read db-pointer & see original content of DB & none of effects of 
             T will be visible
            -T assumed to be successful only when db-pointer is updated
            -if system fails after db-pointer been updated, before that all pages of new copy were 
             written to disk, when system restarts ---> read new DB copy
            -implementation is dependent on write to db-pointer being atomic, disk system provide 
             atomic updates to entire block or at least disk sector, make sure db-pointer lies entirely 
             in single sector, by storing db-pointer at beginning of block
            -inefficient, as entire DB copied for every transaction
-log-based recovery methods -log is sequence of records, log of each transaction maintained in some 
                             stable storage so if any failure occurs ---> can be recovered from there
                            -if any operation performed on database ---> recorded in log
                            -but process of storing logs should be done before actual transaction is 
                             applied in database
                            -stable storage is classification of computer data storage technology that 
                             guarantees atomicity for any given write operation & allows software to be 
                             written thats robust against some hardware & power failures
-deferred DB modifications  -ensuring atomicity by recording all DB 
                             modifications in log but deferring execution of all write operations
                             until final action of T been executed
                            -log information used to execute deferred writes when T completed
                            -if system crashed before T completes or if T is aborted information in 
                             logs are ignored
                            -if T completes --> records associated in log file used in executing 
                             deferred writes
                            -if failure occur while updating is taking place ---> preform redo
-immediate DB modifications -output to DB while T still in active state
                            -written by active T (uncommitted modifications)
                            -in event of crash or T failure, system uses old value field of log records 
                             to restore modified values
                            -update takes place only after log records in stable storage
                            -failure handling -system failure before T completes or if T aborted -----> 
                                               old value field used to undo T
                                              -if T completes & system crashes then new value field is 
                                               used to redo T having commit logs in logs
-both ER-model & relational model are abstract logical representation of real world enterprises
-because 2 models implies similar design principles ---> convert ER design into relational design
-converting DB representation from ER diagram to table format is way arrive at relational DB-design 
 from ER diagram
-ER diagram notations to relations -strong entity -becomes individual table with entity name, 
                                                   attributes becomes columns of relation
                                                  -entity’s primary key (PK) used as relation’s PK
                                                  -FK added to establish relationships with other 
                                                   relations
                                   -weak entity -table formed with all attributes of entity
                                                -PK of its corresponding strong entity added as FK
                                                -PK of the relation will be a composite PK, {FK +  
                                                 partial discriminator key}
                                   -single values attributes -represented as columns directly in 
                                                              tables/relations
                                   -composite attributes -handled by creating separate attribute itself 
                                                      in original relation for each composite attribute
                                                         -address: {street-name, house-no}, is  
                                                          composite attribute in customer relation, add 
                                                          address-street-name & address-house-name as 
                                                          new columns in attribute & ignore “address”  
                                                          as attribute
                                   -multivalued attributes -new tables (named as original attribute 
                                                           name) created for each multivalued attribute
                                                           -PK of entity used as column FK in new table
                                                           -similar name added as column to define 
                                                            multiple values
                                                           -PK of new table would be {FK + multivalued 
                                                            name}
                                                           -for strong entity employee, dependent-name 
                                                            is multivalued attribute
                                                                  -new table named dependent-name will 
                                                                   formed with columns emp-id, & dname
                                                                  -PK: {emp-id, name}
                                                                  -FK: {emp-id}
                                   -derived attributes not considered in tables
-generalisation -method-1 -create table for higher level entity set, for each lower-level entity set, 
                           create table includes column for each of attributes of that entity set plus 
                           column for each attribute of primary key of higher-level entity set
                          -banking system generalisation of account -saving & current
                          -Table 1 -account (account-number, balance)
                          -Table 2 -savings-account (account-number, interest-rate, daily-withdrawal-
                                    limit)
                          -Table 3 -current-account (account-number, overdraft-amount, per-transaction-
                                    charges)
                -method-2 -alternative representation is possible, if generalisation is disjoint & 
                           complete thats, if no entity is member of 2 lower-level entity sets directly 
                           below higher-level entity set & if every entity in higher level entity set 
                           is also member of 1 of lower-level entity sets, don't create table for
                           higher-level entity set, instead, for each lower-level entity set, create 
                           table that includes column for each of attributes of that entity set plus 
                           column for each attribute of higher-level entity sets
                          -tables would be -Table 1: savings-account (account-number, balance, 
                                            interest-rate, daily-withdrawal-limit)
                                           -Table 2: current-account (account-number, balance, 
                                            overdraft-amount, per-transaction-charges)
                -drawbacks of method-2 -If 2nd method used for overlapping generalisation, some values 
                                        such as balance would be stored twice unnecessarily, similarly, 
                                        if generalisation were not complete thats, if some accounts 
                                        were neither savings nor current accounts then such accounts 
                                        couldn't be represented with 2nd method
-aggregation -table of relationship set is made
             -attributes includes primary keys of entity set & aggregation set’s entities
             -add descriptive attribute if any on relationship


NoSQL:
-NoSQL databases -not only SQL are non-tabular databases & store data differently than relational 
                  tables
                 -NoSQL databases come in variety of types based on their data model
                 -main types are document, key-value, wide-column, graph
                 -provide flexible schemas & scale easily with large amounts of data & high user loads
                      -they are schema free
                      -data structures used are not tabular, more flexible, has ability to adjust 
                       dynamically
                      -handles huge amount of data (big data)
                      -most of NoSQL are open sources & has capability of horizontal scaling
                      -stores data in some format other than relational
-NoSQL databases advantages -flexible schema -RDBMS has pre-defined schema ---> become issue when we 
                                              don't have all data with us or need to change schema 
                                             -huge task to change schema on go
                            -horizontal scaling -scale-out, refers to bringing on additional nodes to 
                                                 share load, difficult with relational databases due to  
                                                 difficulty in spreading out related data across nodes 
                                                 with non-relational databases, made simpler since  
                                                 collections are self-contained & not coupled 
                                                 relationally, allows them to be distributed across
                                                 nodes more simply, as queries don't have to “join” 
                                                 them together across nodes
                                                -scaling horizontally achieved through sharding or 
                                                 replica-sets
                            -high availability -highly available due to its auto replication feature 
                                                whenever any kind of failure happens data replicates 
                                                itself to preceding consistent state
                                               -if server fails, access that data from another server 
                                                as well as in data is stored at multiple servers
                            -easy insert & read operations -queries in NoSQL databases faster than SQL 
                                                            databases, data in SQL databases typically 
                                                            normalised, queries for single object or 
                                                            entity require to join data from multiple  
                                                            tables as tables grow in size, joins become 
                                                            expensive, data is typically stored in way 
                                                            thats optimised for queries
                                                           -when using MongoDB is data thats accessed 
                                                            together should be stored together Queries 
                                                            don't require joins, so queries are fast
                                                           -difficult delete or update operations
                            -caching mechanism
                            -NoSQL use case is more for cloud applications
-use NoSQL when -fast-paced agile development
                -storage of structured & semi-structured data
                -huge volumes of data
                -requirements for scale-out architecture
                -modern application paradigms like micro-services & real-time streaming
-NoSQL DB misconceptions -relationship data is best suited for relational databases
                         -common misconception is that NoSQL databases or non-relational databases  
                          don’t store relationship data well 
                         -store relationship data just store it differently than relational databases  
                         -when compared with relational databases, many find modelling relationship 
                          data in NoSQL databases to be easier than in relational databases
                         -allow related data to be nested within single data structure
                         -some NoSQL databases like MongoDB support ACID transactions
-types of NoSQL data models -key-value stores -simplest type of NoSQL database is key-value store
                            -every data element in database stored as key value pair consisting of   
                             attribute name (key) & value, key-value store is like relational database 
                             with only 2 columns (key or attribute name (state) & value (Alaska)
                            -use cases include shopping carts, user preferences & user profiles
                            -oracle NoSQL, amazon dynamoDB, mongoDB also supports key-value store Redis
                            -key-value database associates value (anything from number or simple string 
                             to complex object) with key, used to keep track of object
                            -key-value store is like dictionary/array/map object as it exists in most 
                             programming paradigms, but stored in persistent way & managed by DBMS
                            -key-value databases use compact, efficient index structures to be able to 
                             quickly & reliably locate value by its key, making them ideal for systems 
                             that needs to be able to find & retrieve data in constant time
                            -several use cases when choosing key value store approach is optimal 
                             solution -real time random data access (user session attributes in online 
                                       application like gaming or finance
                                      -caching mechanism for frequently accessed data or configuration 
                                       based on keys
                                      -application is designed on simple key-based queries
-column-oriented/ columnar/ c-Store/ wide-column -data is stored so that each row of column will be 
                                                  next to other rows from that same column
                                                 -while relational database stores data in rows & reads 
                                                  data row by row, column store is organised as set of 
                                                  columns ---> when running analytics on small number 
                                                  of columns ---> read those columns directly without  
                                                  consuming memory with unwanted data
                                                 -columns are often of same type & benefit from more  
                                                  efficient compression, making reads even faster
                                                 -columnar databases quickly aggregate value of given 
                                                  column (adding up total sales for year)
                                                 -cassandra, redShift, snowflake
-document based stores -DB store data in documents similar to JSON (javaScript object notation) objects 
                       -each document contains pairs of fields & values
                       -values typically be variety of types including strings, numbers, booleans, 
                        arrays, objects
                       -use cases include e-commerce platforms, trading platforms, mobile app 
                        development across industries
                       -supports ACID properties hence, suitable for transactions
                       -MongoDB, CouchDB
-graph based stores -focuses on relationship b/w data elements, each element stored as node (person
                     in social media graph)
                    -connections b/w elements called links or relationships
                    -connections first-class elements of database, stored directly
                    -relational databases, links are implied, using data to express relationships
                    -optimised to capture & search connections b/w data elements, overcoming overhead
                     associated with JOINing multiple tables in SQL
                    -very few real-world business systems survive solely on graph queries ----------> 
                     usually run alongside other more traditional databases
                    -use cases include fraud detection, social networks, knowledge graphs
-NoSQL databases disadvantages -data redundancy -since data models in NoSQL databases are typically  
                                                 optimised for queries & not for reducing data 
                                                 duplication, NoSQL databases can be larger than SQL 
                                                 databases, storage is currently so cheap that most 
                                                 consider this minor drawback & some NoSQL databases 
                                                 support compression to reduce storage footprint
                               -update & delete operations are costly
                               -all type of NoSQL data model doesn’t fulfil all of application needs
                               -depending on NoSQL database type select, may not able to achieve all of 
                                your use cases in single database, graph databases are excellent for 
                                analysing relationships in data but may not provide that need for 
                                everyday retrieval of data such as range queries
                               -when selecting NoSQL database, use cases will be & if general purpose 
                                database like MongoDB would be better option
                               -doesn’t support ACID properties in general
                               -doesn’t support data entry with consistency constraints
-relational databases -based on relational model
                      -commonly use structured query language (SQL) for operations like creating, 
                       reading, updating, deleting data
                      -store information in discrete tables, JOINed together by fields foreign 
                       keys
                      -user table which contains information about all your users & join to purchases 
                       table contains information about all purchases they’ve made 
                      -MySQL, Microsoft SQL server & oracle are types of relational databases
                      -ubiquitous, having acquired steady user base
                      -highly optimised for working with structured data
                      -provide stronger guarantee of data normalisation
                      -use well-known querying language through SQL
                      -scalability issues (horizontal scaling)
                      -data become huge, system become more complex
-object oriented databases -object-oriented data model based on OOPs paradigm, widely use inheritance, 
                            object-identity & encapsulation (information hiding) with methods to 
                            provides interface to objects are among key concepts of object-oriented   
                            programming have found applications in data modelling
                           -object-oriented data model also supports rich type system, including 
                            structured & collection types
                           -inheritance & some complex types also present in E-R model, encapsulation 
                            & object-identity distinguish object-oriented data model from E-R model
                           -sometimes database be very complex, having multiple relations, maintaining 
                            relationship b/w them is tedious at times
                                         -object-oriented databases data treated as object
                                         -all bits of information come in one instantly available 
                                          object package instead of multiple tables
                           -advantages -data storage & retrieval is easy & quick
                                       -handle complex data relations & more variety of data types that 
                                        standard relational databases
                                       -relatively friendly to model advance real world problems
                                       -works with functionality of OOPs & object oriented languages
                           -disadvantages -high complexity causes performance issues (read, write, 
                                           update & delete operations are slowed down
                                          -not much of community support as isn’t widely adopted as 
                                           relational databases
                                          -doesn't support views like relational databases
                                          -objectDB, gemstone
-hierarchical databases -most appropriate for use cases in which main focus of information gathering is 
                         based on concrete hierarchy like several individual employees reporting to 
                         single department at company
                        -schema for hierarchical databases defined by its tree-like organisation in 
                         which theres typically root “parent” directory of data stored as records that 
                         links to various other subdirectory branches & each subdirectory branch, or 
                         child record link to various other subdirectory branches
                        -HD structure dictates that while parent record have several child records, 
                         each child record only have 1 parent record, data within records stored in 
                         form of fields & each field can only contain 1 value, retrieving hierarchical 
                         data from HD architecture requires traversing entire tree, starting at root 
                         node
                        -disk storage system also inherently hierarchical structure, these models also 
                         used as physical models
                        -advantage -ease of use, one-to-many organisation of data makes traversing
                                    database simple & fast, ideal for use cases such as website drop-
                                    down menus or computer folders in systems like Windows OS
                                   -due to separation of tables from physical storage structures, 
                                    information can easily be added or deleted without affecting 
                                    entirety of database, most major programming languages offer 
                                    functionality for reading tree structure databases
                        -disadvantage -inflexible nature, one-to-many structure not ideal for complex 
                                       structures as it can't describe relationships in which each 
                                       child node has multiple parents nodes, tree-like organisation of 
                                       data requires top-to-bottom sequential searching that's time 
                                       consuming & requires repetitive storage of data in multiple 
                                       different entities, which is redundant
                        -IBM IMS
-network databases -extension of HD, child records given freedom to associate with multiple parent 
                    records, organised in graph structure, handle complex relations, maintenance is 
                    tedious
                   -M:N links may cause slow retrieval, not much web community support
                   -integrated data store (IDS), IDMS (integrated database management system), raima 
                    database manager, turboIMAGE


Anatomy of production app:
-dev --> build & deploy code (CICD server) --> server --> storage (persistent storage)
-user ------------------Request-----------------^
-increasing RAM, CPU (vertical scaling)
-getting more servers (horizontal scaling)
-load balancer --> forward to server having minimal amount of traffic
-servers don't run in isolation but communicate with other servers
-logging information into external server (monitored by developers)
-metric service (some metric directly come from log)
-altering service -metric feed data into altering service 


Designing YouTube:
-background -upload, search, recommendation, watch, comment, analytics, bots
-functional requirement -upload, watch 
-non-functional requirement -reliability, scaling (1 videos ---> 1000s of viewer)
-1 billion daily active users, watching --> 5 videos/ day
-upload:watching = 1:100, 1% of 5 billion = 50 million videos uploaded (top 5% videos = 90% of views)
-availability > consistency, minimum latency 
-high level design -user --> app server --> object storage (raw) (better for storing media, large file)
----> queue (message queue for compression & encoding) --> object store (encoded) <------------
                                        --> No-SQL (metadata & reference to object storage)   |
-user --> CDN service (distribute static files geographically) --------------------------------
-app server ---> cache (in-memory cache)
-not using streaming but using http request to load chunks of video 
-protocol -UDP (better in live streaming) & TCP (better in reliability)
-upload (rate limit)


Designing Twitter:
-background -1 person following other, following each other, some gets more follower, read heavy twit,  
             like, comment, re-twit
-non-functional -images, video, 500 million total users & 200 millions daily active users 
-200M --> reads 100 twits per day = 20Billion reads per day
-each twit has 140 characters = 140 bytes + metadata + videos + images = 1MB reading from storage
-20 billion * 1MB = 2 petabytes
-high level design -client ---> app server --> cache --> relational database
                      |                     ------------> object storage (Tweet ID, creator of twit, 
                      |                                   time created, image)            
                    -CDN -distribute them in CDN network (assets are static in nature) <---^
                         -using pull based CDN 
-50GB of data written per day to relational database
-read only replica of database
-50M writes/ 100000 sec = 500 writes/sec
-shading -based on user ID
-break database into pieces
-popular twits stored in cacheing (reducing latency) layer or using LRU algorithm
-app server ----> pub/sub queue ---> cluster/worker --> feed cache (storing user feed)
            ------------------------------------------------^


[CPU] <----(word transfer) fast----> [cache memory] <---(block transfer) slow---> [main memory]
                    

Hard drive component:
-disk, tracks, recording head, suspension, flexible printed circuit, carriage, voice coil motor, 
 spindle
-case mounting holes, platters, ribbon cable (attaches heads to logic board)
-tape seal, power connector, jumper, pins, jumper, SCSi interface connector, actuator, actuator axis, 
 actuator arm, slider (& head), base casting


Google's tech stack:
-search engine need web crawler to navigate to every webpage available & save --> convert to weighted 
 graph (pagerank)
-petabytes = 1 quadrillion bytes 
-files need to read & written to by many machines from many developers at google 
-high throughput (req/sec), consistency data replication
-files split in 64MB chunks before stored, each chunk assigned universal unique ID & all chunks stored 
 in at least 3 servers & 1 master server (acts as table of content, tells directory structure, maps,  
 chunks location (just like super block in linux file system))
-file chunks are distributed & makes things more complicated
-map-reduce white paper -process lot of data from google file system 
-mapping data & reducing data & shuffle step
-splitting tex file in chunk & each server receive portion of that & output from each server (list of 
 intermediate key value pairs)
-shuffle/ sort data by making sure every pair with same key value pair ends up at same server for reduce step
-reducing data (input --> intermediate key value pairs & output --> final key value pair)
-Hadoop developed by yahoo
-gRPC not natively supported in web browser, more efficient, data is binary serialised, language neutral
-rest API -text based, ease to use, language neutral
-kubernetes -


System design:
-understanding high level computer architecture of individual computers
-computer function through layered system & each optimised for varying task
-bit (0 or 1), byte (used for representing A,B,C,1,3,4)
-computer disk storage (which holds primary data) (HDD or SSD type)
-disk storage is non-volatile & maintains data without power (contains OS apps & user files)
-ranges from 256GB, 512GB, 1TB, 2TB
-HDD (80MB/sec --> 160MB/sec) & SSD (500MB/sec --> 3500MB/sec)
-RAM (random access memory serves as primary active data holder holds data structures, variable &  
 applications data, volatile memory) (4,8,16,32,64GB) (speed more than 5000MB/sec)
-cache (smaller than Ram in MBs & access time for each memory is faster than RAM offering just few
 nano seconds)
-CPU check L1 cache for data --> L2 --> L3 --> checks RAM
-cache helps in reducing average time to access data 
-CPU fetches --> decodes --> execute instructions
-motherboard is main board (component that connects everything, provides path phase allow data to 	
 flow between component
-high level architecture -CI/CD pipeline continuous integration & continuous deployment
		        -ensures code goes from repository though series of tests & pipeline checks 
		         & onto production server without any manual intervention
		        -configured with platforms like Jenkins & Github 
		        -needs to handle lots of user requests managed by load balancer & reverse 	
		         proxies like NGX
		        -user requests are equally distributed across multiple servers
		        -maintaining smooth user experience even during high traffic specs
		        -server needs to store data (external storage server that is not running on
	                 same production server instead its connected over network
		        -our servers might also communicating with other servers as well
		        -logging & monitoring system ensures everything runs smoothly
		        -keeping eye on every micro interaction, storing logs & analysing data
		        -backend tools like PM2 (logging & monitoring) & frontend platforms like 
		         sentry (capturing & report errors in real time)
		        -when logging system detect failure ---> informs altering service --> push 	
		         notification are sent to keep user informed from generic --> integrate 
	                 into platforms
			-never debug directly into production environment instead recreate issue 
                          in staging & test environment & developers don't get affected by 
                          debugging process 
			-issue needs to be identified (logging & monitoring) & searching for 
                          pattern/ anomalies point to source of problem ----> replicated into safe 
                          environment
-good design -scalability 
             -maintainability
             -efficiency
             -reliability
-heart of system design -moving data -data flows from 1 part of system to another
                        -user request seeding servers or data transfer b/w databases (optimise for 
                         speed/ security)
                        -storing data -access patterns, indexing strategies, backup solutions
                        -transforming data -taking raw data & turning into meaningful info
                                           -aggregating log files for analysis, converting user 
                                            input into different format
-CAP theorem -set of principle guid us on making informed tradeoff between 3 key components of 
              distributed system consistency, availability, partition tolerance 
             -consistency -ensures all nodes in distributed system have same data at same time
                          -change in node ---> change reflected across all nodes
             -availability -always operational & responsive to request (24/7)
             -partition tolerance -able to continue functioning even when network partition occurs 
                                  -still working even if 1 node destroyed
                                  -distributed system only achieve 2 out of 3 property 
                                  -SLO (service level object) -setting performance & availability
             -300milliseconds & 99.9% of time, SLA (service level agreement) -formal contract with 
              user/customer, minimum level of service to provide, 99.99 availability
          -fault tolerance -preparing for things go wrong (failure, attacks)
          -redundancy -having backups 
          -reliability -system works correctly & consistently 
          -speed -throughput -how much data system can handle over period of time
                             -server (request/ sec) (RPS), database (query/ sec) (QPS), data (bytes/  
                              sec)
                 -latency -how long takes to handle single request
                 -optimising for 1 can sacrifice other 
-load balancer -most popular use case of proxy servers
               -distribute incoming traffic among multiple server to avoid single point load
               -increase capacity & reliability of application
               -round robin -each server in pool get request in sequential rotating order (when last 
                             server is reach ---> loops back to 1st 1)
                            -works well for servers with similar specifications & when load is 
                             uniformly distributable
               -least connection -directs traffic to server with fewest active connections 
                                 -works well for longer task, when server load is not distributed 
                                  evenly
               -least response time -chooses server with lowest response time & fewest active 
                                     connections
                                    -effective when want to provide fastest response to request
               -IP hash -server recipes request based on hash of client IP address 
                        -ensures client consistently connects to same server & useful for session 
                         persistence in apps
               -weighted algorithm -servers are assigned weight typically based on capacity & 
                                    performance metrics
                                   -effective when servers in pool have different capabilities 
                                    (different CPUs, RAMs)
               -geographical algorithm -directs request to server geographically closest to user  
                                         based on specific regional requirements 
                                        -used in global services where latency reduction is priority 
               -consistent hashing -uses hash function to distribute data across various nodes 
               -makes sure client connects to same server every time
               -health checking -if server fails, load balancer stops sending traffic to it 
               -load balancer in different forms (hardware apps, software solutions, cloud-based)
               -F5, Citrix (hardware), eNgine X, HA-proxy (software), AWS, Microsoft azure, google  
                cloud (cloud based)
               -when load balancer goes down ----> all servers unavailable
               -redundant load balancing (using more load balancer in pairs)
               -auto scaling & self healing system
               -DNS failover --> reroute traffic away from IP address, no longer accepting 
                connections (failed load balancer to preconfigured standby IP)
-types of databases -each designed for specific task & challenges 
                    -relational databases -organised cabinets & all files neatly sorted into 
                     different drawers & folders
                    -all SQL databases use tables for data storage & use SQL as query language
                    -great for complex transaction, complex queries & integrity, 
                    -ACID compliant -atomicity (transaction all/nothing)
                                    -consistency (after transaction --> database should be in   
                                     consistent state)
                                    -Isolation (transaction should be independent)
                                    -durability (data is there to stay, once transaction is completed)
                    -NoSQL -drops consistency property from ACID
                    -mongoDB (document based), Cassandra, Redis (key value pairs), Neo4J (graph 
                     based)
                    -schema less, no foreign keys b/w tables, better fr unstructured data, ideal for 
                     scalability, quick iteration, simple queries
                    -vertical scaling -increase CPU performance, adding more RAM, add more disk 
                                       storage, upgrading network, single point failure
                    -horizontal scaling -database sharding, replication, redundancy built in
                                        -more complex & efficient for long term
                                        -distribute data across different cluster of machines
                                        -need load balancer to distribute traffic
                    -Sharding -distributing different portions shards of datasets across multiple 
                               servers, split data into multiple chunks
                              -range based sharding -distributing data based on range of given key
                              -directory based -lookup service to direct traffic to database  
                              -geographical based -based on location 
                    -replication -keeping copy of data on multiple servers for high availability 
                                 -masters (read/write) -------- slave (read only)
                                                       -------- slave (read only)
                                 -master (read/write) -------- master (read/ write)
                    -cacheing -not only for web servers but also in-memory databases Redies
                              -cache frequent queuing & boost performance
                    -indexing -another way to boost performance of database, creating index for 
                               frequently accessed column ----> speed up retrieval times)
                    -query optimisation -for fast data access 
-API design -CRUD operations -create -add new product --> send post request to /api/products
                             -read -get request to /api/products
                             -update -patch/ put request /api/products/:id
                             -deleted -removing product /api/products/:id
            -communication HTTP/ web socket, data transport mechanism (XML, JSON), protocol buffers
            -API paradigms -REST -representational state transfer 
                                 -its stateless, each request form client to server must contain all 
                                  information needed to understand & complete request, uses standard 
                                  HTTP methods (get, post, put, delete)
                                 -consumable by different clients, browser, mobile apps
                                 -lead to over fetching & under fetching of data 
                                 -more endpoints may required to access specific data 
                          -GraphQL -avoids over fetching & under fetching
                                   -strongly typed schemas based queries
                                   -queries can impact server performance
                                   -responds to http200 code errors
                          -gRCP -google remote procedure call, built on http/2
                                -multiplexing & server push
                                -


kernel with speed tweak patches. Like pfmod, xanmod or liquorix. When the linux desktop doesn't have to wait on resources, it feels extremely fast. Even low mem/cpu desktops will feel quicker when things can respond without interruptions, micro stutters, hardware pauses, and audio/gfx lags are gone.


Systemd's obsession with boot times which sometimes come to the detriment of other desirable things though.

The scheduler. To put it simply windows traditionally doesn't pin a thread to a specific core but it just swaps them around all the time. So a thread might execute a few instructions in one core, then halt until data is loaded, the core switched to another thread and then when the data is loaded the original thread moves to another core which means it needs to flash the original cache and then load the data on the other core. Microsoft implemented a parking system in windows 10 which is still more convoluted than it needs to be but afaik applications need to specifically target it. And most stuff that exists doesn't, including background processes that you run all the time. So that's a lot of latency wasted. 

I/O. Oh my god windows wastes so much I/O when it loads stuff. There is absolutely no reason why using a high end SATA ssd should have perceptible speed differences with using an NVME drive at conventional usage but windows also manages to do that.

Nothing to do with systemd, Linux distros long before potterware came about typically booted up faster on identical hardware. Still the case today... I use slackware with the standard rc.d init, and it's ridiculously fast compared to even a Windows 10 install.

No antivirus, no registry, no I/O performance, and no complete programs.


-lightning, USB3.0, type C, thunderbolt
-video -title, media ID, player ID, analytic ID, stream type, viewport, dropped frame, BW downlink, 
        buffer health, duration, client ID, feed ID, stream Host, provider, resolution/ mode, version


=-----------------------------------Data structures & algorithm---------------------------------------=


Data types:
-primitive data type -integer -byte (1 byte), long (8 bytes), short (2 bytes), int (4 bytes)
                     -float -float (4 bytes), double (8 bytes)
                     -character -char (2 byte)
                     -boolean -bool (1 byte, but makes use of 1 bit of it)
-non-primitive data type -list, dictionary, tuple, queue, stack, array


Java Mastery:
-Core Java (Must Master)
Java SE (Standard Edition)

Java Syntax, Data Types, Loops, Conditionals
OOP Principles (Encapsulation, Inheritance, Polymorphism, Abstraction)
Exception Handling
Collections Framework (List, Set, Map, Queue)
Generics
Multithreading & Concurrency (ExecutorService, CompletableFuture)
I/O (java.nio, java.io)
JDBC (Java Database Connectivity)
Functional Programming

Lambda Expressions
Streams API
Optional API
Method References
JVM & Performance

JVM Internals (Class Loading, GC, Memory Management)
Profiling Tools (JVisualVM, JFR, JConsole)
JIT Compilation
Build Tools
Maven – Dependency management, project building
Gradle – More advanced, Groovy/Kotlin-based alternative to Maven
Logging Frameworks
Log4j / SLF4J / Logback – Essential for logging in production applications
Testing Frameworks
JUnit / TestNG – Unit testing
Mockito – Mocking dependencies
AssertJ / Hamcrest – Advanced assertion libraries
Selenium – UI testing for web applications
Web Development
Spring Framework (Must Learn)

Spring Core (Dependency Injection, Beans)
Spring Boot (Auto-configuration, Microservices)
Spring MVC (REST APIs, Web Applications)
Spring Data (JPA, Hibernate)
Spring Security (Authentication, JWT, OAuth2)
Spring Cloud (Microservices, Service Discovery, Resilience)
Spring WebFlux (Reactive Programming)
Jakarta EE (Enterprise Java)

Servlets & JSP
JAX-RS (REST APIs)
CDI (Contexts and Dependency Injection)
EJB (Enterprise JavaBeans)
JPA (Java Persistence API)
JMS (Java Messaging Service)
Database & ORM
Hibernate (JPA Implementation)
Jooq / MyBatis (Alternative to Hibernate for complex queries)
PostgreSQL / MySQL / MongoDB / Cassandra (Databases)
Flyway / Liquibase (Database versioning/migrations)
Microservices & Cloud
Spring Cloud (Netflix OSS, Service Discovery, Circuit Breaker)
Docker (Containerization)
Kubernetes (Orchestration)
gRPC (For efficient inter-service communication)
Kafka / RabbitMQ (Message Brokers)
REST APIs & GraphQL
Networking & Security
Netty – High-performance networking (TCP, HTTP)
Bouncy Castle / OWASP – Cryptography, Security
JWT / OAuth2 – Authentication & Authorization
Big Data & Streaming
Apache Kafka – Event streaming
Apache Spark – Big data processing
Flink / Storm – Real-time stream processing
AI & Machine Learning in Java
Deeplearning4j (DL4J) – Deep learning
WEKA – Data mining & ML
Game Development
LibGDX – 2D/3D Game Development
JMonkeyEngine – Advanced 3D Game Engine
GUI Development
JavaFX – Modern Java UI framework
Swing (Legacy) – GUI applications
DevOps & CI/CD
Jenkins / GitHub Actions / GitLab CI/CD – Automating builds & deployments
Terraform / Ansible – Infrastructure as Code
Low-Level & High-Performance Computing
Project Panama – Direct C/C++ Interoperability
Project Loom – Lightweight concurrency (Virtual Threads)
JMH (Java Microbenchmark Harness) – Performance tuning


C:
-datatype -primary -integer, characters, floating points, double floating points, void
          -derived -function, array, pointer, reference
          -user defined -class, structure, union, enum, typedef
-structure -keyword struct
           -occupies higher memory space
           -variable associate with structure, compiler allocates memory for each member, size of 
            structure greater than equal to sum of seize of its members
           -each member in structure is assigned unique storage area of location
           -altering value of member will not affect other members of structure
           -individual members can be accessed at time & flexible array is supported 
           -several members of structure can initialised at once
-union -keyword union
           -variable associate with union, compiler allocates memory by considering size of largest 
            memory, size of union = size of largest member
           -memory allocated is shared by indiwvail members of union
           -altering value of member will affect other member values
           -only 1 members can be accessed at time
           -only 1st members of structure can initialised 
           -occupies lower memory space & flexible array is not supported 
-array -behaves like build in data type
       -holds group of same element under single name
       -can't ave array of array
       -memory occupied by array is multiple of number of index
       -can't take part in complex data structure
-jump statement -used to jump from 1 part of code to another altering flow of program
                -used to transfer program control to somewhere else to program
                -break, continue, goto, return
-type conversion -type safety -ensure data is stored & processed in correct data type, avoiding 
                               potential type mismatching & type errors
                 -improved code reusability -by explicitly converting b/w data b/w different types --> 
                                             make intent of your code clearer & easier to understand
                 -improved performance -optimise & performance (converting to more efficient 
                                        data type processing
                 -improved data manipulation, data storage
                 -loss of precision -converting data from larger data type ---> smaller data type
                 -overflow & underflow, confusing syntax, increased complexity, slow performance
-return 0 -main function, program executed successfully
          -user-defined function is returning false
-return 1 -main function, program is not executed & some error occurred
          -user defined function returning true


Types of data structure:
-primitive data structure -most basic type, used to representing simple values  
                          -integer, float, character, boolean
                          -pre-defined by language itself
                          -sorted in stack, size depends on type of data structure
                          -used to call all methods
                          -copy is created for data, completely separate allocation is done for copy
                          -changes made to copy not reflected in original
                          -contain some value & can't be NULL
-non-primitive structure -linear data structure -arrays, linked list, stack, queue
                         -non-linear data structure -tree, graphs
                         -pre-defined by language itself
                         -sorted in stack but original element in heap, size is not fixed
                         -can't be used to call methods
                         -copy is create new reference variables but both point to same object in heap
                         -changes made to copy trace back to original
                         -consits of NULL value
-user defined -defined by users
-derived types -derived from primitive, built-in datatypes


Classification data structure -data structure -linear -static -array
                                                      -dynamic -queue, stack, linked list
                                              -non-linear -tree, graph
                              -linear -elements arranged sequentially/ linearly, each element 
                                       attached to previous & next adjacent element


Java:
-file name (Demo.java), class name: Demo --> good practice to use initial character as capital)
-public -keyword, used to access class from anywhere
-function -collection of code, use again & again, functions/method
-void -void keyword specifies that method shouldn't have return value
-string[] args -array of sequence of characters ("string") that passed to main function
               -after compiling .class file saved in current location 
               -change location, use -d (destination) 
               -javac -d <path> Demo.java
               -echo $PATH -evert command looks for this location before executing (environment 
                            variables)
               -class name & file name should be same, if don't want to make class name as file name 
                ---> should be public
               -package com.abc & package com.def -------> com 
                                                             |--abc --file1, file2
                                                             |--def --file1, file2
               -System.out.println("hello") --> print output on standard output stream (terminal)
                                            -system (class), out (var), println (function)
                                            -println -adds new line
                                            -print -does not add new line
               -Scanner input = new Scanner(system.in) -scanner (class allows to take input), new 
                (creating object), system (take input from standard input)
               -primitive -any data type cannot be broke further
                          -int roll_no = 64; ---> 4 bytes
                          -char letter = 'r'; 
                          -float marks = 5.63f ---> 4 bytes
                          -double large_decimal_numbers = 424624.1443; ---> 8 bytes
                          -long large_integer = 424252225L; ---> 8 bytes
                          -boolean check = true;
                          -string is written in double quotes whereas specifying char, write int in 
                           single quotes
                          -all decimal values that use are by default of double datatype, store in 
                           float use "f", same for int & long
                          -float marks = 3.5f
                          -double large_decimal_numbers = 32353452234.342342
                          -int roll_no = 63; (by default)
                          -long large_integer = 2342344532522L;
                          -Integer -wrapper class -provides additional functionality
                                                  -converts primitive datatype to object
                          -comment -lines we comment are ignored by java & not be executed 
                          -int a = 10 (a is identifier & 10 literal)
                          -literal -syntactic representation of boolean, character, numeric, string 
                                    data, 10 is integer literal
                          -identifier -names of variables, method, classes, packages & interfaces
                                      -int a = 232_342_424; (value of a will be 232342424, underscore 
                                       ignored)
                                      -564.12345678 ----round off----> 564.12345
                                      -if give float very big, round off value which gives floating 
                                       point error
-type casting & type checking -2 datatypes are automatically converted
                              -assign value of smaller datatype ----> bigger datatype & 2 datatype must 
                               be compatible
                              -byte ---> short ---> int ---> long ---> float ---> double
                              -int j = 100; ---> 100
                              -long l = j; ---> 100
                              -float f = l; ---> 100.0
-narrowing/ explicit conversion -assign value of larger datatype ---> smaller datatype 
                                -explicit type casting, narrowing
                                -double ---> float ---> long ---> short ---> byte
                                -double d = 100.04; ---> 100.04
                                -long l = (long)d; ---> 100
                                -int j = (int)l; ---> 100
-automatic type promotion in expression -while evaluating expression, intermediate value may exceed 
                                         range of operands & expression value will be promoted
                                        -some conditions of type promotion -java automatically promotes
                                         each byte, short, char to int when evaluating expression
                                        -long float, double whole expression is promoted to long float, 
                                         double
                                        -after solving (f*b) + (I/c) - (d*s);
                                                        float + int - double = double
-explicit type casting in expressions -store large value into small data type
                                      -byte b = 50;
                                      -b = (byte)(b*2); ----> type casting int ---> byte


Data structure:
-named location that can be used to store & organise data
-modification is easy, requires less time, space storage memory space, data representation is easy
-easy access to large to large databases
-family tree, array (collection of elements stored in contiguous memory locations)


Algorithm:
-collections of steps to solve particular problems
-input ------> [algorithm] -------> output
-increased speed, improved accuracy, improved scalability, reduced cost, increased security
-unambiguous, effective, feasible, input & output, deterministic, finite
-types of algorithm -brute force algorithm, divide & conquer, dynamic programming, greedy approach, 
                     backtracking algorithm
-all 25 algorithm -searching (linear search, binary search, depth first search, breadth first search)
                  -sorting (insertion, heap, selection, merge, quick, counting)
                  -graph (Krushal, Dijkstra, bellman ford, Floyd waarshall, topological, flood fill, 
                          lee)
                  -basic (Huffman compression, Euclid, union)
                  -array (Kadane, Floyd cycle detection, KMP, quick select, Boyer more majority vote)
-linear search -1 by 1 examines elements of array to find value


Registered vs static variable:
-register variable -CPU register, scope = function, lifetime is function call, access speed is fast, 
                    typical use (temporary values)
-static variable -memory, scope = global, lifetime is program execution, access speed is slow, typical 
                  use (global data)


Flow of control:
-flow chart -visualisation of our thoughts process or algorithm & represent them diagrammatically
-oval (start/stop), parallelogram (input/output), rectangle (processing, assignment of value to 
 variable, constant, parameter), diamond (condition), ----> (flow direction of program), hexagon  
 (beginning of repetition), double rectangle (use of algorithm specified outside program), circle (used 
 to combine flow lines, connectors), semi-circle (delay)
-pseudo code -just way to unite steps which is human readable format (not code)
             -mainly meant for human reading not for machine reading


DSA:
-writing code that is both time & memory efficient
-commonly asked in questions involved DSA in coding job interviews
-linear data structure -static (array), dynamic (queue, stack, linked list)
-non-liner data structure -tree, graph


Laptop:
-8-blade arc flow fans & 3 fan outlets
-MUX switch
-wifi 6
-RGB backlit keyboard
-2-way AI noise cancelation
-dolby Atmos
-hi-res audio
-Nvidia geforce RTX


Static memory allocation vs dynamic memory allocation:
-static -variable gets allocated permanently, till program executes or function call finishes
        -done before program execution
        -uses stack for managing static allocation of memory
        -less efficient
        -no memory reusability
        -once memory allocated, memory size can not change
        -


Linkedin list:
-array -not continuous memory allocation
-linked list is not continuous memory allocation
-collection framework present in java.util package 
-class is implementation of LinkedList data structure (linear data structure where elements not stored 
 in contiguous locations & every element is separate object with data part & address part
-elements linked using pointers & addresses & each element (node)
-no need to increase size, internally implemented using doubly linked list data structure
-breaking down boxes into separate boxes
-single linked list (3->4->5->8->9-> null), acts as dynamic array & no need specify size when 
 creating it, size of list automatically increases when dynamically add & remove items
-doubly linked list contains extra pointer (previous pointer)
-every single item knows about next item
-head & tail 
-singly-linked list [][]-->[][]-->[][]-->[][]-->[]
-doubly-linked list []<--[][][]<-->[][][]<-->[][][]-->[]
-circular-linked list [][]-->[][]-->[][]-->[][]
-nodes cannot be accessed directly 
-dynamic size -vector, size grow/shrink dynamically & no need for  setting initial size
-efficient insertions & deletions elements in middle of list only need to change links b/w 
 elements, rather than shifting all elements after insertion/deletion point
-flexible iteration in both direction each element has reference to both predecessor & successor 
 elements
-linkedList (traverse list to reach desired element) slower performance than ArrayList 
 (accessing by index) when accessing individual elements
-requires more memory than ArrayList as each element requires additional memory for links to its 
 predecessor & successor elements


Binary Trees:
-linked-list can implement binary trees
-data can be any bytes, applies to non-binary trees
-no random access, traverses node must be tracked manually


Sorting:
-simple & easy sorting (for small data)
-bubble sort -never (unless teaching concepts) -too slow, O(n²)
-selection sort -never (unless memory is limited)	-O(n²), but uses O(1) space
-insertion sort	-use for small datasets (≤ 10,000 elements) or nearly sorted data,	faster than Bubble/
                  selection sort, O(n) in best case
-fast sorting (for large data) 
-merge sort -large datasets need stability (linked lists, external sorting), O(n log n), stable, works 
             well for big data
-quick sort -general-purpose sorting (best for average cases), O(n log n) average, fast, worst case 
             O(n²)
-heap sort -when memory limited & constant time deletion needed, O(n log n), good for priority queues
-special cases
-counting sort -when numbers are in limited range (0-1000), O(n + k), super fast & requires extra 
                memory
-radix sort -when sorting large numbers like phone numbers, ZIP codes, IDs	O(nk), faster than O(n log n) 
             if k (digit length) is small
-bucket sort -when data is uniformly distributed,	O(n), useful for floating-point numbers


Big O notation:
-mathematical notation tells upper limit of function telling relationship b/w time & input size
-time complexity cannot exceed O(n^3)
-can be O(n^3), O(n^3), O(n^3), O(n^3), O(log n)
-performance of algorithm as amount of data increase
-machine independent 
-ignore smaller operations O(n+1) --> O(n)


Arrays:
-collection of variables of similar data types, fixed length/ size
-data structure use to store collection fo data
-for 5 integer its simple, for 5000 integer numbers use array
-int[] arr = new int[5];
-int[] roll_no (declaration of array, getting defined in stack)
-roll_no = new int[5] (initialisation of array, actual memory allocation happens object created in heap 
 memory)
-dynamic memory allocation -means at runtime/ execution time memory is allocated
-[arr] stack ------> (1,2,3,4,4) heap
-internally in java, memory allocation totally depends on JVM whether continuous or not
-objects are stored in heap memory
-JLS (java language specifications) heap memory are not continuous
-dynamic memory allocation, array object in java may not be continuous (depends on JVM)
-elements are ordered & each has specific & constant position (index)
-index of array -arr[0], arr[1], arr[2], arr[3]
                -it create object in heap memory of array side 5
                -if don't provide values in array, internally by default it stores [0,0,0,0,0] for 
                 above size of array
-primitives (int, char) are stored in stack
-all other objects are stored in heap memory
-arrays to string (array) ---> internally uses for loop & gives output in proper format
-arrays are mutable, string are immutable
-can be created using both primitive datatype, non-primitive datatypes
-initialise variable & get initialised in stack during compile time
-stack (number)(reference variable initialised) & heap (n[0], n[1], n[2], n[3], n[4], n[5])
-2D array -visualised as matrix has rows & column, total elements = rows * column
          -declare variable in stack during compile time --> new objects created/ initialised in heap 
           memory during runtime
          -int[][] arr = new int[size][]


ArrayList:
-part of collection framework & present in java.util.package
-provides dynamic arrays in java, slower than standard arrays
-Arraylist <integer> list = new Arraylist <> ();
-size is fixed internally
-internal working of array list -make array list of double size of array list initially
                                -old elements are copied in new Arraylist
                                -old ones are deleted 
-contain many elements & initial size is specified, size is fixed but not permanent
-created using primitive datatypes, created using objects, wrapper classes
-used when don't know how many elements to add
-when don't have enough space --> java create new array-list with new size --> copy old list to new 
 list & delete old list


OOP:
-programming paradigm organises code into objects & classes, makes it modular, reusable, maintainable
-encapsulation -data hiding (private fields, public methods)
               -protects data using private fields & public getters/setters
               -private int balance;
-abstraction –hiding unnecessary details
             -hides implementation details (abstract class, interface)
             -abstract void start();             
-inheritance –code reusability (child classes inherit properties from parent classes)
             -child class inherits from parent class (extends)
             -class dog extends animal {}
-polymorphism –one interface, multiple implementations (method overriding, method overloading)
              -void draw() {} in circle & square


Object oriented programming:
-code reusability -using objects & classes
-enhances code organisation -provides clear & logical structure --> easy to understand, maintain, debug
-supports DRY (don’t repeat yourself) principle
-object -basic unit of OOP represents real-life entities, objects perform your code, part of code 
         visible to viewer/use
        -state -represented by attributes of object, reflects properties of object
        -behaviour -represented by methods of object, reflects response of object to other objects
        -identity -unique name given to object enables it to interact with other objects
        -method - collection of statements perform specific task & return result to caller
-class -template for object & object is instance of class, creates new data type used to create objects
       -
-constructor -
-inheritance -mechanism where 1 class allowed to inherit features (fields & methods) of another class 
             -using extends keyword
             -superclass -class whose features inherited (superclass)
             -subclass -class inherits other class (subclass), subclass add its own fields & methods in 
                        addition to superclass fields & methods
             -define more generic class & then go with as many sub-classes as you need
-polymorphism -ability of OOP languages to differentiate b/w entities with same name efficiently
              -using signature & declaration of these entities, ability to appear in many forms
              -overloading -
              -polymorphism ----> static ----> method overloading ----> constructor overloading
                                                                  ----> operator overloading
                            ----> dynamic ----> method overriding 
-abstraction -hides unnecessary details but shows essential details
             -solves issue at design level, focus of external lookout
             -implemented using abstract classes & interfaces hide code complexities
             -process of gaining information
             -objects are encapsulated --> helps in abstraction
             -makes easier to work with only selected behaviour using simplified & high level tools
-encapsulation -hides code & data into single entity & protect from outside world
               -solves issue implementation issue
               -focus on internal working, implemented by access modifiers (public, private, protected)
               -process of containing information
               -getters & setters method to hide data 
               -keeping information within class but reveals selected information
-packages -containers for classes, stored in hierarchical
          -explicitly imported into new class definitions
          -both naming & visibility control mechanism
          -java run-time system uses current working directory as its starting point --> if package is 
           in subdirectory of current directory --> found
          -specify directory path by setting CLASSPATH environmental variable
          -use -classpath option with java & javac to specify path to classes
          -when package is imported, only items within package declared as public -->  available to 
           non-subclasses
-access controls -how member can be access, access modifier attached to declaration
                 -
                 -public -class, package, subclass (same pkg), subclass (diff pkg), world (diff pkg & 
                          not subclass)
                         -least restrictive
                 -protected -class, package, subclass (same pkg), subclass (diff pkg)
                 -no modifier -class, package, subclass (same pkg)
                 -private -class, most restrictive


Recursion:
-function/method -collection of code can be used again & again
-memory management -stack -when declare variable (int a (stack), 10 (heap)
                   -heap -variable pointing to object of variable are stored in heap (heap)
-all function have 1 thing in common (body & definition)
-function calling another function
-recursion -function that calls itself
           -helps in solving bigger/ complex problems in simple way
           -convert recursion solutions into iteration 
           -takes space as well, space complexity not constant because each function call is taking 
            same memory (recursive call)
           -helps in breaking down bigger problems into smaller problems
           -helps in solving bigger/ complex problem in simple way
           -convert recursion solution into iteration & vice versa
           -takes space as well, space complexity not constant as each function call is taking some 
            memory recursive calls
           -helps in breaking down bigger problem into smaller
           -recursive calls & functions call linked to 1 another is visualising recursion
-iteration -means not using any function calls, loops for loops
-base condition -condition where our recursion will stop making new calls
                -simple condition, needs to be returned
-stack overflow error -no base condition, getting error --> function call keeps happening
                      -stack keep getting filled again & again
         -every call takes memory even though its same function or different (doesn't matter)
         -calling function more than 1 time simultaneously, again & again every function cal will take 
          some memory in stack
         -memory exceeds of limit --> throw error 
-understand & approach problem -identify & break down problem into smaller
                               -form recurrence relation of write if needed
                               -draw recursive tree
                               -about tree -see flow of function
                                           -how they are getting stack
                                           -identify & face on left tree calls & right tree calls
                                           -draw trees & pointer again & again using pen & paper
                                           -use delrigepr to see flow
                               -values are returned at each steps & what type of value are returned 
                                (int, string) see where function call will come out of & in end you 
                                will come out of main function
-binary search using recursion -dividing problem into half, problem is divided into sub-problems, 
                                definitely can apply binary search in recursion
-


Sorting:
-bubble sort -process of arranging items systematically
             -simplest algorithm works be repeatedly swapping adjacent elements if they are in wrong 
              order
             -sinking sort/ exchange sort
             -complexity -space complexity -O(1), no extra space required like copying array is not 
                                            required, in-place sorting algorithm
                         -time complexity -best case -array is sorted, when j never swaps for value of 
                                                      I --> array is sorted, end program
                                                     -best case comparison = N-1 -> N
                                                     -constants are ignored, don't want exact time, 
                                                      just mathematical function 
                                          -worst case -sorting descending order array-> ascending order
 
                                          -O(n2)
                         -advantages -easy to understand & implement, doesn't require any additional 
                                      memory space
                                     -stable ----> elements with same key value maintain their relative 
                                      order in sorted output
                         -disadvantages -time complexity of O(n2), very slow for large data sets
                                        -no or limited real world applications

-insertion sort -complexity -worst case O(n2) (descending sorted)
                            -best case O(n) (already sorted)
                            -adaptive -steps gets reduced if array is sorted, no swaps are reduced as 
                             compared to bubble sort
                            -stable sorting algorithm
                            -used for smaller values of n -works good when array is partially sorted
                            -takes part in hybrid sorting algorithm
-selection sort -select element & put it on its correct index
                -select maximum element & put it right index or vice versa
                -4,5,1,2,3 ---> 4,3,1,2,5 ---> 2,3,1,4,5 ---> 2,1,3,4,5 ---> 1,2,3,4,5 (sorted)
                -complexity -n-1, n-2, n-3.......1, 0 
                            -sum = (n2-n)/2 (neglect dominating term)
                            -worst case O(n2)
                            -best case O(n2)
                            -not stable sorting algorithm
                            -performs well on small lists
-cyclic sort -when given numbers from range 1 to N --> use cyclic sort
             -3,5,2,1,4
             -every unique item is only getting swapped once
             -we aren't incrementing i when swapping ---> might result in more than n iteration of loop
             -worst case --> N-1 (swap) ----> (2N-1) ---> O(n) linear
-quick sort -divide & conquer picks element as pivot & partitions given array around picked pivot by 
             placing pivot in its correct position in sorted array
            -select element from array as pivot, choice of pivot vary (first element, last element, 
             random element, or median)
            -rearrange array around pivot, after partitioning, all elements smaller than pivot will be  
             on its left & all elements greater than pivot on right, pivot then in correct position &  
             obtain index of pivot
            -recursively call -recursively apply same process to 2 partitioned sub-arrays (left & right 
                               of pivot)
            -base case -recursion stops when only 1 element left in sub-array, as single element is 
                        already sorted
            -time complexity -best case -(Ω(n log n)) pivot element divides array into 2 equal halves
                             -average case -(θ(n log n)) pivot divides array into 2 parts, not 
                                            necessarily equal
                             -worst case -(O(n²)) when smallest or largest element is always chosen as 
                                          pivot (sorted arrays)
                             -auxiliary space -O(n) due to recursive call stack
            -advantages -efficient on large data sets, low overhead, only requires small amount of 
                         memory to function, cache friendly as work on same array to sort & don't copy 
                         data to any auxiliary array
                        -fastest for large data when stability not required
                        -tail recursive & all tail call optimisation can be done 
            -disadvantages -worst-case time complexity of O(n2) occurs when pivot chosen poorly
                           -not good choice for small data sets
                           -not stable sort, if 2 elements have same key, their relative order won't be  
                            preserved in sorted output in case of quick sort, swapping elements  
                            according to pivot’s position (without considering original positions)
            -Applications of Quick Sort
Efficient for sorting large datasets with O(n log n) average-case time complexity.
Used in partitioning problems like finding the kth smallest element or dividing arrays by pivot.
Integral to randomized algorithms, offering better performance than deterministic approaches.
Applied in cryptography for generating random permutations and unpredictable encryption keys.
Partitioning step can be parallelized for improved performance in multi-core or distributed systems.
Important in theoretical computer science for analysing average-case complexity and developing new techniques.
-merge sort -divide-and-conquer approach, works by recursively dividing input array into smaller   
             subarrays & sorting subarrays ---> merging back together to obtain sorted array
            -time complexity -best case -O(n log n) array is already sorted or sorted
                             -average case -O(n log n) array is randomly ordered 
                             -worst case -O(n log n) array sorted in reverse order
                             -auxiliary space: O(n) -additional space is required for temporary array 
                                                     used during merging
            -advantages -stable, maintains relative order of equal elements in input array
                        -worst-case time complexity of O(N logN) ---> performs well on large datasets
                        -simple to implement & straightforward
                        -naturally parallel -independently merge subarrays makes suitable for parallel 
                                             processing
            -disadvantages -space complexity -merge sort requires additional memory to store merged 
                                              sub-arrays during sorting process
                           -not in-place algorithm, requires additional memory to store sorted data
                           -slower than quick sort is more cache friendly as it works in-place
            -applications -sorting large datasets
                          -external sorting (when dataset too large to fit in memory)
                          -used in library methods of programming languages (variation TimSort used in 
                           python, java android & swift, preferred to sort non-primitive types is   
                           stability (Arrays.sort uses QuickSort while Collections.sort uses MergeSort)
                          -preferred algorithm for sorting linked lists
                          -easily parallelised as we can independently sort subarrays & then merge
                          -merge function efficiently solve problems like union & intersection of 2 
                           sorted arrays
-


Strings & string-builder:
-strings -collection & sequence of character
         -immutable, slow performance, thread safe, fewer methods
         -creates new object
-string-builder -mutable, fast, not thread safe, more methods
                -modifies in place
-reference variable are in stack & pointing towards objects in heap
-string is most commonly used class in java class library (everything starting with capital letter is 
 class)
-every string you create is actually an object of type script
-datatype reference variable = object
-stack memory -declaring variable (int a = 10) reference variable stored in stack memory
-heap memory -reference variable stored in stack memory pointing to object of that variable stored in 
              heap memory 
-memory allocation -specifies memory address to program
-static memory allocation -performs type checking at compile time 
                          -source -----compile time------> compiler
                          -errors will show at compile time
                          -declare datatype before you use it
                          -more control & runtime errors are reduced 
-dynamic memory allocation -performs type checking at runtimes
                           -source -----compile time------> compiler ---runtime---> 
                           -errors might not shown at till program runs
                           -no need to declare datatype of variable
                           -saves time in writing code but might give errors at runtime
-garbage collection -more than 1 reference variable can point to same object
                    -any changes made in object of reference variable will reflected to all other 
                     pointing to same object
                    -if object without reference variable then object will be destroy by garbage 
                     collection
                    -garbage collection works
-strings -pile or sequence of characters 
         -non-primitive datatype, immutable for security purpose, changing object & modify object
         -every starts with capital letter = class
         -most commonly used class in java class library
         -every string created is actually object type string
         -string pool -separate memory structure inside heap
         -comparator -actually checks for value & reference variable, reference variable pointing to 
                      same object
-" " + "a" = "a"
-"a" + "b" = "ab"
-"ab" + "c" = "abc"
-new object is being created every-time & are immutable 
-waste of memory as no reference variable, time complexity = O(n2) worst
-string builder -1 object is made & changes are done in that object only & reference is also same 
                -


Conditional & loops:
-if-else -used to check condition, checks for boolean condition true & false
-multiple if-else -executes 1 condition from multiple statements 
-loops -used to iterate part of program several times
       -for loop -used when how many times loop will iterate
       -while loop -used don't know & until condition is satisfied
                   -entry controlled loop
                   -no semicolon required at end of while (condition)
       -do while loop -used when executing our statement at least 1 time
                      -exit controlled loop
                      =semicolon is required at end
                      -control loop because it checks condition after executing of statement
-switches -cases 1,2,3,4, condition & break & continue
          -default case -execute when none of above does, (if default not at end put break after it)
          -duplicate cases not allowed
          -nested switch case


Methods/function:
-method -block of code which only runs when its called
        -define code once, use it many time
-return type -return statement cause program control to transfer back to caller of method 
             -may be primitive type like int, char, void type (returns nothing)
             -type of data returned by method must be compatible with return type specific method
             -if return type of some method is boolean, can't return any integer
             -variable receiving value returned by method must also be compatible with return type 
              specified for method 
-primitive data type -int, short, char, bytes (just pass value)
-object & reference -passing value of reference variable
-scope -function scope -variable declared inside method/ function scope (means inside method) can't be 
                        accessed outside method
-block scope -variables initialised outside block can be updated inside box
             -variables initialised inside block can't be updated outside box but can reinitialised 
              outside block
             -variables declared outside block updated inside block updated outside block
-loop scope -variable declared inside loop are having loop scope
-shadowing -practice of using variables in overlapping scopes with same name where variable in low 
            level scope overrides variable of high level scope, variable at high level scope is 
            shadowed by low level scope variable
-variable arguments -used to take variable number of arguments, method that takes variable number 
                     arguments is varargs method
-function overloading -happens when 2 functions have same name, allows having different arguments with 
                       same method name, Armstrong number
                      -at compile time, decides which function to run


Time complexity:
-function gives relationship about how time will grow as input size grows
-larger input size, time taken by linear search > time taken by binary search
-smaller input size, time taken by linear search < binary search (keeps on increasing)
-consider case having large number of input size, worst case ----> tell if algorithm is efficient in  
 long term/ not
-worst case analysis ----> tells real world scenario
-always look for worst case scenario
-always take large input size/ infinity into consideration


Stack:
-linear data structure, follows particular order in operations performed
-order is LIFO (last in first out)
-region of memory that is used for storing function call information, local variables, temporary data
-managed by compiler or runtime environment
-heap -region of memory used for dynamic memory allocation
      -doesn't follow specific order & allows more flexible memory management, memory allocation on 
       heap must be explicitly allocated & deallocated by programmer
-entering & retrieving data is possible only from 1 end (pop & push)
-uses algorithm like tower of Hanoi, tree traversal, recursion
-implemented through array/ linked list
-if allocated space for space for stack is full & try of add more elements ----> stack overflow
-used to evaluation & conversion of arithmetic expressions
-used for parenthesis checking
-reversing string, stack is used as well
-used in memory management
-used in processing function calls
-convert expressions from infix ---> postfix
-used to perform undo & redo operations in word processors
-used in virtual machines like JVM
-used in media player, useful to play next & previous song
-operations -push -elements pushed onto top of stack, adding new element to top on stack
            -pop -top element removed from stack by performing pop
            -peek -top element inspect without removing rom stack using peek operations
            -isEmpty -check made to determine if stack is empty
            -size -number of element in stack determined using size operation


Package in java:
-mechanism to encapsulate group of classes, sub-packages, interfaces
-putting related classes into packages ----> write import class from existing packages & use in our 
 program
-user-defined package
-built-in packages -swing, util, net, io, AWT, lang, javax
-import package.name.*;
-javac Welcome.java (compile welcome.java file)
-javac -d . Welcome.java (creates welcome.class file ---> place class file in appropriate package 
 directory)
-java FirstPackage.Welcome (create new folder FirstPackage)
-MyProject/ ----> com/example/utils/ ----> com/example/utils/MyClass.java
-package com.example.utils;
-compile manually using the terminal
-javac -d . com/example/utils/MyClass.java Main.java
-java Main


Queue:
-linear data structure follows FIFO (first in first out), data item stored first will be accessed first
-entering & retrieving data is not done from only 1 end
-reversing 1st K elements of queue, few basic operations performed in queue are enqueue, dequeue, 
 front, rear
-to remove last element of queue all elements inserted before new element in queue must be removed
-queue is ordered list of element of similar datatype
-applications -queue is used for handling website traffic
              -helps maintain playlist in media players
              -used in OS for handling interrupts
              -helps in serving requests on single shared resource (printer, CPU task scheduling)
              -used in asynchronous transfer of data (pipes, file IO, sockets)
              -used for job scheduling in OS
              -upload multiple photos/ videos in social media
              -send email queue data structure, handle website traffic
              -switch b/w multiple applications in windows OS
-operations -enqueue -elements added to back, adding new element to end
            -dequeue -front element can be removed, effectively removing 1st element
            -peek -front element inspected without removing
            -isEmpty -check made to determine if queue is empty
            -size -number of elements in queue determined


Bitwise operators + number system:
-& (And)
-| (or)
-~ (not)
-^ (xor)
-<< (left shift)
->> (right shift)
-int a = 10 (internally in server that running its all bunch of 0s & 1s)
-computers only understand only binary language
-don't code in 0 & 1 --> become very complex, use programming languages
-numbers are stored internally (no system)
-base 10, base 8, base 16, base 2
-base -base basically means how many numbers, do we have in particular base concept
-computer understand base 2 (binary number system) --> 0 (false) & 1 (true)
-bit operators -AND -0 + 0 = 0
                    -0 + 1 = 0
                    -1 + 0 = 0
                    -1 + 1 = 1 (truth table)
                    -AND condition means all number/ input should be true ---> entire expression true
                    -if 1 of input is false then output will be false only
                    -trying of output of A & B & C ---> all inputs should be true/ equal to 1
                    -when you AND 1 with any number, digit will remain same
               -OR -0 + 0 = 0
                   -0 + 1 = 1
                   -1 + 0 = 1
                   -1 + 1 = 1
                   -opposite of AND gate, if any 1 of input is true ---> entire expression true
                   -even if both inputs are true output is positive
                -XOR -exclusive OR, if 2 numbers, only 1 of them should be true anything else will 
                      false as output
                     -same input output will be 0
                     -0 + 0 = 0
                     -0 + 1 = 1
                     -1 + 0 = 1
                     -1 + 1 = 1
                     -a ^ 1 = a bar (complementary bar, opposite of number)
                     -0^1=1 & 1^1=0
                     -anything we XOR with 1 ---> get answer opposite
                     -a^0=a
                     -a bar^a = 0
                     -XOR same input ---> output will always 0
-number system -decimal -0-9 & its of base 10
                        -base 10 means there are 10 numbers which used to represent any number in 
                         decimal form (375)10 & (10)10
                        -0,1,2,3,4,5,6,7,8,9,10,11,12........
               -binary -0 & 1 & its of base 2
                       -(10)10 ----> (1010)2, (7)10 ----> (0111)2
               -octal -0-7 & base 8
                      -comparing decimal & octal, 8 & 9 are not used
                      -0,1,2,3,4,5,6,7,10,11,12,13,14,15,16,17,20........
                      -8 in decimal is 10 in octal & 9 in decimal is 11 in octal
               -hexadecimal -0-9 & A-F & its of base 16
                            -(10)10 = (A)16, (12)10 = (C)16
-conversions -decimal (10) ---> binary (2) -divide decimal number by 2
                                           -write down remainder
                                           -repeat until quotient is 0
                                           -read remainders in reverse order
             -binary (2) ---> decimal (10) -multiply each binary digit by 2 raised to its position 
                                            (right to left, starting at 0)
                                           -add all results
             -decimal (10) ---> octal (8) -divide decimal number by 8
                                          -write down remainder
                                          -repeat until quotient is 0
                                          -read remainders in reverse order
             -octal (8) ---> decimal (10) -multiply each digit by 8 raised to its position (right to 
                                           left, starting at 0)
                                          -add all results
             -decimal (10) ---> hexadecimal (16) -divide decimal number by 16
                                                 -write down remainder
                                                 -repeat until quotient is 0
                                                 -read remainders in reverse order
                                                 -if remainder is 10-15, use A-F
             -hexadecimal (16) ---> decimal (10) -multiply each digit by 16 raised to its position 
                                                  (right to left, starting at 0)
                                                 -convert A-F to 10-15 before multiplying
                                                 -add all results
             -binary (2) ---> octal (8) -group binary digits into sets of 3 (right to left)
                                        -convert each group to its octal equivalent
             -octal (8) ---> binary (2) -convert each octal digit to its 3-bit binary equivalent
                                        -0 (000), 1 (001), 2 (010), 3 (011), 4 (100), 5 (101), 6 (110), 
                                         7 (111)
             -binary (2) ---> hexadecimal (16) -group binary digits into sets of 4 (right to left)
                                               -convert each group to hex equivalent
                                               -0 (0000), 1 (0001), 2 (0010), 3 (0011), 4 (0100), 
                                                5 (0101), 6 (0110), 7 (0111), 8 (1000), 9 (1001),  
                                                A (1010), B (1011), C (1100), D (1101), E (1110), 
                                                F (1111)
-operators -left shift operator (<<) -shift all bits towards left side 1 by 1
           -right shift operator (>>) -opposite of left operator, move given input towards right 


Formate specifiers:
-%c -character
-%d -decimal number (base 10)
-%e -exponential floating-point number
-%f -floating-point number
-%i -integer (base 10)
-%o -octal number (base 8)
-%s -string
-%u -unsigned decimal (integer) number
-%x -hexadecimal number (base 16)
-%t -date/time
-%n -newline


Pattern questions:
-map problem to coordinate system
-think pattern as 2D grid with rows (i) & columns (j)
-derive mathematical condition determines when print * (or any character) & when to print space
-use loops efficiently based on this condition


Graphs:
-non-linear data structure consists of vertices & edges vertices (nodes) & edges are lines/ arcs that 
 connect any 2 nodes in graph
-properties -vertex represent physical object, concept, abstract entity
            -edges -connections b/w vertices, undirected (bidirectional) directed (unidirectional)
            -weight -assigned to edge, represents cost, distance b/w 2 vertices
            -weighted graph -graph where edges have weights
            -degree -vertex is number of edges connect to it, directed graph, the in-degree of a vertex is the number of edges that point to it, and the out-degree is the number of edges that start from it.
            -path -sequence of vertices connected by edges, simple path doesn't contain any repeated 
                   vertices or edges
            -cycle -path that starts & ends at same vertex, simple cycle doesn't contain any repeated 
                    vertices or edges
            -connectedness -graph is connected if there is path b/w any two vertices, disconnected  
                            graph is graph not connected
            -planarity -graph is planar if drawn on plane without any edges crossing each other
            -bipartiteness -if vertices divided into 2 disjoint sets like no 2 vertices in same set are 
                            connected by edge
-set of vertices (V) & set of edges(E), graph is denoted G(V, E)
-adjacency matrix representation -matrix of boolean (0’s & 1’s)
                            -n vertices in graph, create 2D matrix adjMat[n][n] having dimension n x n
                            -if edge from vertex i to j, mark adjMat[i][j] as 1 
                            -if edge from vertex i to j, mark adjMat[i][j] as 0
                 -undirected graph -entire matrix is ​​initialised to 0
                                   -if edge from source to destination --> insert 1 to both cases 
                                    (adjMat[destination] & adjMat[destination]) (goes either way)
                 -directed graph -entire matrix is ​​initialised to 0
                                 -If edge from source to destination --> insert 1 for that particular 
                                  adjMat[destination]
-adjacency list representation -array of lists used to store edges b/w 2 vertices, size of array = 
                                number of vertices (n), each index in array represents specific vertex 
                                in graph, entry at index i of array contains linked list contains 
                                vertices that are adjacent to vertex i
                               -If n vertices, create array of list of size n as adjList[n]
                               -adjList[0] ----> all nodes connected (neighbour) to vertex 0
                               -adjList[1] ----> all nodes connected (neighbour) to vertex 1.....
                     -undirected graph -3 vertices, array of list created of size 3
                                       -each indices represent vertices 
                                       -vertex 0 has 2 neighbours (1 & 2) ---> insert vertex 1 & 2 at 
                                        indices 0 of array
                                       -vertex 1, has 2 neighbour (2 & 0) ---> insert vertices 2 & 0 at 
                                        indices 1 of array
                     -directed graph -3 vertices, array of list --> created of size 3
                                     -each indices represent vertices, vertex 0 has no neighbours
                                     -vertex 1, has 2 neighbour (0 & 2) ---> insert vertices 0 & 2 at 
                                      indices 1 of array
-advantages -effective tools to represent complex data, relation b/w data points are not 
             straightforward, uncover patterns, trends
            -processed efficiently, perform complex operations on large datasets quickly 
            -used in network analysis & study relations b/w individuals or organisations, identify 
             important nodes & edges in network, including social sciences, business, marketing
            -pathfinding -find shortest path b/w 2 points, common problem in computer science, 
                          logistics, transportation planning
            -highly visual, easy to communicate complex data & clear, presentations, reports, data 
             analysis
            -machine learning to model complex relation b/w variables, recommendation systems, fraud 
             detection
            -depict flow of computation
            -users on Facebook (vertices), for friends, edge connecting them, friend suggestion system 
             based on graph theory
            -resources allocation graph in OS, each process & resource (vertically), edges are drawn  
             from resources to assigned functions or from requesting process to desired resources
            -web pages (vertices) on world wide web, link from page A to page B (edge)
-disadvantages -only represent relation b/w objects & not their properties or attributes
               -to fully understand data, its necessary to supplement graph with additional information
               -difficult to interpret, when large or complex, challenging to extract meaningful 
                insights from data, require advanced analytical techniques or domain expertise
               -scalability issues -as number of nodes and edges in a graph increases, the processing time and memory required to analyse it also increases. This can make it difficult to work with large or complex graphs.
Data quality issues: Graphs are only as good as the data they are based on, and if the data is incomplete, inconsistent, or inaccurate, the graph may not accurately reflect the relationships between objects.
Lack of standardisation: There are many different types of graphs, and each has its own strengths and weaknesses. This can make it difficult to compare graphs from different sources, or to choose the best type of graph for a given analysis.
Privacy concerns: Graphs can reveal sensitive information about individuals or organisations, which can raise privacy concerns, especially in social network analysis or marketing.
                        

-stack -follow last-in, 1st-out order, efficient insertion & detain at top
       -shopping lists, task management, used for function call, undo operations
-hash-table -stores key-value pairs for quick lookup, use hash function for indexing
            -caching, symbol tables, efficient retrieval, insertion & deletion operations
-tree -organise element in hierarchical structure, element have parent & child relation
      -used for hierarchy, searching, sorting
-queue -follow 1st-in, 1st-out order, efficient insertion at rear & deletion at front
       -print queue, BFS (breadth 1st search), used for managing tasks, message, passing
-graph -represent relation b/w entities, consist of vertices & edges
       -social networks, network routing, used for modelling networking, social connections
-linked-list -internally uses double linked list to store elements
             -manipulation faster than al (no bit shifting is required in memory)
             -consumes more memory than al (stores next & previous references along with data)
             -act as list & queue both, efficient insertion & deletion operations
             -support dynamic size adjustments
-array-List -internally uses dynamic array
            -manipulation with al is slow (internally use array, if element removed from array 
             ----> bits are shifter in memory)
            -consumes less memory than ll, act as list only, image processing, dynamic programming
            -stores multiple element in contiguous memory, accessed by index, fixed/ resizable size
            -better for storing & accessing data


Binary search:
-arr = [2,4,6,9,11,12,14,20,36,48] (sorted array) (ascending order)
-optimised way of learning
-finding element in sorted array by continually chopping search area in 1/2 (example Oxford 
 dictionary)
-linear search can also be done but maximum comparison would be number of elements in array
-we can also use while loop & recursive function
-algorithm for binary search -setting starting element pointer & ending element pointer
			    -finding middle element 
			    -if target element > middle => search in right 
			      else search in left
			    -if middle element == target element //answer
			    -if start == end //element not found
-we are not creating new array
-best scenarios of binary search = when 1st middle element = searching (only take 1 step)
-best case complexity = constant (size does not matter) (O(N))
-worst case scenario = (N/2^(k)) (total number of comparison = logN)
-time complexity -best case O(1)
                 -worst case O(log n)
-find maximum number of comparisons -1 = N/2^k 
-order agnostic binary search -when we don't array is sorted in ascending/ descending order
-arr = [90,75,18,12,6,4,3,1] target = 75
-target > middle --> search in left
-start > end --> descending order
-start < end --> ascending order


Linear search:
-searching -process of finding given position in list of values
-linear/ sequential search -basic & simple search algorithm
                           -we compare target value will all other elements given in list
                           -arr = [24,63,72,34,11,74], target = 77 (target value is compared with all 
                            elements in array in sequential/ linear array
-time complexity -base case O(1) ---> constant
                                 -how many checks will loop make in best case, element will be found at 
                                  0th index (only 1 comparison will be made for best case)
                 -worst case O(n) -go through every element & then say element not found

-simple searching sequentially checks each element in array or list until it finds target value
-time complexity -O(n) (worst case)
-space complexity -O(1) (no extra space needed)
-best used when -array is unsorted, dataset is small
-start from 1st element ---> compare it with target value ---> If match found return index ---> If no 
 match found, return -1


Applications of data structures:
-array -leaderboard in games –storing player rankings
       -music playlists –storing songs in order
       -shopping cart –holding product IDs temporarily
-linked list -undo/redo in text editors –each operation is node
             -call logs in mobile phones –maintains recent calls dynamically
             -music playlist with shuffle mode -easily insert/delete songs
             -singly linked list -1-directional navigation
             -doubly linked list -forward & backward navigation
             -circular linked list -forms loop (useful in CPU scheduling)
-stack (LIFO) -undo/redo operations –browsers, text editors
              -backtracking algorithms –solving mazes, recursive function calls
              -call stack in java –manages function calls
-queue (FIFO) -ticketing systems –people standing in queue
              -print queue –printing jobs processed in order
              -CPU scheduling –managing process execution
              -circular queue –used in OS job scheduling
              -priority queue –used in Dijkstra’s shortest path algorithm
              -double-ended queue (Deque) –used in browsers (forward/backward navigation)
-HashMap -phone contacts –names mapped to numbers
         -caching in web browsers –storing frequently accessed data
         -DNS resolution –maps website names to IP addresses
-heap (priority queue) -task scheduling –google calendar sorts by priority
                       -search engine rankings –google ranks pages using priority queue
                       -stock market tracking –keeping track of top stocks
-graph -google maps –shortest path algorithms (Dijkstra's)
       -social networks –friend recommendations on Facebook
       -electric circuits –representing circuit paths
-tree -file systems –organising folders/files
      -auto-suggest in search engines –trie structure for search predictions
      -databases (B-Trees, AVL trees) –faster lookups
      -binary search tree (BST) –used in databases
      -trie (prefix tree) –used in autocomplete
      -AVL tree –used in file systems
-bit manipulation (BitSet) -image processing –storing pixels efficiently
                           -music fingerprinting –identifying songs
                           -phone number availability –fast lookup tables


Leetcode Questions:
-easy -pointers, stacks, trees
-anagram -rearranging words (ANKUR --> RNUAK)
-two pointers
-DFS, BFS 
-understand problem statement properly -what is input? (size, type, constraints)
                                       -what is output? (format, expected result)
                                       -are there edge cases? (empty input, duplicates, negatives)
                                       -what is time complexity limit? (O(N)? O(N²)? O(log N)?)
-identify data structure needed
-need sorting ---> array/ heap
-need fast lookups ---> HashMap / set
-need a first-in-first-out (FIFO) structure ---> queue
-need last-in-first-out (LIFO) ---> stack
-need to process elements in order ---> linked list
-need to find the max/min efficiently ---> heap
-need fast range queries ---> segment tree /fenwick tree
-break problem into small parts -write brute force approach 1st
                                -think of optimisations step by step
                                -use helper functions for complex problems
                                -longest substring without repeating characters --> brute force → O(N²)
                                 --> optimised -use sliding window with HashSet → O(N)
-master time & space complexity -every interview problem requires efficient solutions
                                -O(1) -constant time (best)
                                -O(log N) -binary search
                                -O(N) -linear scan
                                -O(N log N) -sorting algorithms
                                -O(N²) -nested loops (avoid if possible)
-practice common edge cases -most interviewers test edge cases, always check
                            -empty input ("", [], {})
                            -single element cases ("a", [1])
                            -duplicates ([1, 1, 1])
                            -negative numbers ([-1, -2, -3])
                            -large inputs (performance testing)
-debug efficiently & use print statements -add print statements to track variable values
                                          -use python tutor /debugger tools
                                          -check edge cases you may have missed
                                          -dry-run code with small example
-sliding window -when dealing with subarrays, strings (longest substring without repeating characters)
-two pointers -when comparing elements in array or string	(valid palindrome, two sum II)
-fast & slow pointers -when detecting cycles (linked lists, arrays) (linked list cycle, happy number)
-binary search -when input is sorted or searching	 (search in rotated sorted array)
-DFS/BFS	 -when dealing with trees, graphs, backtracking (number of islands, word search)
-dynamic programming (DP) -when solving recursive problems with overlapping subproblems (climbing 
                           stairs, house robber)
-greedy algorithm -when making locally optimal choices leads to global optimum (jump game, gas station)
-backtracking -when exploring all possible solutions (permutations, sudoku solve)
-heap/ priority queue -when working with top K elements or scheduling problems (Kth largest element, 
                       merge K sorted lists)
-union-find (disjoint set) -when dealing with connected components	 (number of provinces, redundant 
                            connection)


---------------------------------------------News Info-------------------------------------------------

-stylus -capacitive touch screen -transfer of energy b/w screen & stylus
                                 -constant energy flow in display panel
        -EMR (electromagnetic resonance) -needs actual power
                                         -need digitiser layer b/w glass & LCD touch sensor
                                         -electromagnetic radiations, palm rejection, tilt sensitivity, 
                                          brush stroke, pressure sensitivity
-kernel will show alerts on any ECC capable system that doesn't have ECC memory installed.
The alerts are nothing to worry about. You can blacklist the EDAC driver to hide them but it's not necessary.
-1/2 black and 1/2 CGA striations
-ECC ram installed and wants to drive it as ECC ram
-old things -earphone mobile box, removable battery, pop-up camera, dual punch hole, home button, front   
             facing stereo speakers
-Broadcom wifi card
-finding motherboard that work with Linux, every intel/ AMD CPU is supported & RAM, hard drives, 
 graphics cards
-(ECC RAM) compatible with the mobo, and you can use it if you so choose. No enable/disable switches, parameters, or otherwise for ECC or NON-ECC RAM exist in the BIOS.
-OBS Studio works great, VSCode/VSCodium are available, you can use the vanilla MC launcher in fedora
-rpmfusion, GNOME extensions, DNF tweaks, distro much optimized for games and media production nobara
-Fedora is very bleeding edge and Debian is definitely the more stable
-kernel stability makes using ZFS for raid much easier to deal with

flatpaks for steam and bottles work very well for gaming and they have more updated drivers than the debian system -- so you get the best of both having a stable system but newer drivers just for games

flatpaks work well for other apps, including libreoffice, to be more current than stock debian

Gnome not being the latest helps if you like certain addons
-Most of the desktop apps you use will be available in the official repos, rpmfusion (a community maintained one), copr (user specific) or Flathub, as Flatpaks, which I recommend. Flatpaks are containerized so they run across all distros and they keep their dependencies in the container, so they install/uninstall clean
-Great, since they do minimal customization of upstream and you're getting the latest languages and libraries. Fedora's downstream, RHEL, is also wildly popular in enterprise (arguably the most popular) so it's a standard development target. "Light enough" depends on the desktop you select but the default GNOME desktop is about 750mb RAM.

Personally I haven't had issues with the Discord or Steam Flatpaks, but if you want to customize what they have access to, look at Flatseal. In KDE a Flatpak permissions manager is built-in and can be found in Settings. For IDEs I tend to avoid Flatpaks though, since they're not usually designed for it and I've seen weird behavior.


-AMD lacks many newly announced codecs like VP9/h265/AV1
-nvidia on linux --> 
